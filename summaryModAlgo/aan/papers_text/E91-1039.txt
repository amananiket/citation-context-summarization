AUTOMATIC  SEMANTIC CLASSIFICATION OF VERBS FROM THEIR 
SYNTACTIC CONTEXTS: AN IMPLEMENTED CLASSIFIER FOR STATIVITY 
Michael R. Brent 
M IT  AI Lab 
545 Technology Square 
Cambr idge,  Massachusetts  02139 
michael@ai .mit .edu 
Abst rac t  
This paper discusses an implemented 
program that automatically classifies 
verbs into those that ~ describe only 
states of the world, such as to know, and 
those that describe events, such as to 
look. It works by exploiting the con, 
straint between the syntactic environ- 
ments in which a verb can occur and 
its meaning. The only input is on-line 
text. This demonstrates an important 
new technique for the automatic gener- 
ation of lexical databases. 
1 In t roduct ion  
Young children and natural language process- 
ing programs face a common problem: everyone 
else knows a lot more about words. Children, it is 
hypothesized, catch up by observing the linguis- 
tic and non-linguistic contexts in which words are 
used. This paper focuses on the value and acces- 
sibility of the linguistic context. It argues that  
linguistic ontext by itself can provide useful cues 
about verb meaning to an artificial learner. This is 
demonstrated bya program that exploits two par- 
ticular cues from the linguistic ontext o classify 
verbs automatically into those whose sole sense is 
one describing astate, and those that have a sense 
describing an event. 1 The approach described here 
accounts for a certain degree of noise in the input 
due both to mis-apprehension f input sentences 
and to their occasional real.formation. This work 
shows that the two cues are available and are re- 
liable given the statistical methods applied. 
Language users, whether natural or artificial, 
need detailed semantic and syntactic lassifica- 
tions of words. Ultimately, any artificial anguage 
IThe input  sentences are those compiled in the Lan- 
caster/Oslo/Bergen (LOB) Corpus, a balanced corpus 
of one million words of British English. The LOB con- 
sists primarily of edited prose. 
user must be able to add new words to its lexicon, 
if only to accommodate he many neologisms i t  
will encounter. And our lexicographic needs grow 
with our understanding of language. A number 
of current approaches to satisfying the lexical re- 
quirements for artificial devices do not involve un- 
supervised learning from examples. Boguraev and 
Briscoe (1987)discusses interpreting the informa- 
tion published in on-line dictionaries, while Zernik 
a/~d Dyer (1987) discuss tutored learning in a con. 
trolled environment. But any method that re- 
quires explicit human intervention - - be it that of 
lexicographers, knowledge ngineers, or "tutors" 
- -  will lag behind both the growth of vocabu- 
lary and the growth of linguistics, and even with 
the lag their maintenance will be expensive. By 
contrast, dictionaries constructed by automated 
learners from real sentences will not lag behind 
vocabulary growth; examples of current language 
use are free and nearly infinite. These observa- 
tions have led ~everal researchers, including Hindle 
(1990) and Smadja nd McKeown (1990), to begin 
investigating automatic acquisition of semantics. 
Hindle and Smadja and McKeown rely purely on 
the ability of one particular word to statistically 
predict the occurrence of another in a particular 
position. In contrast, he approach described here 
is targeted at particular semantic lasses that are 
revealed by specific linguistic onstructions. 
2 The  Quest ions  
This section discusses work on two linguis- 
tic cues that reveal the availability of non-stative 
senses for verbs. This work attempts to determine 
the difficulty of using the cues to classify verbs: 
into those describing states and those describing 
events. To that end, it focuses on two questions: 
1. Is it possible to reliably detect he two cues 
using only a simple syntactic mechanism and 
minimal syntactic knowledge? How simple 
can the syntax be? (The less knowledge re- 
quired to learn using a given technique, the 
- 222 - 
J 
more useful the technique will be.) 
2. Assuming minimal syntactic power, how re- 
liable are our two cues in real text, which 
is subject to performance limitations? Are 
there learning strategies under which their re- 
liability is adequate? 
Section 2.1 describes yntactic onstructions stud- 
ied and demonstrates their relation to the stative 
semantic lass. Sections 2.2 answers questions 1 
in the affirmative. Section 2.4 answers question 2 
in the affirmative, discusses the statistical method 
used for noise reduction, and demonstrates the 
program that learns the state-event distinction. 
2.1 l ' teveaHng Const ruct ions  
The differences between verbs describing 
states (statives) and those describing events (non- 
statives) has been studied by linguists at least 
since Lakoff (1965). (For a more precise seman- 
tic characterization f stativ?s ee Dowty, 1979.) 
Classic examples of stative verbs are know, believe, 
desire, and love. A number of syntactic tests have 
been proposed to distinguish between statives and 
non-statives (again see Dowry, 1979). For exam- 
ple, stative verbs are anomalous when used in the 
progressive aspect and when 'modified by rate ad- 
verbs such as quickly and slowly: 
(1) a. * Jon is knowing calculus 
b. * Jon knows calculus quickly 
Perception verbs like see and hear share with st~- 
rives a strong resistance to the progressive aspect, 
but not to rate adverbs: 
(2) a. * Jon is seeing the car 
b. OK Jon quickly saw the car 
Agentive verbs describing attempts to gain per- 
ceptions, like look and listen, do not share either 
property: 
(3) a. OK Jon is looking at a car 
b. OK Jon quickly looked at his watch 
The classification program relies primarily on the 
progressive cue, but uses evidence from the rate 
adverb cue when it is available. 
2.2 Syntact i c  Requ i rements  for  Cue  
Detect ion  
Consider first how much syntactic analysis is 
needed to detect the progressive and rate adverb 
constructions. Initially, suppose that the availabil- 
ity of a non-stative sense is aii intrinsic property of 
a verb 2 not affected by its syntactic ontext. To 
detect progressives one need only parse a trivial 
part of the auxiliary system, which is known to 
2This is not true in general, as shown by the f&ct 
that think that.., is stative while think about.., is not. 
be finite-state. Detecting the rate aclverb cue re- 
quires determining what the adverb modifies, and 
that can be trickier. For example, adverbs may 
appear after the direct object, (4a), and this must 
not be confused with the case where they appear 
after the subject of an embedded clause, (4b). 
(4) a. ,Ion fixed the robot quickly 
b. ,Ion knew his hostess rapidly lost inter- 
eat in such things 
Using simple, finite-state machinery one would be 
forced to deal with (4b) by recognizing the po- 
sition of the adverb as ambiguous and rejecting 
the example. Or one could deploy more sophist i -
cated syntax to try determining the boundaries of 
embedded sentences. But even the best syntactic 
parser will fail on truly ambiguous cases like the 
following: 
(5) a. Jon fixed the robot that had spoken 
slowly 
b. Jon believed the robot that had spoken 
slowly 
The data on rate adverbs were collected using 
the parsing approach, which required a substantial 
amount of machinery, but a finite-state approach 
might do almost as well. (See Brent and Berwick, 
1991, for automatic iexical acquisition using sim- 
ple finite-state parsing.) 
2.3 Data  on Cues f rom the  Corpus  
To test the power of the two proposed cues, 
the LOB corpus was automatically processed to 
determine what percentage of each verb's occur- 
rences were in the progressive, and what percent. 
age were modified by rate adverbs. Sampling error 
was handled by calculating the probability distri- 
bution of the true percentage for each verb assum- 
ing that the sentences in the corpus were drawn 
at random from some infinitely large corpus. The 
overall frequency of the progressive construction 
was substantially higher than that of the rate ad- 
verb construction and so provided more significant 
data. Figure 1 shows a histogram constructed by 
summing these distributions of true frequency in 
the progressive over each of the 38 most common 
verbs in the corpus. 3 Figure 1 shows that, at least 
for these most common verbs, there are three and 
perhaps four distinct populations. In other words, 
these verbs do not vary continuously in their fre- 
quency of occurrence in the progressive, but rather 
show a marked tendency to cluster around certain 
values. As will be shown in the next section, the 
3Histograms that include less frequent verbs have 
the same general character, but the second local maxi- 
mum gets somewhst blurred by the many verbs whose 
true frequency in the progressive is poorly localized 
due to insufficient sample size. 
- 223 - 
(p r ln t -h l s togren  h$?S :wax- index  200 : sca le  tOO0) 
NIL 
I I I I I I i I I I I I I I \[ I-\[T -I I 
O.O 0 .0 |  0.02 III.OS 0.84 O.IIS 0?06 O.OT (I.O0 II.O* 0.1 I I . | |  0.12 | .13  0.14 O. IS 0. l?  II.I\]P I I . lO 0.19 0 .2  
I 
~ic L/so Liatener f 
Figure 1: A h i s togram const ructed  by  smnming the  probab i l i ty  d i s t r ibut ions  o f  t rue  f requency  
in the  progress ive  over  each o f  the  38 most  common verbs  in the  corpus  
stative verbs fall in the first population, to the left 
of the slight discontinuity at 1.35% of occurrence 
in the progressive. 
2,4 The  Class i f icat ion Program 
1 implemented a program that attempts to 
classify verbs into those with event senses, and 
those whose only meaning describes a state rather 
than an event. It does this by first detecting oc- 
currences of the progressive and rate adverb con- 
structions in the LOB corpus, and then computing 
confidence intervals on the true frequency of occur- 
rence of each verb in an arbitrarily large corpus 
of the same composition. The program classifies 
the verbs according to bounds, which are for the 
moment supplied by the researcher, on the confi- 
dence intervals. For example, on the run shown 
in Figure 2, the program classifies verbs which oc- 
cur at least .1% of the time either in the progres- 
sive or modified by a rate adverb, as having an 
event (non-stative) sense. The classifier acts on 
.1% bound only if the sample-size is large enough 
to guarantee the bound with 95% confidence. Ac- 
curacy in ascribing non-stative senses according 
with this technique is excellent - -  no purely sta. 
t ire verbs are ntis-classified as having non-stative 
senses. In fact, this result is not very sensitive to 
raising the minimum progressive frequency from 
.1% to as high as .6% or .7%, since most verbs 
with non-stative senses yield observed frequencies 
of at least two or three percent. 
Now consider the other side of the problem, 
classifying verbs as purely stative. Here the pro- 
gram takes verbs that fail the test for having a 
non-stative sense, and in addition whose true fre- 
quency in the progressive falls below a given upper 
bound with sufficient confidence. The rate-adverb 
construction is not used, except insofar as the 
verbs must fail the . 1% lower bound, because this 
construction turns out to be so rare that only a 
few of the most frequent verbs provide sufficiently 
tight bounds. The results for identifying pure sta- 
- 224 - 
(?lass i ry -s ta t lve -non-s ta t lve  :nax-proor - fo r - s ta t lve  .OlOS 
~n ln - r l te - fo r -non-s ta t lve  .OOI 
:n ln-proor - for -non-stat lve .00 | )  
LRCKS-NRN-STRTIVE-SERSE: 
KHOU SEER LIKE RELIEVE URHT OERRIN HERR HERR REOUIRE UNDEGSTRHO RCGEE 
HRS-UOH-STRTIVE-SEHSE: 
UEflR URZT 00 TRLK SROU SO ?TRY TRY VISIT LISTEN LIE SIT PREPRRE FRIL SEEK HONOEG FIGHT UORK STOOY 
B(GZH ORIVE URTCH OERL OCT EHJOY SETTLE SflILE PLRY OZE LIVE HUH HOVE 8TRRO HOPPER HOLK CRERTE PROVE 
CRUSE OR(OK DROP LOOK CRRRY FRCE RTTEND EXPECT FRLL (HO OEVELOP OFFER ERT URIT\[ OEO0 CLOSE RECOil( P 
OIHT OORU RETURN RISE BUILD CHRHCE DIN COnE LERRN PUBLISH PICK RSSOCIRTE GET PRODUCE REPLY PRY LERO 
ZRTRODUC\[ COflPLETE REFUGE SRV( NOTICE PULL OVOID RECEIVE SERVE PDES?RT STOP OPEN ENTER SET SPEHO ~IGH 
FORGET HOTE RGSURE PLRCE IHCRERSE OCCUR COHPRRE COHSIOER SUGGEST COVER DISCOVER SELL THINK OEGOGO RFF~ 
CT KEEP HOLO FOLLOU PUT HEET RCCEPT 8EHO HELP REVERL BOISG ORIGE OPPERR PGOVIO\[ TONE GEH?HOEO SPEEK 
FINISH TURN DSK RERCH LET TELL RRK\[ FELL RHSUER FIND LERV\[ RCHIEVE FEEL CRLL 6HON USE (XPLRIN GIVE 
OGTRIN OECIOE DRY SEE 
IHOETEGHIRATE: 
THROU REFER BRSE CHOOSE CRrCH ORRIVE KRRRGE SUPPORT EXIST BELONG OHISE BERD REEO CUT IHTEHO IRRCIUE C 
LRIH FQRfl BUY HE STRTE gILL RPPLY REISQVE RERLISE HOPE RRINTRIN JOIN HEHTIGN FILL OOnI! OEPEHO REPORT 
OLLOU flROOY ESTRRLISR IHOICRTE LRY LOOSE SPERK SUPPOSE REDUCE REPRESENT LOVE ZHUOLUE COHTRIH OO0 STORY 
8R IHCLUOE COHCERH COHTIHU\[ OE$CRIBE 
HIL 
Oynarnic Lisp Listener f 
Figure 2: One  run  o f  the s ta t ive /non-s ta t ive  c lassi f icat ion program on verbs  occur r ing  at  least 
100 t imes in the  LOB corpus  
tives are also quite good, although more sensitive 
to the precise bounds than were the results for 
identifying non-statives. If the upper bound on 
progressive frequency is set at 1.35%, as in Fig- 
ure 2, then eleven verbs are identified as purely 
stative, of the 204 distinct verbs occurring at least 
100 times each in the corpus. Two of these, hear 
and agree, have relatively rare non-stative senses, 
meaning to imagine one hears ("I am hearing a 
ringing in my ears") and to communicate agree- 
ment ("Rachel was already agreeing when Jon in- 
terrupted her with yet another tirade"). If the up- 
per bound on progressive frequency is tightened to 
1.20% then hear and agree drop into the "indeter- 
minate" category of verbs that pass neither test. 
So, too, do three pure statives, mean, require, and 
understand. 
It is worth noting the importance of using 
some sort of noise reduction technique, such as 
the confidence intervals used here. There are two 
sources of noise in the linguistic input. First 
speakers do utter anomalous entences. For ex. 
ample, the stative verb mean occurred one time 
out of 450 in the progressive. The sentence, "It's 
a stroke, that was what he was meaning" is clearly 
anomalous. The second source of noise is failure 
of the learner to detect the cue accurately. The 
accuracy of our automatic ue detection detection 
is described in the following section. 
2.5 Accuracy  o f  Cue  Detect ion  
Section 2.2 discussed how much structure must 
be imposed on sentences if the progressive and 
rate-adverb constructions are to be detected. Sec- 
tion 2.3 showed that the progressive and rate- 
adverb constructions are indeed reliable cues for 
the availability of a non-stative sense. This sec- 
tion discusses tile accuracy with which these cues 
can be detected. 
It is not practical to check manually every 
verb occurrence that our program judged tO be 
progressive. Instead, I checked 300 such sentences 
225 - 
selected at random from among the most com- 
monly occurring verbs. This check revealed only 
one sentence that did not truly describe a progres- 
sive event. That sentence is shown in (6a). 
(6) a. go: What that means in this case is go. 
ing back to the war years... 
b. see: The task was solely to see how 
speedily it could be met... 
c. compare: ...the purchasing power of the 
underdeveloped countries in the com- 
monwealth will rise slowly compared 
with that of Europe. 
It is not clear how to automatically determine 
that (6a) does not describe an event of going in 
progress. Rate adverbs are infrequent enough that 
it was possible to verify manually all 281 cases the 
program found. In four of those cases the rate ad- 
verb actually modified a verb other than the one 
that the program chose. Three of these four cases 
had the structure of (6b), where a wh- relative 
is not recognized as signaling the beginning of a 
new clause. This reflects an oversight in the gram- 
mar that should be easily correctable. The one re- 
maining case of a mis-attributed rate adverb, (6c), 
would again require some work, and perhaps ub- 
stantial syntactic knowledge, to correct. The rate 
of false positives in cue detection, then can be esti- 
mated at about one serious hazard in 300 for both 
"t'~sts. 
3 Conc lus ions  
This work demonstrates a promising ap- 
proach to automatic semantic classification of 
verbs based only on their immediate linguistic on- 
texts. Some sort of statistical smoothing is essen- 
tial to avoid being permanently mislead by anoma- 
lous and misunderstood utterances, and this work 
demonstrated the sufficiency of an-approach based 
on binomial confidence-intervals. These meth- 
ods, in combination with pure collocational meth- 
ods like those of \[Hindle, 1990\] and \[Smadja nd 
McKeown, 1990\], may eventually ield substan- 
tial progress toward automatic acquisition of word 
meaning, or some aspects thereof, by language us- 
ing devices. 
The initial results described here suggest 
many more experiments, ome of which are al- 
ready u~nderway (see Brent and Berwick, 1991). 
These include attempting to take into account he 
ability of local syntactic ontext to influence a 
verb's meaning as well as to reveal it. For exam- 
ple, think that is stative while think about and think 
of are not. Separating these two senses automati- 
cally could add substantial power to our classifier. 
Next, there are many more linguistic ues to verb 
meaning to be detected and exploited. For exam- 
ple, the ability to take both adirect object and a 
propositional complement, asin "tell him that he's 
a fool", reveal verbs of communication. While the 
progressive cue is not available in Romance lan- 
guages, the ability to take a direct object and a 
propositional complement seems to be diagnostic 
of communication verbs in Romance as well as in 
English. It would be valuable to demonstrate cues 
like this on non-English text. It would also be 
valuable to apply these techniques to a greater va- 
riety of input sentences, including transcriptions 
of mother's peech to their children. Finally, sub- 
stantially larger corpora should be used in order 
to enlarge the number of verbs classified. All of 
these planned extensions serve the goal of auto- 
matically classifying thousands of verbs by dozens 
of different syntactic riteria, and thereby ielding 
a valuable, adaptable l xicon for natural anguage 
processing and artificial intelligence. 
Re ferences  
\[Boguraev and Briscoe, 1987\] B. Boguraev and 
T. Briscoe. Large Lexicons for Natural Lan- 
guage Processing: Utilising the Grammar Cod- 
ing System of LDOCE. Comp. Ling., 13(3), 
1987. 
\[Brent and Berwick, 1991\] M. Brent and 
R. Berwick. Automatic Acquisition of Subcate- 
gorization Frames From Free Text Corpora. In 
Proceedings of the 4th Darpa Speech and Natu- 
ral Language Workshop. Defense Advanced Re- 
search Projects Agency, Arlington, VA, USA, 
1991. 
\[Dowty, 1979\] D. Dowty. Word Meaning and 
Montague Grammar. Synthese Language Li- 
brary. D. Reidel, Boston, 1979. 
\[Hindle, 1990\] D. Hindle. Noun cla-qsification from 
predicate argument structures. In Proceedings 
of the ~Sth Annual Meeting of the ACL, pages 
268-275. ACL, 1990. 
\[Lakoff, 1965\] G. Lakoff. On the Nature of Syntac. 
tic Irregularity. PhD thesis, Indiana University, 
1965. Published by Holt, Rinhard, and Winston 
as Irregularity in Syntax, 1970. 
\[Smadja and McKeown, 1990\] 
F. Smadja and K. McKeown. Automatically 
extracting and representing collocations for lan- 
guage generation. In ~8th Annual Meeting of 
the Association for Comp. Ling., pages 252-259. 
ACL, 1990. 
\[Zernik and DYer, 1987\] U. Zernik and M. Dyer. 
The self-extending phrasal lexicon. Comp. 
Ling., 13(3), 1987. 
- 226 - 
