The Automated Acquisit ion of Topic Signatures for Text 
Summarizat ion 
Chin -Yew L in  and  Eduard  Hovy  
In fo rmat ion  S(:i(umes I l l s t i tu te  
Un ivers i ty  of Southern  Ca l i fo rn ia  
Mar ina  del Rey, CA  90292, USA 
{ cyl,hovy }C~isi.edu 
Abst rac t  
In order to produce, a good summary, one has 
to identify the most relevant portions of a given 
text. We describe in this t)at)er a method for au- 
tomatically training tel)it, signatures--sets of related 
words, with associated weights, organized around 
head topics and illustrate with signatm'es we cre- 
;tt.ed with 6,194 TREC collection texts over 4 se- 
lected tot)ics. We descril)e the l)ossible integration 
of' tolli(: signatures with ontoh)gies and its evaluaton 
on an automate(l text summarization system. 
1 I n t roduct ion  
This t)aper describes the automated (:reation of what 
we call topic signatures, constructs that can I)lay a 
central role. in automated text summarization and 
information retrieval. ToI)ic signatures can lie used 
to identify the t)resence of a (:omph~x conce.pt a 
concept hat consists of several related coinl)onents 
in fixed relationships. \]~.c.sta'uvant-'uisit, for examph~, 
invoh,es at h,ast the concel)ts lltCgFIt, t'.(tt, pay, and 
possibly waiter, all(l Dragon Boat PcstivaI (in Tat- 
wan) involves the Ct)llC(!l)t,S cal(tlzt'lt,s (a talisman to 
ward off evil), rnoza (something with the t)ower of 
preventing pestilen(:e and strengthening health), pic- 
tures of Ch, un9 Kuei (a nemesis of evil spirits), eggs 
standing on end, etc. Only when the concepts co- 
occur is one licensed to infer the comph:x concept; 
cat or moza alone, for example, are not sufficient. At 
this time, we do not c.onsider the imerrelationships 
among tile concepts. 
Since many texts may describe all the compo- 
nents of a comI)lex concept without ever exI)lic- 
itly mentioning the mlderlying complex concel/t--a 
tol)ic--itself, systems that have to identify topic(s), 
for summarization or information retrieval, require 
a method of infcu'ring comt)h'x concelltS fl'om their 
component words in the text. 
2 Re la ted  Work  
In late 1970's, \])e.long (DeJong, 1982) developed a
system called I"tIUMP (Fast Reading Understand- 
ing and Memory Program) to skim newspaper sto- 
ries and extract the main details. FRUMP uses 
a data structure called sketchy script to organize 
its world knowh'dge. Each sketchy script is what 
FRUMI ) knows al)out what can occur in l)articu- 
lar situations such as denmnstrations, earthquakes, 
labor strike.s, an(t so on. FRUMP selects a t)artic- 
ular sketchy script based on clues to styled events 
in news articles. In other words, FRUMP selects an 
eml)t3 ~ t(uni)late 1whose slots will be tilled on the fly 
as t"F\[UMP reads a news artMe. A summary is gen- 
erated })ased on what has been (:al)tured or filled in 
the teml)Iate. 
The recent success of infornmtion extractk)n re- 
search has encore'aged the FI{UM1 ) api)roach. The 
SUMMONS (SUMMarizing Online News artMes) 
system (McKeown and Radev, 1999) takes tem- 
l)late outputs of information extra(:tion systems de- 
velofmd for MUC conference and generating smn- 
maries of multit)le news artMes. FRUMP and SUM- 
MONS both rely on t/rior knowledge of their do- 
mains, th)wever, to acquire such t)rior knowledge 
is lal)or-intensive and time-consuming. I~)r exam-- 
l)le, the Unive.rsity of Massa(:husetts CIRCUS sys- 
l.enl use(l ill the MUC-3 (SAIC, 1998) terrorism do- 
main required about 1500 i)erson-llours to define ex- 
traction lmtterns 2 (Rilotf, 1996). In order to make 
them practical, we need to reduce the knowhxlge n- 
gineering bottleneck and iml)rove the portability of 
FI{UMI ) or SUMMONS-like systems. 
Since the worhi contains thousands, or perhal)s 
millions, of COml)lex (:on(:et)ts , it is important; to be 
able to learn sketchy scripts or extraction patterns 
automatically from corpora -no existing knowledge 
base contains nearly enough information. (Rilotf aim 
Lorenzen, 1999) 1)resent a system AutoSlog-TS that 
generates extraction i)atterns and learns lexical con- 
straints automatically fl'om t)rec\]assified text to al- 
leviate the knowledge ngineering I)ottleneck men- 
tioned above. Although Riloff al)plied AutoSlog-TS 
l\Ve viewed sketchy s(:lil)tS and teml)lates as equivalent 
(ollstrllctS ill the sense that they sl)ecil ~, high level entities 
and relationships for specific tot)its. 
2Aii extra(:l;iOll pattt!rlk is essentially ;t case fraine contains 
its trigger word, enabling conditions, variable slots, and slot 
constraints. C IRCUS uses a database of extraction patterns 
to t~alSe texts (l{ilolI', 1996). 
495 
to text categorization and information extraction, 
the concept of relevancy signatures introduced by 
her is very similar to the topic si.qnatures we pro- 
posed in this paper. Relevancy signatures and topic 
signatures arc both trained on preclassitied ocu- 
ments of specific topics and used to identify the 
presence of the learned topics in previously unseen 
documents. The main differences to our approach 
are: relevancy signatures require a parser. They are 
sentence-based and applied to text categorization. 
On the contrary, topic signatures only rely on cor- 
pus statistics, arc docmnent-based a and used in text 
smnmarization. 
In the next section, we describe the automated 
text smmnarization system SUMMARIST that we 
used in the experiments to provide the context of 
discussion. We then define topic signatures and de- 
tail the procedures for automatically constructing 
topic signatures. In Section 5, we give an overview 
of the corpus used in the evaluation. In Section 6 we 
present he experimental results and the possibility 
of enriching topic signatures using an existing ontol- 
ogy. Finally, we end this paper with a conclusion. 
3 SUMMARIST  
SUMMARIST (How and Lin, 1999) is a system 
designed to generate summaries of multilingual in- 
put texts. At this time, SUMMARIST can process 
English, Arabic, Bahasa Indonesia, Japanese, Ko- 
rean, and Spanish texts. It combines robust natural 
language processing methods (morl)hologieal trans- 
formation and part-of-speech tagging), symbolic 
world knowledge, and information retrieval tech- 
niques (term distribution and frequency) to achieve 
high robustness and better concept-level generaliza-- 
tion. 
The core of SUMMARIST is based on the follow- 
ing 'equation!: 
summarization = topic identification + 
topic interpretation + generation. 
These three stages are: 
Topic Ident i f ieat lon:  Identify the most imtmrtant 
(central) topics of the texts. SUMMARIST 
uses positional importance, topic signature, and 
term frequency. Importance based on discourse 
structure will be added later. This is tile most 
developed stage in SUMMARIST. 
Topic I n te rpretat ion :  ~i~-) fllse concepts such as 
waiter, menu, and food into one generalized 
concept restaurant, we need more than the sin> 
pie word aggregation used in traditional infor- 
mation retrieval. We have investigated concept 
aWe would like to use only the relevant parts of documents 
to generate topic signatures in the future, qkext segmentation 
algorithms uch as TextTiling (Ilearst, 1997) can be used to 
find subtopic segments in text. 
ABCNEWS.cona  : De lay  in  Hand ing  F l ight  990  \ [ ' robe  to  FB I  
N'I 'SI3 C l la i tn lan  Jarl leS t la l l  says  Egypt ian  clff icials Iv811l to  I,~view res t l l t s  
of  t i le  invest igat ion  intcl lhe  cras l l  o f  l lggyptA i r  F l ight  990 before  t i le  case  
i~ lu r l led  over  Ic, t i le Fi31, 
Nt lv.  IG - U S. i lxvestigl~lo\[~ lLppear to  be leat l i l lg i i Iore thg l l  eveF low~trd 
t i le poss ib i l i ty  that  one  o f  the  cc~-pilot~ o f  EgyptA i r  F l ight  990 may have  
de \ [ ihera le ly  c rashed t i le p lane  las t  I lafl l lth, k i l l i ng  all 217 peop le  on  board .  
f la i l ' ever .  US .  o f f i c ia ls  say  t i le  Nat iona l  T ran~por ' ta t ion  Sa fety  Board  wi l l  
de lay  t rans fer r ing  tile invegt iga l ion  o f  the  Oct  31 c rash  to  tilt: FI31 - the  
agency  that  wot l id  lead i~ c r imina l  p robe  - for at  least  tt few days .  to  M Iow 
Egypt ian  exper ts  to rev iew ev idence  ill t i le case.  
gtts l ) ic iot l~ of  fou l  p lay  were  ra i sed  a f te r  invest igators  l i s ten ing  to  rt tape  
ftol l l  l i l t  cockp i t  vo ice recorder  i so la ted  a re l ig ious  prayer  or s ta te l l l e l l t  
made by t i le co -p i lo t  jus t  be fore  t i le  p lane 's  autop i lo t  was turned  o f f  
s l id  the  p lane  began i ts  in i t ia l  p lunge  in to  t i le A t lant i c  Ocean of f  Mas -  
s r tcht tset t$ '  Na l l tucket  \ [s ia l ld .  
Over  tile' pas t  week .  a f te r  muc i l  e f fo r t ,  t i le  NTSJB and  t i le  Navy  succeeded 
ill I ocat i l lg  the  p lane 's  two  "b lack  boxes , "  th~ cockp i t  vo ice recorder  and  
lhe  f l ight  data  recorder .  
The  tape  ind icates  t l l a t  shor t ly  a f te r  the  p lane  leve led ~ff  a t  i ts c ru i s ing  
a l t i tude  o f  as ,000  feet ,  t i le  cl~ief p i lo t  o f  t i le a i rc ra f t  left  the  p lane 's  
cockp i t ,  l eav ing  one  o f  t i le  twc~ co-p i lo ts  nIol le t i lere as the  a i rc ra f t  began 
its descent .  
Figure 1: A Nov. 16 1999 ABC News page sumnmry 
generated by SUMMARIST. 
counting and topic signatures to tackle tile fll- 
sion problem. 
Summary Generat ion :  SUMMARIST can pro- 
duce keyword and extract type summaries. 
Figure 1 shows an ABC News page summary 
about EgyptAir Flight 990 by SUMMARIST. SUM- 
MARIST employs several different heuristics in tile 
topic identification stage to score terms and sen- 
tences. The score of a sentence is simply the sum 
of all the scores of content-bearing terms in the sen- 
tence. These heuristics arc implemented in separate 
modules using inputs from preprocessing modules 
such as tokenizer, part-of-speech tagger, morpholog- 
ical analyzer, term frequency and tfidf weights cal- 
culator, sentence length calculator, and sentence lo- 
cation identifier. \Ve only activate the position mod- 
ule, tile tfidfmodule, and the. topic signature module 
for comparison. We discuss the effectiveness of these 
modules in Section 6. 
4 Top ic  S ignatures  
Before addressing the problem of world knowledge 
acquisition head-on, we decided to investigate what 
type of knowledge would be useflfl for summariza- 
tion. After all, one can spend a lifetime acquir- 
ing knowledge in just a small domain. But what 
is tile minimum amount of knowledge we need to 
enable effective topic identification ms illustrated by 
the restaurant-visit example? Our idea is simple. 
We would collect a set of terms 4 that were typi- 
cally highly correlated with a target concept from a 
preclassified corpus such as TREC collections, and 
then, during smnmarization, group the occurrence of 
the related terms by the target concept. For exam- 
pie, we would replace joint instances of table, inert'u, 
waiter, order, eat, pay, tip, and so on, by the single 
phrase restaurant-visit, in producing an indicative 
4Terms can be stemmed words, bigrams, or trigrams. 
496 
sulnlllary. \Ve thus defined a tot)it signat.ure as a 
family of related terms, as follows: 
~I'S = { topic, sifl~zutu.rc. } 
= {topic,< ( t , ,w l ) , . . . , ( t , , ,w , , )  >} (1) 
where topic is the target concet)t and .,d.q)zat~Lrc is 
a vector of related ternls. Each t, is an term ldghly 
correlated to topic with association weight w/. The 
number of related terms 7z can tie set empirically 
according to a cutot\[ associated weight. We. describe 
how to acquire related terms and their associated 
weights in the next section. 
4.1  S ignature  Term Ext rac t ion  and  Weight  
Es t imat ion  
()n the assumption that semantically related terms 
tend to co-occur, on(' can construct topic signa- 
tures fl'om preclassified text using the X 2 test, mu-. 
tual information, or other standard statistic tests 
and infornlation-theoreti(: measures. Instead of X '2, 
we use likclih.ood ratio (Dunniug, 1993) A, sin(:e A 
i,; more apI)rot)riate for si/arse data than X 2 test 
and the quantity -21o9A is asymi)t(/tically X~ dis- 
tril)ute(15. Therefore, we Call (leterndnc the (:onti- 
( lence level for a specific -21o9A value l/y looking ut) 
X :~ (tistril)ution table and use tlm value to sel(,,ct an 
at)i)rot)riate cutoff associated weight. 
We have documents l)\['e.classitied into a :;('~t, "R. of 
relevant exts and a set ~. of nonrelewmt exl;s for a 
given topic. Assuming the following two hyl)othe,'~es: 
t typothes is  1 ( I f l ) :  t'(~Pvlti) = P = P('PvltT/), i.e. 
the r(.,lewmcy of a d()(:|lment is in(teI)en(hmt, of 
t i .  
I \ ] \ [ypothes is  2 ( t t2) :  I'('Pv\[ti) == lh ~ 1)'2 - 
t)('Pvlt, i), i.e. th(~ t)r(.':;(;n(:(~ of t i indi(:~Lt(.~.'; strong 
r(~levan(:y ~ssunling \]h >> 1)2 ?
and the following 2-10=2 contingency tabl(;: 
where Ol~ is the fiequency of term ti occurring in 
the. l 'e lev;tnt  set ,  012 is the \ [ r ( !qu(nlcy of Lerm t i t)c- 
curring in the  \] lol lreleval lt ,  set ,  O21 is the  f le(l l lel l( :y 
of tt;rnl \ [ i?  ti occurring in the rtdevant set, O._,~ is 
the fl'equ(mcy of term l.i ? ti o(:curring in the non- 
l ' e leva i i t  seL.  
-kssmning a l)inomial distril)ution: 
C;) b(~; ,,., :/.) = :,:~(1 - .~:)(" ") (2 )  
5This assumes |ha l  the ratio is between the inaximuni like> 
\[ihood est, im&t.(! over a .qll})part of l;}l(! i)alatlllC't(~r sl)a(:(~ ;tll(\] l.h(! 
lllaxillUllll likelihood (}sI.i|II}tlA~ ov(!r the (Hltill! i)al'aillt~tt!r si);t(:e. 
Set! (Manning ;tnd Sch/itze, I999) t)ag, es 172 l.o 175 for d(!t.ails. 
then the likelihood for HI is: 
L(H~) = b(Ot~; 0~ + Ou,,p)b(O:,~; 0:,, + Om,,p) 
and for //2 is: 
L(H2)  = D(OI 1; O11 Jr" (')12, Pl )b(O21; (')21 Jr- (,)22,1)2) 
The -2log,\ value is then computed ms follows: 
1.(f/1 ) 
m --21o 9 - -  
L( i t  2 ) 
b(O 11 ; O I  1 + O12,  P) I J (021 : O21 + 022 , P) 
- -21o 9 
1'((-)1 l ; ( )11  + O1'-),  P I )h (O21 ; O21 q- ( )22  , P2 ) 
: - -2 ( (O l l  +021) lo r_ Jp+( ( )12+022) lo9(1 - - l~) - -  (,~1) 
(? ) l l l o ' JP l+Ol21og( l  " t '1 )+0211ogp2-~0221o0(1- f~2) ) )  
-- '.2.,~' x (~ ' i (7~) -  ;~(~19- ) )  (4 )  
= 2,'v x Z(P~;  T )  (5 )  
whel 'e  N = O l t  -F O12 -1- O21 -I- 022 is the  to ta l  l lum-. 
her of t, ernl occurrence, in the corpus, 7/('/~) is the 
entropy of terms over relevant and nonrelevant sets 
of documents, 7/ ( ' fe l t  ) is the entropy of a given term 
OVel" relev;inL ~/nd nonl ' ( .qeval l t  sets  of doel l inel lLS, ~tll(1 
Z('R.; T) i:; the inutual information between docu- 
ment relevancy and a given t('.rm. Equation 5 indi- 
cates that mutual inforntation 6 is an e(tuiwdent mea- 
sur(.' t() lik(.qiho(id ratio when we assume a binomial 
distribution and a 2-by-2 ('ontingency table. 
To crest(; topic .~dgnature for a given tot)ic , we: 
1. (:lassify doctunents as relevant or nonrclcwmt 
according t() tile given topic 
2. comt)ut.e the -21oflA wdue using Equation 3 for 
each Lcrm in the document colle(:Lion 
"{. rank t, erms according 1o their -2lo9~ value 
4. select a c(mfid(mce l , vel fi'om the A;: (listril)utiotl 
table; (letermin(~ the cutotf associated weight, 
mid the numl)(n" of t(nms to he included iIl the 
signatures 
5 The Corpus  
The training data derives Kern the Question and 
Answering summary evahmtion data provided l)y 
T IPSTEI / . -SUMMAC (Mani et al, 1998) that is a 
sttbset of the TREC collectioliS. The TREC data is a 
collection of texts, classified into various topics, used 
for formal ewduaLions of information retrieval sys- 
tems in a seri(~s of annual (:omparisons. This data set: 
contains essential text fragnients (phrases, (:Iausos, 
iuld sentences) which must 1)e included in SUllltIlarios 
to ~tnswer some TI{EC tel)its. These fl'agments are 
each judged 1)y a hmnan judge. As described in Se(:- 
tion 3, SUMMAI~IST employs several independent 
nlo(hlles to assign a score to each SelltA:llCe~ and Chell 
COlll})illeS the st.'or(.'.% L() decide which sentences to ex- 
tract from the input text;. ()n0. can gauge the efticacy 
(>l'he lllll\[lla} inrormalion is defined according to chapter 2 
of ((;over and Thomas, i991) and is not tile i)airwis(~ mutual 
inforlnalion us(!d in ((;hur(:h and llanks, 1990). 
497 
TREC Top ic  Da~cr lp t ion  
(nunQ Number :  151 
( t i t le}  Top ic :  Co, p ing  w i th  overc rowded pr i sons  
(dese} Deser i l l t io l l :  
The  doeu l laent  will p rov ide  in f ,~rn lat ion ol~ jai l  and  pr ison overc rowd iuK  
and  how i r lmates  are forced to cope  wi th  th,~se cond i t ions ;  or it wil l  
revea l  p lan~ to  re l ieve  ti le overc rowded ?o l ld i t lon .  
(nar t )  Nar ra t ive :  
A re levant  docunaent  will descr ibe  scene~ of overcro~vdi l lg that  have  
beco lne  all too  crlllllllOll ill ja i l s  and  pr i sons  a ro t tnd  the  count ry ,  T i le  
document  will i dent i fy  how inmates  are forced to  cope w i th  those  over -  
crowded cond i t ion~,  and/or  what  ti le Cc l r reet iona l  Syste l l l  is do ing ,  or 
ph lnn ing  to do,  to a l lev ia te  ti le c rowded col ld i t io l l .  
(/top) 
Test  Quest ions  
QI  Me'hat are  name and/or  locat ion  of ti le cor rec t ion  fae i l i l ies  
where  the  repor ted  ~vercrowd ing  ex is ts?  
Q2 x~Vhat negat ive  exper iences  have  there  been  at t i le overc rowded 
fac i l i t ies  (whether  or not tile)" are thought  to have  been  caused  
by  the  overc rowd lng)?  
Q3 What  measures  have  been  taken/p la ia i led / recommended (e tc . )  
to aecon l lnod~te  more  i l l l l la Ies zlt pena l  fac i l i t ies ,  e .g . ,  doub l i l l g  
tip, Ile~y COllStructlon? 
Q,I ~,Vhat measures  have  been  taken/planned/rec~mnlel,ded (etc .} 
to reduce  ti le l lt l l l lber of Dew il l l i \]ate$, e .g . ,  morator iums 
on admisMon,  a l te rnat ive  pena l t ies ,  p rograme to reduce  
c r ime/ rec ld iv i sm? 
Q5 What  measures  have  been  taken/p lanned/ recommended (e tc . )  
to reduce  ti le number  of ex i s t ing  inmates  at an overcrc~wded 
fac i l i ty ,  e .g . .  g rant ing  ear ly  re lease ,  t rnns fer ing  to  uncrowded 
fac i l i t ies?  
Sample  Answer  Keys  
(DOCNO)  AP891027-0063 ( /DOCNO)  
(F ILE ID)  AP -NR-  10-27-89 0615EDT( /F ILE ID)  
( IST_L INE) r  a PM-Cha ined Inmates  10-27 0335( / IST .L INE)  
(2ND-L INE)PM-Cha ined  lnmates ,0344 ( /2ND_L INE)  
( I IEAD)  lnmates  Cha ined  to 1.Vails in 13Mtimore Po l i ce  
S ta t ions ( / l lEAD)  
(DATEL INE)BALT IMOIT IE  (AP)  ( /DATEL INE} 
('tEXT) 
(Q ,q )pr i soner~ are  kept  cha ined  to the wall~ of local po l ice  lcJekup~ for 
as long as th ree  days  at a t ln~e I)ecattse of overc rowd ing  ill regu la r  je l l  
cel ls ,  pol ice sa id . ( /Q3} 
Overcrowd ing  at  the  (Q1) lqMt l rnore  County  Detent ion  Center ( /Q1)  
h~ forced pn l lee  tn  . .  
(/TEXT) 
Table 1: TREC topic description for topic 151, test 
questions expected to be answered by relewmt doc- 
uments, and a smnple document with answer key, s. 
of each module by comparing, for ditferent amounts 
of extraction, how many :good' sentences the module 
selects by itself. We rate a sentence as good simply 
if it also occurs in the ideal human-made xtract, 
and measure it using combined recall and precision 
(F-score). We used four topics r of total 6,194 doc- 
uments from the TREC collection. 138 of them are 
relevant documents with T IPSTER-SUMMAC pro- 
vided answer keys for the question and answering 
evaluation. Model extracts are created automati- 
cally from sentences contailfing answer keys. Table 
1 shows TREC topic description for topic 151, test 
questions expected to be answered by relevant doc- 
uments , and a sample relevant document with an- 
swer keys markup. 
7These four topics are: 
topic 151: Overcrowded Prisons, 1211 texts, 85 relevant; 
topic 257: Cigarette Consumption, 1727 texts, 126 relevant; 
topic 258: Computer Security, 1701 texts, 49 relevant; 
topic 271: Solar Power, 1555 texts, 59 relevant. 
SA relevant: document only needs to answer at least one of 
the five questions. 
6 Experimental Results 
In order to assess the utility of topic signatures in 
text sununarization, we follow the procedure de- 
scribed at the end of Section 4.1 to create topic 
signature for each selected TREC topic. Docu- 
ments are separated into relevant and nom'elevant 
sets according to their TREC relevancy judgments 
for each topic. We then run each document hrough 
a part-of-speech tagger and convert each word into 
its root form based on the \\h)rdNct lexical database. 
We also collect individual root word (unigram) fi'e- 
quency, two consecutive non-stopword 9 (bigram) fi'e- 
quency, and three consecutive non-stopwords (tri- 
gram) fi'equeney to facilitate the computation of the 
-21ogA value for each term. We expect high rank- 
ing bigram and trigram signature terms to be very 
informative. We set the cutoff associated weight at 
10.83 with confidence level ~t = 0.001 by looking up 
a X 2 statistical table. 
Table 2 shows the top 10 unigrmn, bigram, and tri- 
gram topic signature terms for each topic m. Several 
conclusions can be drawn directly. Terms with high 
-21ogA are indeed good indicators for their corre- 
sponding topics. The -2logA values decrease as the 
number of words in a term increases. This is rea- 
sonable, since longer terms usually occur less often 
than their constituents. However, bigram terms are 
more informative than nnigrant erms as we can ob- 
serve: jail//prison overervwding of topic 151, tobacco 
industry of topic 257, computer security of topic 258, 
and solar e'n, ergy/imwer of topic 271. These mLto- 
matically generated signature terms closely resemble 
or equal the given short TREC topic descriptions. 
Although trigram terms shown in the table, such 
as federal court order, philip morris 7~r, jet propul.. 
sion laboratory, and mobile telephone s:qstem are also 
meaningflfl, they do not demonstrate he closer term 
relationship among other terms in their respective 
topics that is seen in tlm bigram cases. We expect 
that more training data can improve tile situation. 
We notice that the -2logA values for topic 258 
are higher than those of the other three topics. As 
indicated by (Mani et al, 1998) the majority of rel- 
evant documents for topic 258 have the query topic 
as their main theme; while the others mostly have 
the query topics as their subsidiary themes. This 
implies that it is too liberal to assume all the terms 
in relevant documents of the other three topics are 
relevant. We plan to apply text segmentation algo- 
rithms such as TextTiling (Hearst, t997) to segment 
documents into subtopic units. We will then per- 
form the topic signature creation procedure only on 
tile relevant units to prevent inchlsion of noise terms. 
9\,Ve use the stopword list supplied with the SMAIIT re- 
trieval system. 
l?q'he -2logA values are not comparable across ngram cat- 
egories, since each ngraln category has its own sample space. 
498 
Top ic  
I :ll h~l al l l  -21,~gX \ ] l i~ la l l I  -21,,9X 
j a i l  t)3L I)1,1 e()tH~t 2, ja i l  Dit) 27:1 
c+,l l l l l} .IIJN ~21 eae ly  le+\]+.~lSt ? N,'~ :{t;\] 
, )v , . ) , '~ , ,wd ln~;  :?12:1. I~ ~ta l , .  D l~. , ,n  7.1 R72 
i l l ln?lt ," 2 : t l  7d5  s ta l , "  1,) i~, ,n, . i  67  ,3(~t~ 
~h+. l i f \ [  IF, I . i l o  ,1:~ 3 fill," l ; l  t(;2") 
s ta le  151 9t t~ ia i l  r l%l ' lctr~%vI\] l r ld I;1 ~\[ i  
I}l l~t l l i l ' l  I I  ~" I ";~' C(,tlt I + , l , i " t  t{ll.O!)l} 
i+tl-s,,rl 1,17, 3t),i h . .a l  j a i l  56  t i t+  
C l )y  133177 p l l . , )D  ( )vcy lc l , , i v th l l~  55 37:  +, 
, , v , . r , . r , ,wd ,+d 12N I)t)S i-(*lllt :l\[ fac i l i t  3 52 9o9  
10 S ignat t t ro  Torms o f  Tup ic  151  Ovorcrowdod Pr i sons  
"I'I I~I al I l  -21,,~11\ 
f - , I t . l~t l  c , ,u l~ <, l t t , . l  -I.', :),;11 
C, , l l l p \ ]y  c+,ll~('lll ,\]+'c\[+++" 3,5 12L 
+l,.kali+ i'i)iI i,\[~' +h, ' l l \ [ \ [  \[15 121 
~,11  i,) t l ; ,nk  :;.5 L21 
j , )o t l ; l l l k  IH ) l i5  :~.',.1'21 
pl l~C, l l , ' r  c+)l l : l l~ la i l  :~5 121 
91: i f , .  \ ] ) l l~t ) l l  i21) l l l t l~ ~N t).l\[\] 
t put  pl is+, l l  .2t~ :t-II 
c+~uuly  jaiL ~l ; l l , .  2 t~31 l 
h,,hl l,~e~l ja i l  2d  :l I I 
Top ic  10  S ig l ln t t l re  Tern ls  o f  Top ic  257  - ( l igar~t t~ Co| l s l l l ) l | ) t lo | l  
l :n i<r tun  21ogX I+i ~.rarll -- 2 / , , f / . \  'i r i4~am - 21, ,~A 
c lgrt l , . I t?+ .171; \[}:iN ~tlb:xt'c+) LIt( \ ] l l~l l~ ~il 7)iN I ,h i l ip  I I l , ) l l i+ t j l  2.~ ~DSI 
l ( )ht lcc~) : l l ; l  017  hn  t - lg / l l , - l l t -  t ;7 t2}I I r ) l \ ] i l I l a l l s  beDs~, l l  h<.(\[~f. 211 ~)t~\[l 
s I I IOk i l l~  28.t  19~ ph i l ip  t l l ( , l \ [ i~  5t  ()7;~ \[1111~ L'ikll('e\[ d '+\ [ l l l l  22 21. t  
~n l~,ke  15913.1  clarxl<'t1, :  %, 'at  t80 . t5  q t t  iri l ln cl l~ '.2'1 I IS  
I ,~ lh l l l a l l?  156. )375 to lh l l l l l l l~  i t l Y , ' l I l a t l t ) l lgk l  -t.t .13.1 qt l  q t t  f i~ ln  21 - I lS  
, ,~ha  I . tS 372  tobac? , )  elll()k.~ 112){}I  bll  b\[i bl l  20  22t i  
s ,~i la 12)i .121 ~il pat r i ck  t0 .  t55  c+)l lst l l l l l} l lo l l  bn  c lgar , . l te  2022d 
Illtll 113 ~+1~) c l~at+' l l~"  c~l l lpa l lV  :ID \[$1)D ~\[t+gtt a l l l . r \ [ iCtt l l  ~llI,lk?'(}llt 20226 
al l l , )k( ' l  10.1 I i0  ('el l l  l l l a lk+' l  36223 \[ l l l l~ Ca l l t 'e \ [  ht:gl\[ I  2(~ 22{i 
b\[~t 79 .90:1  ?~IN illt+ll+il++t :1t;.22:1 i l l a \ [ay~ia l l  +illk~\[tl>,ll+e t'4)l l lpi l l IV 2( I .22t \ ]  
Top ic  I0 S ignatur .  "I'~r)ns of Top ic  258 -- Co)nputor  Secur i ty  
I ~llial /lilt "2Ionia I t  i+/,r al l l  21,QIX "I'1 i~ratn  --21o9, X 
(:+lll l l)l ltOr 115!~ :151 C4, l l lp I l l l ' t  ae l ' t l l l l y  213331 )e l  I l t t /p l l \ [~i() l l  \ ] l th t )h l t ( l l y  \ [~  ~5.t  
v i rus  927.G7-1 ~\[ ; idt lgt l , "  s l t l \ [ t l ' l l l  17~ 5NN I l lh . ' l l  I lilt) 9R 85, t  
hacker  867 .377 FOl l lp t l t , ' t  +yS le l l l  1 -16.32~ C,+ltl++\]l I l l l iVet~il~,'  ~ lad l l \ [ t le  7}) IJNI 
in,) l  rl+ +i+;+~ 2i13'.! ) l , .~+-arch c,+ulte\[  l ; i2  .l I :i l awte l l c l "  b , ' rk , '  *'j~ lal l , ) l  al+,l  ,,. 79.0N \[ 
c , , rn , ' l l  3P+5 6+4 c , : ,ml ,u t , ' r  wrus  12~k033 I~+,++, je t  p tO l , t l L+ io t+ 79 .0~1 
un lv+' l? i ty  31)5 .95~ corne l i  U lX iVe le i ty  1(1~4 7-t l  U l ; iV ,q+i )y  ~; radu lx t , .  +tx ldt .  lll 79U~1 
+ysl+' l l l  290 .3"17  Iltl(:l,P;ll %t++npl)ll 107 .283 lawt l l l e ,+ l i v+: r tn ( . te  I igt l i () l lal  i\]\[) l\[I;~ 
I / tb , . ra lL : ) ly  2N7 521 in i l i ta ry  t ' ( , l l lp , l l . : r  106 .522 l iv~qll l ,) l?" i lu) i ,maL  lubora lo ry  {59195 
\ [ab  225 .51) ;  v i tu~ plo~t<' l l l l  1U6 522 c,) l l lp l l I (~r S ,~CUl i ly  eXpet l  66 .19G 
mecLa ly  128 .515 %vesl ~et l l l a l l  82  2 \ [0  ~ecu\ [ i t? , '  cenl{~\[  13ethesda  -19423 
Top ic  10  S ignature  Ter lns  o f  Top ic  271  So lar  Power  
I ' l l i g ta ln  - -21oqX t i ig t  ~ltn --2logX "I'r i ~;r hi l l  - -21o!~A 
so la r  -1S- l .315 e,~la~ e l te t l4y  2{Di 521 d iv i~ i ,m Inu l l ip l ,~  acress  31 3-17 
) t lazd i t  :10Pt 0IY) s<,lal l , t lw , ' t  9,1 210  n l , )b i l , :  l , , l , -ph , ,n , .  #c iv ic , ,  313 .17  
le,) 271; .932  ( 'h r i~t ia l l  a id  8 f i .211  b l i l l sh  It .cl l l l i l l l )R}' g \ [ , , l l p  23510 
it JtLi It l l l  2.5N.71):"+ l++,a S3'Sl,*III 711 5:{5 el l l I} l  he iNht  llXile 23+5111 
pax+lh , ,n  2133 81 I ill++tlllt. Ie i t ' j ) l l l ) l le  (115;l+i I'illllllCilll I lack i l l+;  I l Jd l l l l l l  22i+51(1 
i)(~tltld 12 / ,121  i t i , l i un l  p l , , j , . c l  112.697 ~l,~l lal  In r )h i l ,  + sa l , ' l l i te  23  511J 
t , lw~r  12G.35:1 lei l i  <+, , ,d -  61.~111 ha l ld l le ld  IIled~il," t , ' l eph , , l l , :  '23510 
\ [ , , , , k , ,u t  125 .ll3t; scie. l lc, ,  pa lk  ~'>.1 NS{) i l l ( ,h i le  ~ate l l l l . ,  . v>tetn  23  510 
i i l \ [ l l l i lSRl  1O9728 ~()llkl t ' i l l l t ' l ' l l t l i l I l , l  51t ~5{} I l l l l t l l lvl i l l  i g id i l ln l  I> l , l j ec t  23 ,510  
hc ,ydsh , t l  7N :173 l)p s l l la l  ?+1 ; /17  act iv t -  s+,la\[ *ys tern  15673 
Tattle 2: Top 10 signat.m'e t.erm.~; of mfigram, bigram, and trigram for fore" TREe  t.opics. 
6.1 Comparing Summary Extraction 
Effectiveness Using Topic Signatures+ 
TFII)t",  and Bas(,line Algor i thms 
In orde)" I() (~vahla(.(~ the (d\[+:ct.iv(,im.~s nf l(>l)i(: .~dgna- 
l;lll'(~S llS(~(\] ill SlllllIIN/l'y (~Xtl'it(:t;iOll, W{,  ~ CtIllll)~ll'(~ +flit! 
Sllltllll~tl'y StHII~011('CS ex(~ract,(~d 1)y the tol) ic si~Ilil\[lll'0, 
module+, basulin(.' module, and tfidf lnothll(~s with lm- 
nta'n annot,  at(~(l lllo(lo,\] Sllllllll}ll'ios. \VC III(+~}/SIlI'(+ + l;h(; 
l)c'rfl)rmanc(~' using a c()ml)ined umasure of l'n'call (I~) 
and pr(~cisi(m (P), F. F-score is defined by: 
I " - -  (1 +H'2)I'l? where 
/3-'P + I~ 
t ) 
2 \7 . )  ,. 
f'~rln 
fVln 
~\,, 
# of  .sc,tcncc.~ c:rtratcd th,t  olso 
atqwar in. tim model ,s.mn)?lr!l 
# of  sc+lt(!ncc,s i11 tim nlo,h:l .~um.tav!l 
# of  ,s('./Itclwcs c:rlv?lclcd t)1,t ll*c .Sll.Slcln 
rclatic'c iml,ortancc of  l~ aml 1:' 
(6) 
(7) 
\Ve as.~um(~ (,(lual importance of re(:all iIIld preci- 
sion aim set H to 1 in our (+,Xl)('+rimtml;s. The Imselitm 
(I)ositi(m) module scores ('at:h S(!llt(':llC{} hy its I)osi- 
ti(>n in the text. The first sent(race gets the high- 
esc s(:ortL the last S(HIt(H1Co the lowest. The l)as(~liIl(~ 
method is eXlmCted to lm ('.f\[ectiv(~ for news gem'e. 
The tfidf module assigns a score t.o a tt++rllI ti at:cord- 
ing to the product; of its flequc, ncy within a dot:- 
lllll(Hlt .j ( t f i j )  and its illV(~I'S(} doctmmnt  t?equoncy  
(idfi lo.q ,~). N is the total mmfl)or of document.s 
in the (:()rlms and dfj is the, numl)er of (Io(:HnloAll;.q 
(:OlH:nining te rm ti. 
The topic sigjlla(.lll(++ module sciliis each ,q(~llt;(H1C(~: 
assigning to ('ach word that occurs in a topic signa- 
(ure thu weigh(, of that, keyword in t.hc' tol)ic signa- 
tltl'tL Eit{'h s(++llt(,+ItC(~ Ill(ill l'(:c(:ive.q a top ic  s ignature  
score equal to tlm total of all signature word scores it 
(:Olllailis, normalizc'd 1) 3' the. highest sentence score. 
This s(:ol( 3 indical.es l;h(~ l'(!l(wall(:(~ of l.h(; S(!llt.t~n(:(! to 
t, lw sigmmlre topic. 
SU.~\[.MAt/IST In'oduced (!xttat:ts of tlm samu 
l(~xI.q sui)aralely for each ,,lodul0, for a s(~l'i(,s of ex- 
tracts ranging from ()cX; to 100% of the. original l;(}xI. 
Althottgh many rel<want docttments are avaita})l+, 
for each t01>ic, Ollly SOlll0 o\[ \[h0111 htlv(~ allSWOl kc!y 
499 
markut)s. The mnnber of documents with answer 
keys are listed in the row labeled: "# of Relevant 
Does Used in Training". To ensure we utilize all 
the available data and conduct a sound evaluation, 
we perform a three-fold (:ross validation. We re- 
serve one-third of documents as test set, use the rest 
as training set, and ret)eat three times with non- 
overlapl)ing test set. Furthernmre, we use only uni- 
gram topic signatures fin" evaluation. 
The result is shown in Figure 2 and TaMe 3. We 
find that the topic signature method outperforms 
the other two methods and the tfidfmethod performs 
poorly. Among 40 possibh,, test points fl)r four topics 
with 10% SUmlnary length increment (0% means se- 
lect at least one sentence) as shown in Table 3, the 
topic signature method beats the baseline method 
34 times. This result is really encouraging and in- 
dicates that the topic signature method is a worthy 
addition to a variety of text summarization methods. 
6.2 Enriching Topic Signatures Using 
Existing Ontologies 
We have shown in the previous sections that topic 
signatures can be used to al)I)roximate topic iden- 
tification at the lexieal level. Although the au- 
tomatically acquired signature terms for a specific 
topic seem to 1)e bound by unknown relationships as 
shown in Table 2, it is hard to image how we can 
enrich the inherent fiat structure of tol)ie signatures 
as defined in Equation 1 to a construct as complex 
as a MUC template or script. 
As discussed in (Agirre et al, 2000), we propose 
using an existing ontology such as SENSUS (Knight 
and Luk, 1994) to identify signature term relations. 
The external hierarchical framework can be used to 
generalize topic signatures and suggest richer rep- 
resentations for topic signatures. Automated entity 
recognizers can be used to (:lassify unknown enti- 
ties into their appropriate SENSUS concept nodes. 
We are also investigating other approaches to attto- 
matieally learn signature term relations. The idea 
mentioned in this paper is just a starting point. 
'7 Conc lus ion  
In this paI)er we l)resented a t)rocedure to automati- 
(:ally acquire topic signatures and valuated the eflk~c- 
tiveness of applying tol)i(: signatures to extract ot)i(: 
relevant senten(:es against two other methods. The 
tot)ie signature method outt)erforms the baseline and 
the tfidfmethods for all test topics. Topic signatures 
can not only recognize related terms (topic identifi- 
(:ation), but grout) related terms togetlmr under one 
target concept (topic interpretation). 'IbI)i(: identi- 
fication and interpretation are two essential steps in 
a typical automated text summarization system as 
we l)resent in Section 3. 
'\]))pic: signatures (:an also been vie.wed as an in- 
verse process of query expansion. Query expansion 
intends to alleviate the word mismatch ln'oblenl in 
infornmtion retrieval, since documents are normally 
written in different vocabulary, ttow to atttomati- 
(ally identify highly e(nrelated terms and use them 
to improve information retrieval performance has 
been a main research issue since late 19611's. Re- 
cent advances in the query expansion (Xu and Croft, 
1996) can also shed some light on the creation of 
topic signatures. Although we focus the ltse of topic 
signatures to aid text summarization i this paper, 
we plan to explore the possibility of applying topic 
signatures to perform query expansion in the future. 
The results reported are encouraging enough to 
allow us to contimm with topic signatures as the ve- 
hMe for a first approximation to worht knowledge. 
We are now busy creating a large nmnber of signa- 
ture.s to overcome the world knowledge acquisition 
problem and use them in topic interpretation. 
8 Acknowledgements  
YVe thank the anonymous reviewers for very use- 
tiff suggestions. This work is supported in part by 
DARPA contract N66001-97-9538. 
References  
Eneko .~girre, Olatz Ansa, Edum'd Hovy, and David 
Martinez. 2000. Enriching very large ontologies 
using the www. In Proceedings of the Work,,;hop 
on Ontology Construction of the European Con- 
fl:rencc of AI (ECAI). 
Kenneth Church and Patrick Hanks. 1990. Word as- 
sociation IIOrlllS, mutual information and lexicog- 
raphy. In Proceedings of the 28th Annual Meeting 
of the Association for Computational Lingui.vtic.~" 
(,4CL-90), pages 76~-83. 
Thomas Cover and Joy A. Thomas. 1991. Elcment.~ 
of Information Theory..John Wiley & Sons. 
Gerald DeJong. 1982. An overview of the FRUMP 
system. In ~2mdy G. Lehnert and Martin H. 
Ringle, editors, Strategies for natural language 
processing, pages 149-76. Lawrence Erlbaum A.s- 
so(lares. 
Ted Dunning. 1993. A~i:eurate methods for the 
statistics of surprise and coincidence. Computa- 
tional Li'nguistics, 19:61--7'4. 
Marti Itearst. 1997. TextTiling: Segmenting text 
into nmlti-l)aragraph subtopic passages. Compu- 
tational Linguistics, 23:33-64. 
Eduard Hovy and Chin-Yew Lin. 1999. Automated 
text summarization i SUMMAIRIST. In Inder- 
jeer Mani and Mark T. Maybury, editors, Ad- 
vances in Automatic 71xxt Summarization, chap- 
ter 8, pages 81 94. MIT Press. 
Kevin Knight and Steve K. Luk. 1994. Building a 
large knowledge base for machine translation, ht 
Proceedings of the Eleventh National Coy@re'nee 
on Arti\]icial Intelligence (AAAI-9/~). 
500 
-~  ..~:,., .;~ ,5. " ' - -=-"  _..  _ . .&ass  
0 50000 n ~ .~ . . . . . . . . . . . . . .  n ~ . . . . . . . . . . . . . . . . . . . .  ~ . . . . . . . . . .  
- - ' - . , ,q ,~  . . . .  + +. ,x.  o + ~ ? 
. . . . .  1,* '+  .~  *+-  . . . .  - -  
. . ; -5; , :~:;  . . . .  h ~.:~.7~.~ ~ ~ ^' - -~- . .  
. . . . . . . .  , ? - -g2  . . . . . . . . . .  o 400OO f , ' " +- ~-" + ~ -, "~2x-+, 
\[ ? . . . .  : . . . . . . .  : 
\[ - ...... ; ""7 ........ 2,=_ 
~ 0 =0000 j '  +J" J j  1" " 
.,::i'ff "4. 4 "A- . I  - i+ ~. : 
4" .,~t . -a  + -a--  -#. - . -~-- - .a  ~ ' . 
0 ~o00o 'd-;9~7~ -7 '+ 5~:7~:=-+': ; :  ~ . . . .  =-~++:7:: ~ -:'~ +--~ ....... " ~5_~Ztt::~:ll;: ; i  
I " , ; .  A ' / , -?~-  <F" ~. " "~" ~ 257 
44" ? 
o ;oo~ ._~-.c_-__~ / 
0 00000 
I 
000 005 010 015 020 025 030 ,335 040 045 050 055 060 065 070 o75 050 085 090 095 ~00 
.~ umrn~i-~ Lenqth 
Figure 2:  F-measur(: w;. summary length for all fimr topics. ~bi)ic signature cl(mrly outperforin tfidf and 
baselin(', ex(:ei)t for tit(: case of topic 258 where t)(~rforman(:(; for tim thr(;e methods are roughly equal. 
I__ I - - - - - -~~g-  lO% I ___~o~a -ao~~a--- -  4o~ I ~0%- - \ [  ~o~ \[ ~,o~ ~o% I 9o~ I lOO% I 
\[ ~.+,_~.,~dl .... i . . :ms o.a-~9 I o..~.o o.aa4 o . ,~:c -  I ...ao=, \[ '__2 :~r'  I~  o.ara oar , ;  I . .a t , ,  I e.a.~w-I 
+4.58 +7.48 +15.6a +14.17 +8.66 +3. I 51_ top lc . s i~  I -2 ,7d  -2 .19- -  
\[ 257-h , , * , , l i  .... r--- (1.1-}98 {~.15.__.5 I c,,, ,,.is., ".'~L I o.,~~--F--,~.~,, I - -o  t,l o.1~, I ?.!s~ 
\[ '_,.~r_,a,,r \[ -55.11- -38.56 I -'".5U ~">' ~".0'; ' ' " '+ '  I S '~: ' '  I ~ ~ " " "  I +r  0 '~t  . . . . .  , 
257_,~i,ic.~ig +45.5~ +64.06 +31.88 ~ +20.40 \[ +20.60 \[ 4_-~01 +12.4&- I14 .24  - O.(h.~\] 
\[_ 25u_h~,~.,li . . . .  L_  o l  tk_ o 270 I "'4'-'2 ~' *'~:~ I ,, ~,r_, L_  "47t_ J  .4 r , ,  1 - - ~ - ' 1  o.~,'__,+~ o s'_,Z._J 
\[ 271_l,aseli . . . .  I <,at tT_.._,~.:,,~; T--,Ta77--- ..a:~ _L ,, :s:,r, .L .... ~~~~:~- i~-  T -  o.ae~ \] , ) . :~:~~\[--~ 
. . . . . . .  +a~. lO  j _ _  + 4 ~ _ ~ ~ s . r o . ~  +~.a,~ I +~.~o_ l l  0.,~, \] 
Table 3: F..measul'e t)erformanc(~ differen(:e compared to 1)aselin(~ nt(:thod in t)ercentage. Cohmms indicate 
at diffe.rent summary lengths related to fldl length docum(mts. Values in the 1)aselin(,. rows are F-measure 
s(:ores. Vahms in the tfidf and tot)i(: signatur(~ rows arc i)('.rformmlc(~ increase or (h,.crease divide(l by their 
(:orr(.,sI)ontling baseline scores and shown in I)er(:(mtag(!. 
Inderje(?t Mani, David House, Gary KMn, Lyn(~tt(~ 
ttirschman, Leo ()brst, Thdr6se Firmin, Micha(d 
Chrzanowski, and Beth Sundheim. 1998. 
The T IPSTER SUMMAC t~xl smmnm'iza- 
tion evaluation final r(:t)ort. %~(:hnical I/,ol)orl; 
MTR98W0000138, The MITRE Corporation. 
Christopher Manning and Hinrich Schiitzc. 1999. 
t'}mdatious of Statistical Natural Language Pro~ 
cessi'ng. MIT Press .  
Kathh~(m M(:K(!own and l)rag(mfir R. I ladev. 1999. 
( 'TO. I I (  ra t ,  i l l g  S l l l l l l l l ; l l ' i ( : s  o f  I l t l l l t ,  i \ [ ) l \ [~  l l ( !~vs  articles. 
In hMtu.iet~t Mani and Mark T. Maybury, edi 
t,ors, Admm.ces i'n Automatic Text Sv,.mmarization, 
chapter 24, pagc+s 381 :/89. MiT Press. 
Ellen Riloff and Jeffrey Lorenzen. 1999. Ext:raction- 
t)a:;e,d text cateI,dorization: Generating donmin- 
qmcitic role relationships atttonmtically. In 
Tomek Strzalkowski, editor, Natural Language In- 
formation, Retrieval. Kluwer Academic Publishc, r.q. 
Ellen tlilolf. 1996. An ompirical study of automated 
dictionary construction for information extraction 
in three domains. Artificial Intelligence ,Journal, 
85, August. 
SAIC. 1998. Introduction to information extraction. 
http://www.mu(:.sai(:.(:om. 
Jinxi Xu and W. Bruc(! Croft. 1996. Query ex- 
pal>ion using local and gh)bal document analysis. 
In l'rocee.dings of the 17th Annual Inter'national 
A(JM SIGIR Co't@rence. on Research and Devel- 
opment in Information l{et'rieval, pages 4 -11. 
50 I  
