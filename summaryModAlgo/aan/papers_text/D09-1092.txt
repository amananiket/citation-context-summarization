Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 880?889,
Singapore, 6-7 August 2009.
c
?2009 ACL and AFNLP
Polylingual Topic Models
David Mimno Hanna M. Wallach Jason Naradowsky
University of Massachusetts, Amherst
Amherst, MA 01003
{mimno, wallach, narad, dasmith, mccallum}cs.umass.edu
David A. Smith Andrew McCallum
Abstract
Topic models are a useful tool for analyz-
ing large text collections, but have previ-
ously been applied in only monolingual,
or at most bilingual, contexts. Mean-
while, massive collections of interlinked
documents in dozens of languages, such
as Wikipedia, are now widely available,
calling for tools that can characterize con-
tent in many languages. We introduce a
polylingual topic model that discovers top-
ics aligned across multiple languages. We
explore the model?s characteristics using
two large corpora, each with over ten dif-
ferent languages, and demonstrate its use-
fulness in supporting machine translation
and tracking topic trends across languages.
1 Introduction
Statistical topic models have emerged as an in-
creasingly useful analysis tool for large text col-
lections. Topic models have been used for analyz-
ing topic trends in research literature (Mann et al,
2006; Hall et al, 2008), inferring captions for im-
ages (Blei and Jordan, 2003), social network anal-
ysis in email (McCallum et al, 2005), and expand-
ing queries with topically related words in infor-
mation retrieval (Wei and Croft, 2006). Much of
this work, however, has occurred in monolingual
contexts. In an increasingly connected world, the
ability to access documents in many languages has
become both a strategic asset and a personally en-
riching experience. In this paper, we present the
polylingual topic model (PLTM). We demonstrate
its utility and explore its characteristics using two
polylingual corpora: proceedings of the European
parliament (in eleven languages) and a collection
of Wikipedia articles (in twelve languages).
There are many potential applications for
polylingual topic models. Although research liter-
ature is typically written in English, bibliographic
databases often contain substantial quantities of
work in other languages. To perform topic-based
bibliometric analysis on these collections, it is
necessary to have topic models that are aligned
across languages. Such analysis could be sig-
nificant in tracking international research trends,
where language barriers slow the transfer of ideas.
Previous work on bilingual topic modeling
has focused on machine translation applications,
which rely on sentence-aligned parallel transla-
tions. However, the growth of the internet, and
in particular Wikipedia, has made vast corpora
of topically comparable texts?documents that are
topically similar but are not direct translations of
one another?considerably more abundant than
ever before. We argue that topic modeling is
both a useful and appropriate tool for leveraging
correspondences between semantically compara-
ble documents in multiple different languages.
In this paper, we use two polylingual corpora
to answer various critical questions related to
polylingual topic models. We employ a set of di-
rect translations, the EuroParl corpus, to evaluate
whether PLTM can accurately infer topics when
documents genuinely contain the same content.
We also explore how the characteristics of dif-
ferent languages affect topic model performance.
The second corpus, Wikipedia articles in twelve
languages, contains sets of documents that are not
translations of one another, but are very likely to
be about similar concepts. We use this corpus
to explore the ability of the model both to infer
similarities between vocabularies in different lan-
guages, and to detect differences in topic emphasis
between languages. The internet makes it possible
for people all over the world to access documents
from different cultures, but readers will not be flu-
ent in this wide variety of languages. By linking
topics across languages, polylingual topic mod-
els can increase cross-cultural understanding by
providing readers with the ability to characterize
880
the contents of collections in unfamiliar languages
and identify trends in topic prevalence.
2 Related Work
Bilingual topic models for parallel texts with
word-to-word alignments have been studied pre-
viously using the HM-bitam model (Zhao and
Xing, 2007). Tam, Lane and Schultz (Tam et
al., 2007) also show improvements in machine
translation using bilingual topic models. Both
of these translation-focused topic models infer
word-to-word alignments as part of their inference
procedures, which would become exponentially
more complex if additional languages were added.
We take a simpler approach that is more suit-
able for topically similar document tuples (where
documents are not direct translations of one an-
other) in more than two languages. A recent ex-
tended abstract, developed concurrently by Ni et
al. (Ni et al, 2009), discusses a multilingual topic
model similar to the one presented here. How-
ever, they evaluate their model on only two lan-
guages (English and Chinese), and do not use the
model to detect differences between languages.
They also provide little analysis of the differ-
ences between polylingual and single-language
topic models. Outside of the field of topic mod-
eling, Kawaba et al (Kawaba et al, 2008) use
a Wikipedia-based model to perform sentiment
analysis of blog posts. They find, for example,
that English blog posts about the Nintendo Wii of-
ten relate to a hack, which cannot be mentioned in
Japanese posts due to Japanese intellectual prop-
erty law. Similarly, posts about whaling often
use (positive) nationalist language in Japanese and
(negative) environmentalist language in English.
3 Polylingual Topic Model
The polylingual topic model (PLTM) is an exten-
sion of latent Dirichlet alocation (LDA) (Blei et
al., 2003) for modeling polylingual document tu-
ples. Each tuple is a set of documents that are
loosely equivalent to each other, but written in dif-
ferent languages, e.g., corresponding Wikipedia
articles in French, English and German. PLTM as-
sumes that the documents in a tuple share the same
tuple-specific distribution over topics. This is un-
like LDA, in which each document is assumed to
have its own document-specific distribution over
topics. Additionally, PLTM assumes that each
?topic? consists of a set of discrete distributions
D
N
1
T
N
L
...
w
? ?
wz
z
...
?
1
?
L
?
1
?
L
Figure 1: Graphical model for PLTM.
over words?one for each language l = 1, . . . , L.
In other words, rather than using a single set of
topics ? = {?
1
, . . . ,?
T
}, as in LDA, there are L
sets of language-specific topics, ?
1
, . . . ,?
L
, each
of which is drawn from a language-specific sym-
metric Dirichlet with concentration parameter ?
l
.
3.1 Generative Process
A new document tuplew = (w
1
, . . . ,w
L
) is gen-
erated by first drawing a tuple-specific topic dis-
tribution from an asymmetric Dirichlet prior with
concentration parameter ? and base measurem:
? ? Dir (?, ?m). (1)
Then, for each language l, a latent topic assign-
ment is drawn for each token in that language:
z
l
? P (z
l
|?) =
?
n
?
z
l
n
. (2)
Finally, the observed tokens are themselves drawn
using the language-specific topic parameters:
w
l
? P (w
l
| z
l
,?
l
) =
?
n
?
l
w
l
n
|z
l
n
. (3)
The graphical model is shown in figure 1.
3.2 Inference
Given a corpus of training and test document
tuples?W and W
?
, respectively?two possible
inference tasks of interest are: computing the
probability of the test tuples given the training
tuples and inferring latent topic assignments for
test documents. These tasks can either be accom-
plished by averaging over samples of ?
1
, . . . ,?
L
and ?m from P (?
1
, . . . ,?
L
, ?m |W
?
, ?) or by
evaluating a point estimate. We take the lat-
ter approach, and use the MAP estimate for ?m
and the predictive distributions over words for
?
1
, . . . ,?
L
. The probability of held-out docu-
ment tuples W
?
given training tuples W is then
approximated by P (W
?
|?
1
, . . . ,?
L
, ?m).
Topic assignments for a test document tuple
w = (w
1
, . . . ,w
L
) can be inferred using Gibbs
881
sampling. Gibbs sampling involves sequentially
resampling each z
l
n
from its conditional posterior:
P (z
l
n
= t |w, z
\l,n
,?
1
, . . . ,?
L
, ?m)
? ?
l
w
l
n
|t
(N
t
)
\l,n
+ ?m
t
?
t
N
t
? 1 + ?
, (4)
where z
\l,n
is the current set of topic assignments
for all other tokens in the tuple, while (N
t
)
\l,n
is
the number of occurrences of topic t in the tuple,
excluding z
l
n
, the variable being resampled.
4 Results on Parallel Text
Our first set of experiments focuses on document
tuples that are known to consist of direct transla-
tions. In this case, we can be confident that the
topic distribution is genuinely shared across all
languages. Although direct translations in multi-
ple languages are relatively rare (in contrast with
comparable documents), we use direct translations
to explore the characteristics of the model.
4.1 Data Set
The EuroParl corpus consists of parallel texts in
eleven western European languages: Danish, Ger-
man, Greek, English, Spanish, Finnish, French,
Italian, Dutch, Portuguese and Swedish. These
texts consist of roughly a decade of proceedings
of the European parliament. For our purposes we
use alignments at the speech level rather than the
sentence level, as in many translation tasks using
this corpus. We also remove the twenty-five most
frequent word types for efficiency reasons. The
remaining collection consists of over 121 million
words. Details by language are shown in Table 1.
Table 1: Average document length, # documents, and
unique word types per 10,000 tokens in the EuroParl corpus.
Lang. Avg. leng. # docs types/10k
DA 160.153 65245 121.4
DE 178.689 66497 124.5
EL 171.289 46317 124.2
EN 176.450 69522 43.1
ES 170.536 65929 59.5
FI 161.293 60822 336.2
FR 186.742 67430 54.8
IT 187.451 66035 69.5
NL 176.114 66952 80.8
PT 183.410 65718 68.2
SV 154.605 58011 136.1
Models are trained using 1000 iterations of
Gibbs sampling. Each language-specific topic?
word concentration parameter ?
l
is set to 0.01.
centralbank europ?iske ecb s l?n centralbanks 
zentralbank ezb bank europ?ischen investitionsbank darlehen 
??????? ???????? ???????? ??? ????????? ???????? 
bank central ecb banks european monetary 
banco central europeo bce bancos centrales 
keskuspankin ekp n euroopan keskuspankki eip 
banque centrale bce europ?enne banques mon?taire 
banca centrale bce europea banche prestiti 
bank centrale ecb europese banken leningen 
banco central europeu bce bancos empr?stimos 
centralbanken europeiska ecb centralbankens s l?n 
b?rn familie udnyttelse b?rns b?rnene seksuel 
kinder kindern familie ausbeutung familien eltern 
?????? ??????? ?????????? ??????????? ?????? ???????? 
children family child sexual families exploitation 
ni?os familia hijos sexual infantil menores 
lasten lapsia lapset perheen lapsen lapsiin 
enfants famille enfant parents exploitation familles 
bambini famiglia figli minori sessuale sfruttamento 
kinderen kind gezin seksuele ouders familie 
crian?as fam?lia filhos sexual crian?a infantil 
barn barnen familjen sexuellt familj utnyttjande 
m?l n? m?ls?tninger m?let m?ls?tning opn? 
ziel ziele erreichen zielen erreicht zielsetzungen 
??????? ????? ?????? ?????? ?????? ???????? 
objective objectives achieve aim ambitious set 
objetivo objetivos alcanzar conseguir lograr estos 
tavoite tavoitteet tavoitteena tavoitteiden tavoitteita tavoitteen 
objectif objectifs atteindre but cet ambitieux 
obiettivo obiettivi raggiungere degli scopo quello 
doelstellingen doel doelstelling bereiken bereikt doelen 
objectivo objectivos alcan?ar atingir ambicioso conseguir 
m?l m?let uppn? m?len m?ls?ttningar m?ls?ttning 
andre anden side ene andet ?vrige 
anderen andere einen wie andererseits anderer 
????? ???? ???? ????? ?????? ???? 
other one hand others another there 
otros otras otro otra parte dem?s 
muiden toisaalta muita muut muihin muun 
autres autre part c?t? ailleurs m?me 
altri altre altro altra dall parte 
andere anderzijds anderen ander als kant 
outros outras outro lado outra noutros 
andra sidan ? annat ena annan 
DA
DE
EL
EN
ES
FI
FR
IT
NL
PT
SV
 
DA
DE
EL
EN
ES
FI
FR
IT
NL
PT
SV
 
DA
DE
EL
EN
ES
FI
FR
IT
NL
PT
SV
 
DA
DE
EL
EN
ES
FI
FR
IT
NL
PT
SV
 
Figure 2: EuroParl topics (T=400)
The concentration parameter ? for the prior over
document-specific topic distributions is initialized
to 0.01T , while the base measure m is initialized
to the uniform distribution. Hyperparameters ?m
are re-estimated every 10 Gibbs iterations.
4.2 Analysis of Trained Models
Figure 2 shows the most probable words in all lan-
guages for four example topics, from PLTM with
400 topics. The first topic contains words relating
to the European Central Bank. This topic provides
an illustration of the variation in technical ter-
minology captured by PLTM, including the wide
array of acronyms used by different languages.
The second topic, concerning children, demon-
strates the variability of everyday terminology: al-
though the four Romance languages are closely
882
related, they use etymologically unrelated words
for children. (Interestingly, all languages except
Greek and Finnish use closely related words for
?youth? or ?young? in a separate topic.) The third
topic demonstrates differences in inflectional vari-
ation. English and the Romance languages use
only singular and plural versions of ?objective.?
The other Germanic languages include compound
words, while Greek and Finnish are dominated by
inflected variants of the same lexical item. The fi-
nal topic demonstrates that PLTM effectively clus-
ters ?syntactic? words, as well as more semanti-
cally specific nouns, adjectives and verbs.
Although the topics in figure 2 seem highly fo-
cused, it is interesting to ask whether the model
is genuinely learning mixtures of topics or simply
assigning entire document tuples to single topics.
To answer this question, we compute the posterior
probability of each topic in each tuple under the
trained model. If the model assigns all tokens in
a tuple to a single topic, the maximum posterior
topic probability for that tuple will be near to 1.0.
If the model assigns topics uniformly, the maxi-
mum topic probability will be near 1/T . We com-
pute histograms of these maximum topic prob-
abilities for T ? {50, 100, 200, 400, 800}. For
clarity, rather than overlaying five histograms, fig-
ure 3 shows the histograms converted into smooth
curves using a kernel density estimator.
1
Although
there is a small bump around 1.0 (for extremely
short documents, e.g., ?Applause?), values are
generally closer to, but greater than, 1/T .
0.0 0.2 0.4 0.6 0.8 1.0
0
2
4
6
8
10
12
Smoothed histograms of max(P(t))
Maximum topic probability in document
Den
sity 800 topics400 topics200 topics100 topics50 topics
Figure 3: Smoothed histograms of the probability of the
most probable topic in a document tuple.
Although the posterior distribution over topics
for each tuple is not concentrated on one topic,
it is worth checking that this is not simply be-
cause the model is assigning a single topic to the
1
We use the R density function.
tokens in each of the languages. Although the
model does not distinguish between topic assign-
ment variables within a given document tuple (so
it is technically incorrect to speak of different pos-
terior distributions over topics for different docu-
ments in a given tuple), we can nevertheless divide
topic assignment variables between languages and
use them to estimate a Dirichlet-multinomial pos-
terior distribution for each language in each tuple.
For each tuple we can then calculate the Jensen-
Shannon divergence (the average of the KL di-
vergences between each distribution and a mean
distribution) between these distributions. Figure 4
shows the density of these divergences for differ-
ent numbers of topics. As with the previous fig-
ure, there are a small number of documents that
contain only one topic in all languages, and thus
have zero divergence. These tend to be very short,
formulaic parliamentary responses, however. The
vast majority of divergences are relatively low (1.0
indicates no overlap in topics between languages
in a given document tuple) indicating that, for each
tuple, the model is not simply assigning all tokens
in a particular language to a single topic. As the
number of topics increases, greater variability in
topic distributions causes divergence to increase.
0.0 0.1 0.2 0.3 0.4 0.5
0
5
10
15
20
Smoothed histograms of inter?language JS divergence
Jensen?Shannon Divergence
Den
sity
800 topics400 topics200 topics100 topics50 topics
Figure 4: Smoothed histograms of the Jensen-Shannon
divergences between the posterior probability of topics be-
tween languages.
4.3 Language Model Evaluation
A topic model specifies a probability distribution
over documents, or in the case of PLTM, docu-
ment tuples. Given a set of training document tu-
ples, PLTM can be used to obtain posterior esti-
mates of ?
1
, . . . ,?
L
and ?m. The probability of
previously unseen held-out document tuples given
these estimates can then be computed. The higher
the probability of the held-out document tuples,
the better the generalization ability of the model.
883
Analytically calculating the probability of a set
of held-out document tuples given ?
1
, . . . ,?
L
and
?m is intractable, due to the summation over an
exponential number of topic assignments for these
held-out documents. However, recently developed
methods provide efficient, accurate estimates of
this probability. We use the ?left-to-right? method
of (Wallach et al, 2009). We perform five esti-
mation runs for each document and then calculate
standard errors using a bootstrap method.
Table 2 shows the log probability of held-out
data in nats per word for PLTM and LDA, both
trained with 200 topics. There is substantial varia-
tion between languages. Additionally, the predic-
tive ability of PLTM is consistently slightly worse
than that of (monolingual) LDA. It is important to
note, however, that these results do not imply that
LDA should be preferred over PLTM?that choice
depends upon the needs of the modeler. Rather,
these results are intended as a quantitative analy-
sis of the difference between the two models.
Table 2: Held-out log probability in nats/word. (Smaller
magnitude implies better language modeling performance.)
PLTM does slightly worse than monolingual LDA models,
but the variation between languages is much larger.
Lang PLTM sd LDA sd
DA -8.11 0.00067 -8.02 0.00066
DE -8.17 0.00057 -8.08 0.00072
EL -8.44 0.00079 -8.36 0.00087
EN -7.51 0.00064 -7.42 0.00069
ES -7.98 0.00073 -7.87 0.00070
FI -9.25 0.00089 -9.21 0.00065
FR -8.26 0.00072 -8.19 0.00058
IT -8.11 0.00071 -8.02 0.00058
NL -7.84 0.00067 -7.75 0.00099
PT -7.87 0.00085 -7.80 0.00060
SV -8.25 0.00091 -8.16 0.00086
As the number of topics is increased, the word
counts per topic become very sparse in mono-
lingual LDA models, proportional to the size of
the vocabulary. Figure 5 shows the proportion
of all tokens in English and Finnish assigned to
each topic under LDA and PLTM with 800 topics.
More than 350 topics in the Finnish LDA model
have zero tokens assigned to them, and almost all
tokens are assigned to the largest 200 topics. En-
glish has a larger tail, with non-zero counts in all
but 16 topics. In contrast, PLTM assigns a sig-
nificant number of tokens to almost all 800 top-
ics, in very similar proportions in both languages.
PLTM topics therefore have a higher granularity ?
i.e., they are more specific. This result is impor-
tant: informally, we have found that increasing the
granularity of topics correlates strongly with user
perceptions of the utility of a topic model.
0 200 400 600 800
0.00
0.01
0.02
0.03
0.04
Sorted topic rank
Perc
enta
ge o
f tok
ens
Figure 5: Topics sorted by number of words assigned.
Finnish is in black, English is in red; LDA is solid, PLTM is
dashed. LDA in Finnish essentially learns a 200 topic model
when given 800 topics, while PLTM uses all 800 topics.
4.4 Partly Comparable Corpora
An important application for polylingual topic
modeling is to use small numbers of comparable
document tuples to link topics in larger collections
of distinct, non-comparable documents in multiple
languages. For example, a journal might publish
papers in English, French, German and Italian. No
paper is exactly comparable to any other paper, but
they are all roughly topically similar. If we wish
to perform topic-based bibliometric analysis, it is
vital to be able to track the same topics across all
languages. One simple way to achieve this topic
alignment is to add a small set of comparable doc-
ument tuples that provide sufficient ?glue? to bind
the topics together. Continuing with the exam-
ple above, one might extract a set of connected
Wikipedia articles related to the focus of the jour-
nal and then train PLTM on a joint corpus consist-
ing of journal papers and Wikipedia articles.
In order to simulate this scenario we create a
set of variations of the EuroParl corpus by treat-
ing some documents as if they have no paral-
lel/comparable texts ? i.e., we put each of these
documents in a single-document tuple. To do this,
we divide the corpusW into two sets of document
tuples: a ?glue? set G and a ?separate? set S such
that |G| / |W| = p. In other words, the proportion
of tuples in the corpus that are treated as ?glue?
(i.e., placed in G) is p. For every tuple in S, we
assign each document in that tuple to a new single-
document tuple. By doing this, every document in
S has its own distribution over topics, independent
of any other documents. Ideally, the ?glue? doc-
884
uments in G will be sufficient to align the topics
across languages, and will cause comparable doc-
uments in S to have similar distributions over top-
ics even though they are modeled independently.
Table 3: The effect of the proportion p of ?glue? tuples on
mean Jensen-Shannon divergence in estimated topic distribu-
tions for pairs of documents in S that were originally part of
a document tuple. Lower divergence means the topic distri-
butions distributions are more similar to each other.
p Mean JS # of pairs Std. Err.
0.01 0.83755 487670 0.00018
0.05 0.79144 467288 0.00021
0.1 0.70228 443753 0.00026
0.25 0.38480 369608 0.00029
0.5 0.29712 246380 0.00030
Table 4: Topics are meaningful within languages but di-
verge between languages when only 1% of tuples are treated
as ?glue? tuples. With 25% ?glue? tuples, topics are aligned.
lang Topics at p = 0.01
DE ru?land russland russischen tschetschenien sicherheit
EN china rights human country s burma
FR russie tch?etch?enie union avec russe r?egion
IT ho presidente mi perch?e relazione votato
lang Topics at p = 0.25
DE ru?land russland russischen tschetschenien ukraine
EN russia russian chechnya cooperation region belarus
FR russie tch?etch?enie avec russe russes situation
IT russia unione cooperazione cecenia regione russa
We train PLTM with 100 topics on corpora with
p ? {0.01, 0.05, 0.1, 0.25, 0.5}. We use 1000 it-
erations of Gibbs sampling with ? = 0.01. Hy-
perparameters ?m are re-estimated every 10 it-
erations. We calculate the Jensen-Shannon diver-
gence between the topic distributions for each pair
of individual documents in S that were originally
part of the same tuple prior to separation. The
lower the divergence, the more similar the distri-
butions are to each other. From the results in fig-
ure 4, we know that leaving all document tuples
intact should result in a mean JS divergence of
less than 0.1. Table 3 shows mean JS divergences
for each value of p. As expected, JS divergence is
greater than that obtained when all tuples are left
intact. Divergence drops significantly when the
proportion of ?glue? tuples increases from 0.01 to
0.25. Example topics for p = 0.01 and p = 0.25
are shown in table 4. At p = 0.01 (1% ?glue? doc-
uments), German and French both include words
relating to Russia, while the English and Italian
word distributions appear locally consistent but
unrelated to Russia. At p = 0.25, the top words
for all four languages are related to Russia.
These results demonstrate that PLTM is appro-
priate for aligning topics in corpora that have only
a small subset of comparable documents. One area
for future work is to explore whether initializa-
tion techniques or better representations of topic
co-occurrence might result in alignment of topics
with a smaller proportion of comparable texts.
4.5 Machine Translation
Although the PLTM is clearly not a substitute for
a machine translation system?it has no way to
represent syntax or even multi-word phrases?it is
clear from the examples in figure 2 that the sets of
high probability words in different languages for a
given topic are likely to include translations. We
therefore evaluate the ability of the PLTM to gen-
erate bilingual lexica, similar to other work in un-
supervised translation modeling (Haghighi et al,
2008). In the early statistical translation model
work at IBM, these representations were called
?cepts,? short for concepts (Brown et al, 1993).
We evaluate sets of high-probability words in
each topic and multilingual ?synsets? by compar-
ing them to entries in human-constructed bilingual
dictionaries, as done by Haghighi et al (2008).
Unlike previous work (Koehn and Knight, 2002),
we evaluate all words, not just nouns. We col-
lected bilingual lexica mapping English words to
German, Greek, Spanish, French, Italian, Dutch
and Swedish. Each lexicon is a set of pairs con-
sisting of an English word and a translated word,
{w
e
, w
`
}. We do not consider multi-word terms.
We expect that simple analysis of topic assign-
ments for sequential words would yield such col-
locations, but we leave this for future work.
For every topic t we select a small number K
of the most probable words in English (e) and
in each ?translation? language (`): W
te
and W
t`
,
respectively. We then add the Cartesian product
of these sets for every topic to a set of candidate
translations C. We report the number of elements
of C that appear in the reference lexica. Results
for K = 1, that is, considering only the single
most probable word for each language, are shown
in figure 6. Precision at this level is relatively
high, above 50% for Spanish, French and Italian
with T = 400 and 800. Many of the candidate
pairs that were not in the bilingual lexica were
valid translations (e.g. EN ?comitology? and IT
885
?comitalogia?) that simply were not in the lexica.
We also do not count morphological variants: the
model finds EN ?rules? and DE ?vorschriften,? but
the lexicon contains only ?rule? and ?vorschrift.?
Results remain strong as we increase K. With
K = 3, T = 800, 1349 of the 7200 candidate
pairs for Spanish appeared in the lexicon.
l l
l
l
l
200 400 600 800
0
100
200
300
400
500
Translation pairs at K=1
Topics
Corr
ect t
rans
lation
s
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
ESFRITDESVEL
Figure 6: Are the single most probable words for a given
topic in different languages translations of each other? The
number of such pairs that appear in bilingual lexica is shown
on the y-axis. For T = 800, the top English and Spanish
words in 448 topics were exact translations of one another.
4.6 Finding Translations
In addition to enhancing lexicons by aligning
topic-specific vocabulary, PLTM may also be use-
ful for adapting machine translation systems to
new domains by finding translations or near trans-
lations in an unstructured corpus. These aligned
document pairs could then be fed into standard
machine translation systems as training data. To
evaluate this scenario, we train PLTM on a set of
document tuples from EuroParl, infer topic distri-
butions for a set of held-out documents, and then
measure our ability to align documents in one lan-
guage with their translations in another language.
It is not necessarily clear that PLTM will be ef-
fective at identifying translations. In finding a low-
dimensional semantic representation, topic mod-
els deliberately smooth over much of the varia-
tion present in language. We are therefore inter-
ested in determining whether the information in
the document-specific topic distributions is suffi-
cient to identify semantically identical documents.
We begin by dividing the data into a training
set of 69,550 document tuples and a test set of
17,435 document tuples. In order to make the task
more difficult, we train a relatively coarse-grained
PLTM with 50 topics on the training set. We then
use this model to infer topic distributions for each
40
50
60
70
80
90
100
Min query doc length
% o
f tra
nsl 
at r
ank
0 50 100 200
Rank 1
Rank 5
Rank 10
Rank 20
Figure 7: Percent of query language documents for which
the target language translation is ranked at or above 1, 5, 10
or 20 by JS divergence, averaged over all language pairs.
of the 11 documents in each of the held-out doc-
ument tuples using a method similar to that used
to calculate held-out probabilities (Wallach et al,
2009). Finally, for each pair of languages (?query?
and ?target?) we calculate the difference between
the topic distribution for each held-out document
in the query language and the topic distribution for
each held-out document in the target language. We
use both Jensen-Shannon divergence and cosine
distance. For each document in the query language
we rank all documents in the target language and
record the rank of the actual translation.
Results averaged over all query/target language
pairs are shown in figure 7 for Jensen-Shannon
divergence. Cosine-based rankings are signifi-
cantly worse. It is important to note that the
length of documents matters. As noted before,
many of the documents in the EuroParl collection
consist of short, formulaic sentences. Restrict-
ing the query/target pairs to only those with query
and target documents that are both longer than 50
words results in significant improvement and re-
duced variance: the average proportion of query
documents for which the true translation is ranked
highest goes from 53.9% to 72.7%. Performance
continues to improve with longer documents, most
likely due to better topic inference. Results vary
by language. Table 5 shows results for all tar-
get languages with English as a query language.
Again, English generally performs better with Ro-
mance languages than Germanic languages.
5 Results on Comparable Texts
Directly parallel translations are rare in many lan-
guages and can be extremely expensive to pro-
duce. However, the growth of the web, and in par-
ticular Wikipedia, has made comparable text cor-
886
CY
DE
EL
EN
FA
FI
FR
HE
IT
PL
RU
TR
CY
DE
EL
EN
FA
FI
FR
HE
IT
PL
RU
TR
CY
DE
EL
EN
FA
FI
FR
HE
IT
PL
RU
TR
Figure 8: Squares represent the proportion of tokens in each language assigned to a topic. The left topic, world ski km won,
centers around Nordic counties. The center topic, actor role television actress, is relatively uniform. The right topic, ottoman
empire khan byzantine, is popular in all languages but especially in regions near Istanbul.
Table 5: Percent of English query documents for which the
translation was in the top n ? {1, 5, 10, 20} documents by JS
divergence between topic distributions. To reduce the effect
of short documents we consider only document pairs where
the query and target documents are longer than 100 words.
Lang 1 5 10 20
DA 78.0 90.7 93.8 95.8
DE 76.6 90.0 93.4 95.5
EL 77.1 90.4 93.3 95.2
ES 81.2 92.3 94.8 96.7
FI 76.7 91.0 94.0 96.3
FR 80.1 91.7 94.3 96.2
IT 79.1 91.2 94.1 96.2
NL 76.6 90.1 93.4 95.5
PT 80.8 92.0 94.7 96.5
SV 80.4 92.1 94.9 96.5
pora ? documents that are topically similar but are
not direct translations of one another ? consider-
ably more abundant than true parallel corpora.
In this section, we explore two questions re-
lating to comparable text corpora and polylingual
topic modeling. First, we explore whether com-
parable document tuples support the alignment of
fine-grained topics, as demonstrated earlier using
parallel documents. This property is useful for
building machine translation systems as well as
for human readers who are either learning new
languages or analyzing texts in languages they do
not know. Second, because comparable texts may
not use exactly the same topics, it becomes cru-
cially important to be able to characterize differ-
ences in topic prevalence at the document level (do
different languages have different perspectives on
the same article?) and at the language-wide level
(which topics do particular languages focus on?).
5.1 Data Set
We downloaded XML copies of all Wikipedia ar-
ticles in twelve different languages: Welsh, Ger-
man, Greek, English, Farsi, Finnish, French, He-
brew, Italian, Polish, Russian and Turkish. These
versions of Wikipedia were selected to provide a
diverse range of language families, geographic ar-
eas, and quantities of text. We preprocessed the
data by removing tables, references, images and
info-boxes. We dropped all articles in non-English
languages that did not link to an English article. In
the English version of Wikipedia we dropped all
articles that were not linked to by any other lan-
guage in our set. For efficiency, we truncated each
article to the nearest word after 1000 characters
and dropped the 50 most common word types in
each language. Even with these restrictions, the
size of the corpus is 148.5 million words.
We present results for a PLTM with 400 topics.
1000 Gibbs sampling iterations took roughly four
days on one CPU with current hardware.
5.2 Which Languages Have High Topic
Divergence?
As with EuroParl, we can calculate the Jensen-
Shannon divergence between pairs of documents
within a comparable document tuple. We can then
average over all such document-document diver-
gences for each pair of languages to get an over-
all ?disagreement? score between languages. In-
terestingly, we find that almost all languages in
our corpus, including several pairs that have his-
torically been in conflict, show average JS diver-
gences of between approximately 0.08 and 0.12
for T = 400, consistent with our findings for
EuroParl translations. Subtle differences of sen-
timent may be below the granularity of the model.
887
sadwrn blaned gallair at lloeren mytholeg 
space nasa sojus flug mission 
?????????? sts nasa ???? small 
space mission launch satellite nasa spacecraft 
??????? ??????? ???? ???? ??????? ?????  
sojuz nasa apollo ensimm?inen space lento 
spatiale mission orbite mars satellite spatial 
?????? ? ???? ??? ???? ????  
spaziale missione programma space sojuz stazione 
misja kosmicznej stacji misji space nasa 
??????????? ???? ???????????? ??????? ???????
uzay soyuz ay uzaya salyut sovyetler 
sbaen madrid el la jos? sbaeneg 
de spanischer spanischen spanien madrid la 
???????? ??????? de ??????? ??? ??????? 
de spanish spain la madrid y 
?????? ???? ????????? ???????  de ????  
espanja de espanjan madrid la real 
espagnol espagne madrid espagnole juan y 
???? ??????? ????? ?? ?????? ????  
de spagna spagnolo spagnola madrid el 
de hiszpa?ski hiszpanii la juan y 
?? ?????? ??????? ??????? ????????? de 
ispanya ispanyol madrid la k?ba real 
bardd gerddi iaith beirdd fardd gymraeg 
dichter schriftsteller literatur gedichte gedicht werk 
??????? ?????? ?????? ???? ??????? ???????? 
poet poetry literature literary poems poem 
???? ???? ????? ?????? ??? ????  
runoilija kirjailija kirjallisuuden kirjoitti runo julkaisi 
po?te ?crivain litt?rature po?sie litt?raire ses 
?????? ????? ???? ???? ????? ?????
poeta letteratura poesia opere versi poema 
poeta literatury poezji pisarz in jego 
???? ??? ???????? ?????????? ?????? ????????? 
?air edebiyat ?iir yazar edebiyat? adl? 
CY
DE
EL
EN
FA
FI
FR
HE
IT
PL
RU
TR
 
CY
DE
EL
EN
FA
FI
FR
HE
IT
PL
RU
TR
 
CY
DE
EL
EN
FA
FI
FR
HE
IT
PL
RU
TR
Figure 9: Wikipedia topics (T=400).
Overall, these scores indicate that although indi-
vidual pages may show disagreement, Wikipedia
is on average consistent between languages.
5.3 Are Topics Emphasized Differently
Between Languages?
Although we find that if Wikipedia contains an ar-
ticle on a particular subject in some language, the
article will tend to be topically similar to the arti-
cles about that subject in other languages, we also
find that across the whole collection different lan-
guages emphasize topics to different extents. To
demonstrate the wide variation in topics, we cal-
culated the proportion of tokens in each language
assigned to each topic. Figure 8 represents the es-
timated probabilities of topics given a specific lan-
guage. Competitive cross-country skiing (left) ac-
counts for a significant proportion of the text in
Finnish, but barely exists in Welsh and the lan-
guages in the Southeastern region. Meanwhile,
interest in actors and actresses (center) is consis-
tent across all languages. Finally, historical topics,
such as the Byzantine and Ottoman empires (right)
are strong in all languages, but show geographical
variation: interest centers around the empires.
6 Conclusions
We introduced a polylingual topic model (PLTM)
that discovers topics aligned across multiple lan-
guages. We analyzed the characteristics of PLTM
in comparison to monolingual LDA, and demon-
strated that it is possible to discover aligned top-
ics. We also demonstrated that relatively small
numbers of topically comparable document tu-
ples are sufficient to align topics between lan-
guages in non-comparable corpora. Additionally,
PLTM can support the creation of bilingual lexica
for low resource language pairs, providing candi-
date translations for more computationally intense
alignment processes without the sentence-aligned
translations typically used in such tasks. When
applied to comparable document collections such
as Wikipedia, PLTM supports data-driven analysis
of differences and similarities across all languages
for readers who understand any one language.
7 Acknowledgments
The authors thank Limin Yao, who was involved
in early stages of this project. This work was
supported in part by the Center for Intelligent In-
formation Retrieval, in part by The Central In-
telligence Agency, the National Security Agency
and National Science Foundation under NSF grant
number IIS-0326249, and in part by Army prime
contract number W911NF-07-1-0216 and Uni-
versity of Pennsylvania subaward number 103-
548106, and in part by National Science Founda-
tion under NSF grant #CNS-0619337. Any opin-
ions, findings and conclusions or recommenda-
tions expressed in this material are the authors?
and do not necessarily reflect those of the sponsor.
References
David Blei and Michael Jordan. 2003. Modeling an-
notated data. In SIGIR.
David Blei, Andrew Ng, and Michael Jordan. 2003.
Latent Dirichlet alocation. JMLR.
Peter F Brown, Stephen A Della Pietra, Vincent J Della
Pietra, and Robert L Mercer. 1993. The mathemat-
ics of statistical machine translation: Parameter esti-
mation. CL, 19(2):263?311.
888
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In ACL, pages 771?779.
David Hall, Daniel Jurafsky, and Christopher D. Man-
ning. 2008. Studying the history of ideas using
topic models. In EMNLP.
Mariko Kawaba, Hiroyuki Nakasaki, Takehito Utsuro,
and Tomohiro Fukuhara. 2008. Cross-lingual blog
analysis based on multilingual blog distillation from
multilingual Wikipedia entries. In ICWSM.
Philipp Koehn and Kevin Knight. 2002. Learn-
ing a translation lexicon from monolingual corpora.
In Proceedings of ACL Workshop on Unsupervised
Lexical Acquisition.
Gideon Mann, David Mimno, and Andrew McCal-
lum. 2006. Bibliometric impact measures leverag-
ing topic analysis. In JCDL.
Andrew McCallum, Andr?es Corrada-Emmanuel, and
Xuerui Wang. 2005. Topic and role discovery in
social networks. In IJCAI.
Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.
2009. Mining multilingual topics from Wikipedia.
In WWW.
Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007.
Bilingual LSA-based adaptation for statistical ma-
chine translation. Machine Translation, 28:187?
207.
Hanna Wallach, Iain Murray, Ruslan Salakhutdinov,
and David Mimno. 2009. Evaluation methods for
topic models. In ICML.
Xing Wei and Bruce Croft. 2006. LDA-based docu-
ment models for ad-hoc retrieval. In SIGIR.
Bing Zhao and Eric P. Xing. 2007. HM-BiTAM: Bilin-
gual topic exploration, word alignment, and transla-
tion. In NIPS.
889
