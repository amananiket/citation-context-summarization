Optimizing Synonym Extraction Using Monolingual and Bilingual 
Resources 
Hua WU, Ming ZHOU 
Microsoft Research Asia 
5F Sigma Center, No.49 Zhichun Road, Haidian District 
Beijing, 100080, China 
wu_hua_@msn.com, mingzhou@microsoft.com 
Abstract 
Automatically acquiring synonymous words 
(synonyms) from corpora is a challenging task. 
For this task, methods that use only one kind 
of resources are inadequate because of low 
precision or low recall. To improve the per-
formance of synonym extraction, we propose 
a method to extract synonyms with multiple 
resources including a monolingual dictionary, 
a bilingual corpus, and a large monolingual 
corpus. This approach uses an ensemble to 
combine the synonyms extracted by individ-
ual extractors which use the three resources. 
Experimental results prove that the three re-
sources are complementary to each other on 
synonym extraction, and that the ensemble 
method we used is very effective to improve 
both precisions and recalls of extracted 
synonyms. 
1 Introduction 
This paper addresses the problem of extracting 
synonymous English words (synonyms) from 
multiple resources: a monolingual dictionary, a 
parallel bilingual corpus, and a monolingual cor-
pus. The extracted synonyms can be used in a 
number of NLP applications. In information re-
trieval and question answering, the synonymous 
words are employed to bridge the expressions 
gaps between the query space and the document 
space (Mandala et al, 1999; Radev et al, 2001; 
Kiyota et al, 2002). In automatic text summari-
zation, synonymous words are employed to iden-
tify repetitive information in order to avoid re-
dundant contents in a summary (Barzilay and 
Elhadad, 1997). In language generation, syno-
nyms are employed to create more varied texts 
(Langkilde and Knight, 1998).  
Up to our knowledge, there are few studies in-
vestigating the combination of different resources 
for synonym extraction. However, many studies 
investigate synonym extraction from only one 
resource. The most frequently used resource for 
synonym extraction is large monolingual corpora 
(Hindle, 1990; Crouch and Yang, 1992; Grefen-
statte, 1994; Park and Choi, 1997; Gasperin et al, 
2001 and Lin, 1998). The methods used the con-
texts around the investigated words to discover 
synonyms. The problem of the methods is that the 
precision of the extracted synonymous words is 
low because it extracts many word pairs such as 
?cat? and ?dog?, which are similar but not syn-
onymous.  
Other resources are also used for synonym ex-
traction. Barzilay and Mckeown (2001), and Shi-
mohata and Sumita (2002) used bilingual corpora 
to extract synonyms. However, these methods can 
only extract synonyms which occur in the bilingual 
corpus. Thus, the extracted synonyms are limited. 
Besides, Blondel and Sennelart (2002) used mono-
lingual dictionaries to extract synonyms. Although 
the precision of this method is high, the coverage is 
low because the result of this method heavily de-
pends on the definitions of words. 
In order to improve the performance of syno-
nym extraction, Curran (2002) used an ensemble 
method to combine the results of different methods 
using a monolingual corpus. Although Curran 
(2002) showed that the ensemble extractors out-
performed the individual extractors, it still cannot 
overcome the deficiency of the methods using the 
monolingual corpus. 
To overcome the deficiencies of the methods 
using only one resource, our approach combines 
both monolingual and bilingual resources to auto-
matically extract synonymous words. By combin-
ing the synonyms extracted by the individual ex-
tractors using the three resources, our approach can 
combine the merits of the individual extractors to 
improve the performance of synonym extraction. 
In fact, our approach can be considered as an 
ensemble of different resources for synonym 
extraction. Experimental results prove that the 
three resources are complementary to each other 
on synonym extraction, and that the ensemble 
method we used is very effective to improve both 
precisions and recalls of extracted synonyms. 
The remainder of this paper is organized as 
follows. The next section presents our approach 
for synonym extraction. Section 3 describes an 
implementation of the three individual extractors. 
Section 4 presents the evaluation results. Section 5 
discusses our method. In the last section, we draw 
the conclusions of this work. 
2 Our Approach 
Instead of using only one kind of resource to 
extract synonyms, we combine both monolingual 
and bilingual resources for synonym extraction. 
The resources include a monolingual dictionary, 
an English-Chinese bilingual corpus, and a large 
corpus of monolingual documents. Before com-
bining them, we first propose three methods to 
extract synonyms from the three resources. Espe-
cially, a novel method is proposed to increase the 
coverage of the extracted synonyms using the 
bilingual corpus. Next, we develop an ensemble 
method to combine the individual extractors. The 
advantage of our approach is that it can combine 
the merits of the individual extractors to improve 
the precision and recalls of the extracted syno-
nyms. 
2.1 Synonym Extraction with a Monolin-
gual Dictionary 
This section proposes a method to extract syno-
nyms from a monolingual dictionary. In a mono-
lingual dictionary, each entry is defined by other 
words and may also be used in the definitions for 
other words. For a word in the dictionary, the 
words used to define it are called hubs and the 
words whose definitions include this word are 
called authorities as in (Blondel and Sennelart, 
2002). We use the hubs and authorities of a word 
to represent its meaning. The assumption behind 
this method is that two words are similar if they 
have common hubs and authorities. In this paper, 
we only use content words as members of hubs and 
authorities. 
We take these hubs and authorities as features of 
a word. The vector constructed with them is re-
ferred to as the feature vector of a word. The simi-
larity between two words is calculated through 
their feature vectors with the cosine measure as 
shown in Equation (1).  


=
=
=
j
j
i
i
ww
ji
vv
vv
FFwwsim
ji
2
2
2
1
21
21211
*
)*(
),cos(),(
21      
(1) 
where 
 ),( ... ),,( ),,( 2211 >=< imimiiiii vwvwvwF  
Fi is the feature vector of wi; 
1=ijv if word ijw is a hub or an authority of the 
word wi; else, 0=ijv ; 
2.2 Synonym Extraction with a Bilingual 
Corpus 
This section proposes a novel method to extract 
synonyms from a bilingual corpus. It uses the 
translations of a word to express its meaning. The 
assumption of this method is that two words are 
synonymous if their translations are similar.  
Given an English word, we get their translations 
with an English-Chinese bilingual dictionary. Each 
translation is assigned a translation probability, 
which is trained with a bilingual English-Chinese 
corpus based on the result of word alignment. The 
aligner use the model described in (Wang et al, 
2001). In order to deal with the problem of data 
sparseness, we conduct a simple smoothing by 
adding 0.5 to the counts of each translation pair as 
in (2).  
|_|*5.0)(
5.0),()|(
ctransecount
eccount
ecp
+
+
=       (2) 
where 
),( eccount  represents the co-occurring fre-
quency of the Chinese word c and the English 
word e in the sentence pairs. 
)(ecount  represents the frequency of the English 
word e occurring in the bilingual corpus. 
|_| ctrans  represents the number of Chinese 
translations for a given English word e.  
The translations and the translation probabili-
ties of a word are used to construct its feature 
vector. The similarity of two words is estimated 
through their feature vectors with the cosine 
measure as shown in (3).    


=
=
=
j
j
i
i
cc
ji
pp
pp
FFwwsim
ji
2
2
2
1
21
21212
*
)*(
),cos(),(
21              (3) 
where  
 ),( ... ),,( ),,( 2211 >=< imimiiiii pcpcpcF  
Fi is the feature vector of wi; 
ijc is the jth Chinese translation of the word wi; 
ijp is the translation probability of the word wi 
is translated into ijc  
For example, the feature vectors of two words 
? abandon?  and ? forsake?  are: 
forsake: < ( , 0.1333),  ( , 0.1333),  ( , 
0.0667) ( , 0.0667), ( , 0.0667), ?> 
abandon:  <( , 0.3018), ( , 0.1126), ( , 
0.0405), ( , 0.0225), ( , 0.0135),?>  
2.3 Synonym Extraction with a Monolin-
gual Corpus 
The context method described in Section 1 is also 
used for synonym extraction from large mono-
lingual corpora of documents. This method relies 
on the assumption that synonymous words tend to 
have similar contexts. In this paper, we use the 
words which have dependency relationships with 
the investigated word as contexts. The contexts are 
obtained by parsing the monolingual documents. 
The parsing results are represented by dependency 
triples which are denoted as <w1, Relation Type, 
w2>. For example, the sentence ? I declined the 
invitation?  is transformed into three triples after 
parsing: <decline, SUBJ, I>, <decline, OBJ, invi-
tation> and <invitation, DET, the>.  If we name 
<Relation Type, w2> as an attribute of the word w1,  
the verb ? decline?  in the above sentence has two 
attributes <OBJ, invitation> and <SUBJ, I> . Thus, 
the contexts of a word can be expressed using its 
attributes. In this case, two words are synonymous 
if they have similar attributes. 
We use a weighted version of the Dice measure 
to calculate the similarity of two words.  
),(),(
)),(),((
),(
2)2(
1)1(
21)2()1(
213
j
wAjatt
i
wAiatt
kk
wAwAkatt
attwWattwW
attwWattwW
wwsim
??
?
+
+
=

   (4) 
where  
kji attattatt  , ,  stands for  attributes of  words. 
),( ji attwW indicates the association strength 
between the attribute attj with the word iw . 
)( iwA denotes the attribute set of the word iw . 
The measure used to measure the association 
strength between a word and its attributes is 
weighted mutual information (WMI) (Fung and 
Mckeown, 1997) as described in (5). 
)()(
),(
log*),(
),(),(
ji
ji
ji
jiji
attpwp
attwp
attwp
attwWMIattwW
?
=
=
                 (5) 
where 
N
wcount
wp ii
,*,*)()( =
 
N
wrcount
attp j
),(*,)( =
, 
),( wratt j =
 
),(*, wrcount : frequency of the triples having 
dependency relation r with the word w. 
,*,*)( iwcount : frequency of the triples including 
word iw . 
N: number of triples in the corpus. 
We use it instead of point-wise mutual information 
in Lin (1998) because the latter tends to overesti-
mate the association between two parts with low 
frequencies. Weighted mutual information melio-
rates this effect by adding ),( ji attwp .  
2.4 Combining the Three Extractors 
In terms of combining the outputs of the different 
methods, the ensemble method is a good candidate. 
Originally, the ensemble method is a machine 
learning technique of combining the outputs of 
several classifiers to improve the classification 
performance (Dietterich, 2000). It has been suc-
cessfully used in many NLP tasks. For example, 
(Curran, 2002) proved that the ensembles of indi-
vidual extractors using different contexts in the 
monolingual corpus improve the performance of 
synonym extraction.  
 In fact, we can consider the extractors in the 
previous sections as binary classifiers. Thus, we 
use the ensemble method to combine the output of 
the individual extractors described in the previous 
sections for synonym extraction. The method is 
described in Equation (6). 
)),((),(
3
1
2121 
=
?=
i
ii wwsimawwsim             (6) 
where 
 3) 2, 1,(i ),( 21 =wwsim i stands for the different 
similarity measure using different resources 
described in the previous sections. 
)1 and ,3 ,2 ,1(
i
 == ii aia is the weight for the 
individual extractors. 
The reasons that we use the weighted ensemble 
method are as follows: (1) If the majority of three 
extractors select the same word as a synonym of a 
investigated word, it tend to be a real synonym. 
This method can ensure it has a high similarity 
score. Thus, it will improve the precision of the 
extracted synonyms. (2) With this method, it can 
improve the coverage of the extracted synonyms. 
This is because if the similarity score of a candi-
date with the investigated word is higher than a 
threshold, our method can select the candidate as a 
synonym even though it is only suggested by one 
extractor.  
3 Implementation of Individual 
Extractors 
For the extractor employing a monolingual dic-
tionary, we use the same online dictionary as in 
(Blondel and Sennelart, 2002), which is named the 
Online Plain Text Dictionary. The dictionary 
consists of 27 HTML files, which is available 
from the web site http://www.gutenberg.net/. With 
the method described in Section 2.1, the result for 
the extracted synonyms is shown in Table 1 when 
the similarity threshold is set to 0.04. An example 
is shown as follows: 
acclimatize: 
 (acclimate, 0.1481;  habituate, 0.0976) 
The numbers in the example are the similarity 
scores of two words.  
Table 1. Synonyms Extracted from the Monolingual 
Dictionary 
Category # Entries # Average 
Synonyms 
Noun 16963 4.7 
Verb 5084 7.1 
For synonym extraction from the bilingual 
corpus, we use an English-Chinese lexicon, which 
includes 219,404 English words with each source 
word having 3 translations on average. The word 
translation probabilities are estimated from a bi-
lingual corpus that obtains 170,025 pairs of Chi-
nese-English sentences, including about 2.1 million 
English words and about 2.5 million Chinese words. 
With the method described in Section 2.2, we 
extracted synonyms as shown in Table 2 when the 
similarity threshold is set to 0.04. 
Table 2. Synonyms Extracted from the Bilingual 
corpus 
Category #Entries #Average 
Synonyms 
Noun 26253 10.2 
Verb 7364 14.8 
For synonym extraction from a monolingual 
corpus, we use the Wall Street Journal from 1987 to 
1992, the size of which is about 500M bytes. In 
order to get contexts of words, we parse the corpus 
with an English parser ?NLPWIN 1 . From the 
parsing results, we extracted the following four 
types of dependency triples. 
(a) <verb, OBJ, noun> 
(b) <verb, SUBJ, noun> 
(c) <noun, ATTRIB, adjective> 
(d)  <verb, MODS, adjunct> 
The statistics are shown in Table 3. Token 
means the total number of triples in the triple set 
and type means a unique instance of triple in the 
corpus. These triples are used as contexts of words 
to calculate the similarity between words as de-
scribed in Section 2.3. The result is shown in Table 
4 when the similarity threshold is set to 0.1. 
                                                     
1
 The NLPWIN parser is developed at Microsoft Re-
search. Its output can be a phrase structure parse tree or a 
logical form which is represented with dependency 
triples. 
Table 3. Statistics for Triples 
 # Token # Type 
OBJ 7,041,382 1,487,543 
SUBJ 7,180,572 2,116,761 
ATTRIB 4,976,822 1,393,188 
MODS 3,557,737 94,004 
Total 22,756,512 5,937,496 
Table 4. Synonyms Extracted from the Monolingual 
Corpus 
Category Entries Average 
Synonyms 
Noun 16963 4.6 
Verb 5084 7.1 
4 Evaluation  
4.1 The Gold Standard 
The simplest evaluation measure is direct com-
parison of the extracted synonyms with the manu-
ally created thesaurus. However, the thesaurus 
coverage is a problem. In this paper, we combined 
two thesauri as a gold stardard: WordNet 1.6 
http://www.cogsci.princeton.edu/~wn/) and Roget 
(Roget?s II: The New Thesaurus, 1995. 
http://www.bartleby.com/thesauri/).  
In WordNet, one synset consists of several 
synonyms which represent a single sense. There-
fore, a polysemous word occurs in more than one 
synsets. For example, the polysemous word 
? abandon?  occur in five different synsets: 
(abandon,  forsake,  desolate,  desert,  lurch)  
(vacate,  empty,  abandon)  
(abandon,  give up, give) 
(abandon,  give up) 
(abandon) 
For a given word, we combine its synonyms from 
all synsets including the word. Thus, we get the 
synonyms of the word ? abandon?  as follows: 
abandon forsake, desolate, desert, lurch, vacate, 
empty, give up, give 
For synonyms in Roget, we also combine the 
synonyms in different synsets into one set as we 
do for WordNet. Thus, we get the synonyms of the 
word ? abandon? as follows: 
abandonbreak off, desist, discontinue, give up, leave 
off, quit, relinquish, remit, stop, desert, forsake, leave, 
throw over, abdicate, cede, demit, forswear, hand over, 
quitclaim, render, renounce, resign, surrender, waive, 
yield, give over, forgo, lay down  
Combining the results of WordNet and Roget, 
we can get the synonyms of the word ? abandon?  as 
follows. 
abandon desolate, lurch, vacate, empty, give, abdicate, 
break off, cede, demit, desert, desist, discontinue, forgo, 
forsake, forswear, give up, give over, hand over, lay 
down, lay off, leave off, leave, quit, quitclaim, relinquish, 
remit, stop, swear off, throw over, render, renounce, 
resign, surrender, waive, yield 
4.2 Evaluation Measures 
The evaluation metrics are precision, recall, and 
f-measure. If we use S to indicate the synonyms 
that our method extracts for a word and GS  to 
denote the synonyms of the word in WordNet and 
Roget, the methods to calculate the precision, recall, 
and f-measure of our methods are shown in Equa-
tion (7), (8), and (9). To investigate the results of 
more than one word, we calculate the average 
precision, recall and f-measure, which sum the 
individual values divided by the number of the 
investigated words. 
|S|
|SS| G?
=precision          (7) 
|S|
 |SS|
G
G?
=recall        (8) 
recallprecision
recallprecision2
measure-f
+
??
=
 
(9) 
4.3 Test Set 
In order to evaluate our methods, we build up a test 
set which includes three parts: 
(a) high-frequency words: occurring more than 
100 times;  
(b) middle-frequency words: occurring more than 
10 times and not greater than 100 times; 
(c) low-frequency words: occurring no greater 
than 10 times. 
Table 5. Statistics for Nouns and Verbs 
 High Fre-
quency 
Middle 
Frequency 
Low 
Frequency 
Noun 600 2000 1000 
Verb 340 1300 800 
The frequency counts are estimated from Wall 
Street Journal (1987-1992), from which we ran-
domly extracted 3600 nouns and 2440 verbs. These  
Table 6. Evaluation Results for Nouns 
 High-Frequency Nouns Middle-Frequency Nouns Low-Frequency Nouns 
 Pre Rec F Pre Rec F Pre Rec F 
1 0.174 0.140 0.155 0.212 0.137 0.167 0.198 0.119 0.149 
2 0.225 0.209 0.217 0.242 0.212 0.226 0.207 0.212 0.209 
3 0.118 0.109 0.114 0.117 0.104 0.109 0.099 0.096 0.098 
1+2+3 0.240 0.201 0.219 0.271 0.220 0.243 0.222 0.232 0.227 
Table 7. Evaluation Results for Verbs 
 High-Frequency Verbs Middle-Frequency Verbs Low-Frequency Verbs 
 Pre Rec F Pre Rec F Pre Rec F 
1 0.228 0.243 0.235 0.272 0.233 0.251 0.209 0.216 0.212 
2 0.226 0.312 0.262 0.224 0.292 0.253 0.184 0.275 0.220 
3 0.143 0.166 0.154 0.162 0.127 0.142 0.128 0.135 0.132 
1+2+3 0.295 0.323 0.308 0.311 0.304 0.307 0.238 0.302 0.266 
Note: 1, 2, and 3 represent the extractor using the monolingual dictionary, the bilingual corpus, and the monolingual 
corpus respectively. The symbols ? Pre? , ? Rec? , and ? F?  represent precision, recall, and f-measure scores. 
 
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0 0.1 0.2 0.3 0.4 0.5
Recall
Pr
ec
isi
o
n
2 1 3 1+2+3
 
Figure 1. Recall-Precision curves for nouns 
 
Figure 2. Recall-Precision curves for verbs 
 
words have synonyms both in our results extracted 
from the three resources and in the thesauri 
WordNet and Roget. The statistics of the test set 
are shown in Table 5. 
4.4 Experimental  Results 
In this section, we compare the extracted syno-
nyms of the nouns and verbs in the test set with 
those in WordNet and Roget. For each method, we 
select those as synonyms whose similarity scores 
with the investigated word are larger than a given 
threshold. A development set is used to determine 
the thresholds of each method. The thresholds for 
getting highest f-measure scores on the develop-
ment set are selected. In our experiments, we get 
0.04, 0.04, 0.1 and 0.04 for Method 1, Method 2, 
Method 3 and the combined approach, respectively. 
The evaluation results for the individual extractors 
and the ensemble extractor are shown in Table 6 
and Table 7.  We set a1=0.4, a2=0.4 and a3=0.2 in 
Equation (6) for the ensemble to combine the re-
sults from the three resources. The weights are also 
obtained with the development set. 
In order to examine the performance of each 
method in more details, we also get the precisions 
and recalls under different thresholds. Figure 1 and 
Figure 2 shows the precision values under different 
recall values (different thresholds) for all nouns and 
verbs, respectively. 
Among all of the methods, the method com-
bining all of the three resources gets the best results 
in terms of both precision and recall. The effect is 
similar to the ensemble methods for synonym 
0 
0.05 
0.1 
0.15 
0.2 
0.25 
0.3 
0.35 
0.4 
0.45 
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
Recall 
Pr
ec
isi
o
n
 
2 1 3 1+2+3 
extraction in (Curran 2002). However, our method 
uses an ensemble of different resources instead of 
one single resource. During the experiments, we 
also find the ensemble combining all of the three 
extractors outperforms the ensembles only com-
bining any two of the three extractors. This indi-
cates that the extractors using the three different 
resources are complementary to each other. For 
example, the extractor using the monolingual 
dictionary gets a high precision and the extractor 
using the bilingual corpus gets a high recall. Al-
though the extractor using the monolingual corpus 
achieved much lower precision and recall on 
synonym extraction, it is still useful to be included 
in the ensemble.  This shows that the monolingual 
corpus is complementary to the other two re-
sources on synonym extraction.  The success of 
our method also indicates that our ensemble 
method by weighting all extractors is effective for 
synonym extraction. 
Among the methods only using one kind of 
resource, Method 2, which uses the bilingual 
corpus, has the highest f-measure scores on both 
nouns and verbs. From the results in Figure 1 and 
Figure 2, we can see that the coverage of syno-
nyms extracted by Method 2 is the highest. Al-
though it has lower precisions than Method 1 
under low recalls, its precisions are higher than 
those of Method 1 under higher recalls. This 
shows that Method 2 can get a good compromise 
between precision and recall. We also note that the 
maximum recall of Method 2 is much larger than 
that of Method 1. This is because (1) in Method 1, 
the words used in the definitions are highly limited. 
Thus, the coverage of the synonyms is limited; (2) 
the advantage of Method 2 is that the coverage of 
extracted synonyms is high because it can extract 
the synonyms not occurring in the corpus. It is 
different from the method in (Barzilay and 
Mckeown, 2001; Shimohata and Sumita, 2002), 
which can only extract the synonyms in the bi-
lingual corpus. 
The performance of Method 3 is the worst. It is 
caused by two factors: (1) the context model of 
Method 3 introduces much noise because of the 
errors of the parser; (2) this method is unable to 
distinguish synonyms, antonyms, and similar 
words because they tend to have similar contexts. 
From the contexts it uses, method 3 is suitable to 
extract related words which have the similar us-
ages from the view of syntax. 
5 Discussions 
This paper uses three different methods and re-
sources for synonym extraction. By using the cor-
pus-based method, we can get some synonyms or 
near synonyms which can not be found in the 
hand-built thesauri. For Example: ? handspring  
handstand? , ? audiology   otology? , ? roisterer 
 carouser?  and ? parmesan  gouda? . These 
kinds of synonyms are difficult for hand-built 
thesauri to cover because they occur too infrequent 
to be caught by humans. In addition, this cor-
pus-based method can get synonyms in specific 
domains while the general thesauri don?t provide 
such fine-grained knowledge. 
Comparing the results with the human-built 
thesauri is not the best way to evaluate synonym 
extraction because the coverage of the human-built 
thesaurus is also limited. However, manually 
evaluating the results is time consuming. And it 
also cannot get the precise evaluation of the ex-
tracted synonyms. Although the human-built 
thesauri cannot help to precisely evaluate the re-
sults, they can still be used to detect the effective-
ness of extraction methods. 
Conclusion 
This paper proposes a new method to extract 
synonyms from three resources: a monolingual 
dictionary, a bilingual corpus, and a large mono-
lingual corpus. This method uses a weighted en-
semble to combine all of the results of the indi-
vidual extractors using one of the three resources 
respectively. Experimental results prove that the 
three resources are complementary to each other on 
synonym extraction, and that the ensemble method 
we used is very effective to improve both preci-
sions and recalls when the results are compared 
with the manually-built thesauri WordNet and 
Roget.  
Further, we also propose a new method to ex-
tract synonyms from a bilingual corpus. This 
method uses the translations of a word to represent 
its meaning. The translation probabilities are 
trained with the bilingual corpus. The advantage of 
this method is that it can improve the coverage of 
the extracted synonyms. Experiments indicate that 
this method outperforms the other methods using a 
monolingual corpus or a monolingual dictionary.  
The contribution of this work lies in three as-
pects: (1) develop a method to combine the results 
of individual extractors using the three resources 
on synonym extraction; (2) investigate the per-
formance of the three extraction methods using 
different resources, exposing the merits and de-
merits of each method; (3) propose a new method 
to extract synonyms from a bilingual corpus, 
which greatly improves the coverage of the ex-
tracted synonyms.  
References  
Barzilay R. and Elhadad M. 1997. Using lexical chains 
for text summarization. In proceedings of the ACL 
Workshop on Intelligent Scalable Text Summariza-
tion, pp10-17. 
Barzilay R. and McKeown K. 2001. Extracting Para-
phrases from a Parallel Corpus. In Proc. of 
ACL/EACL. 
Blondel V. D. and Sennelart P. 2002. Automatic ex-
traction of synonyms in a dictionary. In Proc. of the 
SIAM Workshop on Text Mining. 
Crouch C. J. and Yang B. 1992. Experiments in auto-
matic statistical thesaurus construction. In Proc. of 
the 15th Annual International ACM SIGIR confer-
ence on Research and Development in Information 
Retrieval, pp77-88. 
Curran J. 2002 Ensemble Methods for Automatic The-
saurus Extraction. In Proc. of the Conference on 
Empirical Methods in Natural Language Processing. 
pp. 222-229. 
Dietterich T. 2000. Ensemble Methods in Machine 
Learning. In Proc. of the First International Work-
shop on Multiple Classier Systems. pp 1-15. 
Fung P., Mckeown K. 1997. A Technical Word- and 
Term- Translation Aid Using Noisy Parallel Corpora 
across Language Groups. In: Machine Translation, 
Vol.1-2 (special issue), pp53-87. 
Gasperin C., Gamallo P., Agustini A., Lopes G., Lima 
V. 2001 Using Syntactic Contexts for Measuring 
Word Similarity. Workshop on Knowledge Acquisi-
tion & Categorization, ESSLLI.  
Grefenstette G. 1994 Explorations in Automatic The-
saurus Discovery. Kluwer Academic Press. 
Hindle D. 1990. Noun Classification from Predi-
cate-Argument Structure. In Proc. of the 28th Annual 
Meeting of the Association for Computational Lin-
guistics. 
Kiyota Y., Kurohashi S., Kido F. 2002. "Dialog Navi-
gator":  A Question Answering System Based on 
Large Text Knowledge Base.  In Proc. of the 19th 
International Conference on Computational Linguis-
tics. 
Langkilde I. and Knight K. 1998. Generation that Ex-
ploits Corpus-based Statistical Knowledge. In Proc. of 
the COLING-ACL. 
Lin D. 1998 Automatic Retrieval and Clustering of 
Similar Words. In Proc. of the 36th Annual Meeting of 
the Association for Computational Linguistics. 
Mandala R., Tokunaga T. Tanaka H. 1999. Combining 
Multiple Evidence from Different Type of Thesaurus 
for Query Expansion. In Proc. of the 22nd annual in-
ternational ACM SIGIR conference on Research and 
development in information retrieval. 
Park Y.C. and Choi K. S. 1997. Automatic Thesaurus 
Construction Using Baysian Networks.  Information 
Processing & Management. Vol. 32. 
Radev D., Qi H., Zheng Z., Goldensohn S., Zhang Z., 
Fan W., Prager J. 2001. Mining the Web for Answers 
to Natural Language Questions. In the Tenth Interna-
tional ACM Conference on Information and Knowl-
edge Management. 
Shimohata M. and Sumita E. 2002. Automatic Para-
phrasing Based on Parallel Corpus for Normalization. 
In Proc. of the Third International Conference on 
Language Resources and Evaluation. 
Wang W., Huang J., Zhou M., Huang C.N. 2001. Find-
ing Target Language Correspondence for Lexicalized 
EBMT System. In Proc. of the 6th Natural Language 
Processing Pacific Rim Symposium. 
