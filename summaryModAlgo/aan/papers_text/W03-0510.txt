?The?Potential?and?Limitations?of?Automatic?????????????????????????????????????????
Sentence?Extraction?for?Summarization?
Chin-Yew?Lin?and?Eduard?Hovy?
University?of?Southern?California/Information?Sciences?Institute?
4676?Admiralty?Way?
Marina?del?Rey,?CA?90292,?USA?
{cyl,hovy}@isi.edu 
?
?
Abstract?
In?this?paper?we?present?an?empirical?study?of?
the?potential?and?limitation?of?sentence?extrac-
tion? in? text? summarization.?Our? results? show?
that? the? single? document? generic? summariza-
tion?task?as?defined?in?DUC?2001?needs?to?be?
carefully?refocused?as?reflected?in?the? low?in-
ter-human? agreement? at? 100-word 1 ?(0.40?
score)? and? high? upper? bound? at? full? text 2?
(0.88)? summaries.? For? 100-word? summaries,?
the?performance?upper?bound,?0.65,?achieved?
oracle?extracts3.?Such?oracle?extracts?show?the?
promise? of? sentence? extraction? algorithms;?
however,? we? first? need? to? raise? inter-human?
agreement?to?be?able?to?achieve?this?perform-
ance? level.?We? show? that? compression? is? a?
promising?direction? and? that? the? compression?
ratio?of?summaries?affects?average?human?and?
system?performance.?
1? Introduction?
Most? automatic? text? summarization? systems? existing?
today?are?extraction?systems? that?extract?parts?of?origi-
nal? documents? and? output? the? results? as? summaries.?
Among? them,? sentence? extraction? is? by? far? the? most?
???????????????????????????????????????????????????????????
1?We?compute?unigram?co-occurrence?score?of?a?pair?of?man-
ual? summaries,? one? as? candidate? summary? and? the? other? as?
reference.?
2?We?compute?unigram?co-occurrence?scores?of?a?full?text?and?
its?manual?summaries?of?100?words.?These?scores?are?the?best?
achievable? using? the? unigram? co-occurrence? scoring? metric?
since? all?possible?words? are? contained? in? the? full? text.?Three?
manual?summaries?are?used.?
3 ?Oracle? extracts? are? the? best? scoring? extracts? generated? by?
exhaustive? search? of? all? possible? sentence? combinations? of?
100?5?words.??
popular? (Edmundson? 1969,? Luhn? 1969,? Kupiec? et? al.?
1995,?Goldstein? et? al.?1999,?Hovy? and?Lin?1999).?The?
majority?of?systems?participating? in? the?past?Document?
Understanding? Conference? (DUC? 2002),? a? large? scale?
summarization? evaluation? effort? sponsored? by? the? US?
government,? are? extraction? based.? Although? systems?
based?on? information?extraction? (Radev?and?McKeown?
1998,?White?et?al.?2001,?McKeown?et?al.?2002)?and?dis-
course?analysis?(Marcu?1999b,?Strzalkowski?et?al.?1999)?
also?exist,?we?focus?our?study?on?the?potential?and?limi-
tations?of?sentence?extraction?systems?with?the?hope?that?
our?results?will?further?progress?in?most?of?the?automatic?
text?summarization?systems?and?evaluation?setup.?
The?evaluation?results?of?the?single?document?summari-
zation?task?in?DUC?2001?and?2002?(DUC?2002,?Paul?&?
Liggett?2002)?indicate?that?most?systems?are?as?good?as?
the?baseline?lead-based?system?and?that?humans?are?sig-
nificantly?better,?though?not?by?much.?This?leads?to?the?
belief?that?lead-based?summaries?are?as?good?as?we?can?
get? for? single? document? summarization? in? the? news?
genre,? implying? that? the? research? community? should?
invest?future?efforts? in?other?areas.? In?fact,?a?very?short?
summary? of? about? 10? words? (headline-like)? task? has?
replaced? the? single? document? 100-word? summary? task?
in?DUC?2003.?The?goal?of?this?study?is?to?renew?interest?
in? sentence? extraction-based? summarization? and? its?
evaluation?by? estimating? the?performance?upper?bound?
using?oracle?extracts,?and?to?highlight?the?importance?of?
taking? into? account? the? compression? ratio? when? we?
evaluate?extracts?or?summaries.??
Section? 2? gives? an? overview? of?DUC? relevant? to? this?
study.?Section?3? introduces? a? recall-based?unigram? co-
occurrence? automatic?evaluation?metric.?Section?4?pre-
sents?the?experimental?design.?Section?5?shows?the?em-
pirical? results.? Section? 6? concludes? this? paper? and?
discusses?future?directions.?
?2? Document?Understanding?Conference?
Fully? automatic? single-document? summarization? was?
one? of? two?main? tasks? in? the? 2001?Document?Under-
standing?Conference.?Participants?were? required? to?cre-
ate? a? generic? 100-word? summary.? ?There?were? 30? test?
sets? in?DUC?2001?and?each? test?set?contained?about?10?
documents.?For?each?document,?one?summary?was?cre-
ated? manually? as? the? ?ideal?? model? summary? at? ap-
proximately? 100?words.? ?We?will? refer? to? this?manual?
summary? as? H1.? Two? other? manual? summaries? were?
also?created?at?about?that?length.??We?will?refer?to?these?
two?additional?human?summaries?as?H2?and?H3.?In?addi-
tion,?baseline?summaries?were?created?automatically?by?
taking? the? first? n? sentences? up? to? 100?words.?We?will?
refer?this?baseline?extract?as?B1.?
3? Unigram?Co-Occurrence?Metric?
In?a?recent?study?(Lin?and?Hovy?2003),?we?showed?that?
the?recall-based?unigram?co-occurrence?automatic?scor-
ing?metric?correlated?highly?with?human?evaluation?and?
has? high? recall? and? precision? in? predicting? statistical?
significance?of? results?comparing?with? its?human?coun-
terpart.? The? idea? is? to? measure? the? content? similarity?
between?a?system?extract?and?a?manual?summary?using?
simple? n-gram? overlap.? A? similar? idea? called? IBM?
BLEU? score? has? proved? successful? in? automatic? ma-
chine?translation?evaluation?(Papineni?et?al.?2001,?NIST?
2002).?For?summarization,?we?can?express?the?degree?of?
content?overlap? in? terms?of?n-gram?matches?as? the? fol-
lowing?equation:?
)1(
)(
)(
}{
}{
? ?
? ?
? ??
? ??
?
?
=
UnitsModelC Cgramn
UnitsModelC Cgramn
match
n gramnCount
gramnCount
C ?
Model?units? are? segments?of?manual? summaries.?They?
are? typically? either? sentences? or? elementary? discourse?
units?as?defined?by?Marcu? (1999b).?Countmatch(n-gram)?
is? the?maximum? number? of? n-grams? co-occurring? in? a?
system?extract? and? a?model?unit.?Count(n-gram)? is? the?
number? of? n-grams? in? the?model? unit.?Notice? that? the?
average?n-gram? coverage? score,?Cn,? as? shown? in?equa-
tion?1,?is?a?recall-based?metric,?since?the?denominator?of?
equation? 1? is? the? sum? total? of? the? number? of? n-grams?
occurring? in? the?model? summary? instead?of? the? system?
summary?and?only?one?model?summary?is?used?for?each?
evaluation.? In? summary,? the? unigram? co-occurrence?
statistics?we?use? in? the?following?sections?are?based?on?
the?following?formula:?
)2(logexp),( ???
?
???
?
= ?
=
j
in
nn CwjiNgram ?
Where? j??? i,? i? and? j? range? from?1? to?4,?and?wn? is?1/(j-
i+1).?Ngram(1,?4)?is?a?weighted?variable? length?n-gram?
match? score? similar? to? the? IBM? BLEU? score;? while?
Ngram(k,?k),?i.e.?i?=?j?=?k,?is?simply?the?average?k-gram?
co-occurrence?score?Ck.? In? this?study,?we?set? i?=? j?=?1,?
i.e.?unigram?co-occurrence?score.???
With?a?test?collection?available?and?an?automatic?scoring?
metric? defined,?we? describe? the? experimental? setup? in?
the?next?section.?
4? Experimental?Designs?
As? stated? in? the? introduction,?we? aim? to? find? the? per-
formance?upper?bound?of?a? sentence? extraction? system?
and? the?effect?of?compression?ratio?on? its?performance.?
We? present? our? experimental? designs? to? address? these?
questions?in?the?following?sections.?
4.1? Performance? Upper? Bound? Estimation?
Using?Oracle?Extract?
In?order?to?estimate?the?potential?of?sentence?extraction?
systems,?it?is?important?to?know?the?upper?bound?that?an?
ideal? sentence? extraction? method? might? achieve? and?
how? far? the? state-of-the-art? systems? are? away? from? the?
bound.? If? the? upper? bound? is? close? to? state-of-the-art?
systems?? performance? then?we? need? to? look? for? other?
summarization?methods? to? improve?performance.? If? the?
upper? bound? is?much? higher? than? any? current? systems?
can?achieve,?then?it?is?reasonable?to?invest?more?effort?in?
sentence? extraction? methods.? The? question? is? how? to?
estimate? the?performance?upper?bound.?Our? solution? is?
to?cast?this?estimation?problem?as?an?optimization?prob-
lem.? We? exhaustively? generate? all? possible? sentence?
combinations? that?satisfy?given? length?constraints? for?a?
summary,? for? example,? all? the? sentence? combinations?
totaling? 100?5? words.?We? then? compute? the? unigram?
co-occurrence? score? for? each? sentence? combination,?
against? the? ideal.? The? best? combinations? are? the? ones?
with? the?highest?unigram? co-occurrence? score.?We?call?
this? sentence? combination? the? oracle? extract.? Figure? 1?
shows?an?oracle?extract? for?document?AP900424-0035.?
One?of?its?human?summaries?is?shown?in?Figure?2.?The?
oracle? extract? covers? almost? all? aspects? of? the? human?
summary?except?sentences?5?and?6?and?part?of?sentence?
4.?However,?if?we?allow?the?automatic?extract?to?contain?
more?words,?for?example,?150?words?shown?in?Figure?3,?
the? longer?oracle? extract? then? covers? everything? in? the?
human?summary.?This?indicates?that?lower?compression?
can? boost? system? performance.? The? ultimate? effect? of?
compression?can?be?computed?using?the?full?text?as?the?
oracle? extract,? since? the? full? text? should?contain?every-
thing? included? in? the? human? summary.? That? situation?
provides? the? best? achievable? unigram? co-occurrence?
score.?A?near?optimal?score?also?confirms?the?validity?of?
using? the?unigram?co-occurrence? scoring?method?as?an?
automatic?evaluation?method.?
?4.2? Compression?Ratio? and? Its?Effect? on? System?
Performance?
One? important? factor? that? affects? the? average?perform-
ance? of? sentence? extraction? system? is? the? number? of?
sentences? contained? in? the? original? documents.? This?
factor?is?often?overlooked?and?has?never?been?addressed?
systematically.? For? example,? if? a? document? contains?
only?one?sentence?then?this?document?will?not?be?useful?
in?differentiating? summarization? system?performance???
there? is? only? one? choice.?However,? for? a? document? of?
100?sentences?and?assuming?each?sentence? is?20?words?
long,? there? are? C(100,5)? =? 75,287,520? different? 100-
word?extracts.?This?huge?search?space?lowers?the?chance?
of? agreement? between? humans? on? what? constitutes? a?
good? summary.? It? also?makes? system? and? human? per-
formance? approach? average? since? it? is?more? likely? to?
include? some?good? sentences?but?not? all?of? them.?Em-
pirical?results?shown? in?Section?5?confirm? this?and? that?
leads?us?to?the?question?of?how?to?construct?a?corpus?to?
evaluate? summarization? systems.?We?discuss? this? issue?
in?the?conclusion?section.??
4.3? Inter-Human?Agreement?and?Its?Effect?on?
System?Performance?
In? this? section? we? study? how? inter-human? agreement?
affects? system? performance.? Lin? and?Hovy? (2002)? re-
ported? that,? compared? to? a?manually? created? ideal,?hu-
mans? scored?about?0.40? in?average?coverage? score? and?
the? best? system? scored? about? 0.35.?According? to? these?
numbers,?we?might?assume?that?humans?cannot?agree?to?
each?other?on?what? is? important?and? the?best?system? is?
almost?as?good?as?humans.?If?this?is?true?then?estimating?
an?upper?bound?using?oracle?extracts?is?meaningless.?No?
matter?how?high?the?estimated?upper?bounds?may?be,?we?
probably?would?never?be?able? to?achieve? that?perform-
ance? due? to? lack? of? agreement? between? humans:? the?
oracle? approximating? one? human?would? fail?miserably?
with?another.??Therefore?we?set?up?experiments?to?inves-
tigate?the?following:?
1.? What? is? the?distribution?of? inter-human?agree-
ment??
Figure?3.?A?150-word?oracle?extract? for?docu-
ment?AP900424-0035.?
Figure? 2.? A? manual? summary? for? document?
AP900424-0035.?
Figure?1.?A?100-word?oracle?extract? for?docu-
ment?AP900424-0035.?
<DOC>?
<DOCNO>AP900424-0035</DOCNO>?
<DATE>04/24/90</DATE>?
<HEADLINE>?
<S?HSNTNO="1">Elizabeth?Taylor?in?Intensive?Care?Unit</S>?
<S?HSNTNO="2">By?JEFF?WILSON</S>?
<S?HSNTNO="3">Associated?Press?Writer</S>?
<S?HSNTNO="4">SANTA?MONICA,?Calif.?(AP)</S>?
</HEADLINE>?
<TEXT>?
<S?SNTNO="1">A?seriously?ill?Elizabeth?Taylor?battled?pneumonia?at?her?
hospital,?her?breathing?assisted?by?a?ventilator,?doctors?say.</S>?
<S?SNTNO="2">Hospital?officials?described?her?condition?late?Monday?
as?stabilizing?after?a?lung?biopsy?to?determine?the?cause?of?the?pneumo-
nia.</S>?
<S?SNTNO="3">Analysis?of?the?tissue?sample?was?expected?to?take?until?
Thursday,?said?her?spokeswoman,?Chen?Sam.</S>?
<S?SNTNO="9">Another?spokewoman?for?the?actress,?Lisa?Del?Favaro,?
said?Miss?Taylor's?family?was?at?her?bedside.</S>?
<S?SNTNO="13">``It?is?serious,?but?they?are?really?pleased?with?her?
progress.</S>?
<S?SNTNO="22">During?a?nearly?fatal?bout?with?pneumonia?in?1961,?
Miss?Taylor?underwent?a?tracheotomy,?an?incision?into?her?windpipe?to?
help?her?breathe.</S>?
</TEXT>?
</DOC>
<DOC>?
<TEXT>?
<S?SNTNO="1">Elizabeth?Taylor?battled?pneumonia?at?her?hospital,?
assisted?by?a?ventilator,?doctors?say.</S>?
<S?SNTNO="2">Hospital?officials?described?her?condition?late?Monday?
as?stabilizing?after?a?lung?biopsy?to?determine?the?cause?of?the?pneumo-
nia.</S>?
<S?SNTNO="3">Analysis?of?the?tissue?sample?was?expected?to?be?com-
plete?by?Thursday.</S>?
<S?SNTNO="4">Ms.?Sam,?spokeswoman?said?"it?is?serious,?but?they?are?
really?pleased?with?her?progress.</S>?
<S?SNTNO="5">She's?not?well.</S>?
<S?SNTNO="6">She's?not?on?her?deathbed?or?anything.</S>?
<S?SNTNO="7">Another?spokeswoman,?Lisa?Del?Favaro,?said?Miss?
Taylor's?family?was?at?her?bedside.</S>?
<S?SNTNO="8">During?a?nearly?fatal?bout?with?pneumonia?in?1961,?Miss?
Taylor?underwent?a?tracheotomy?to?help?her?breathe.</S>?
</TEXT>?
</DOC>?
<DOC>?
<DOCNO>AP900424-0035</DOCNO>?
<DATE>04/24/90</DATE>?
<HEADLINE>?
<S?HSNTNO="1">Elizabeth?Taylor?in?Intensive?Care?Unit</S>?
<S?HSNTNO="2">By?JEFF?WILSON</S>?
<S?HSNTNO="3">Associated?Press?Writer</S>?
<S?HSNTNO="4">SANTA?MONICA,?Calif.?(AP)</S>?
</HEADLINE>?
<TEXT>?
<S?SNTNO="1">A?seriously?ill?Elizabeth?Taylor?battled?pneumonia?at?her?
hospital,?her?breathing?assisted?by?a?ventilator,?doctors?say.</S>?
<S?SNTNO="2">Hospital?officials?described?her?condition?late?Monday?
as?stabilizing?after?a?lung?biopsy?to?determine?the?cause?of?the?pneumo-
nia.</S>?
<S?SNTNO="3">Analysis?of?the?tissue?sample?was?expected?to?take?until?
Thursday,?said?her?spokeswoman,?Chen?Sam.</S>?
<S?SNTNO="4">The?58-year-old?actress,?who?won?best-actress?Oscars?
for?``Butterfield?8''?and?``Who's?Afraid?of?Virginia?Woolf,''?has?been?
hospitalized?more?than?two?weeks.</S>?
<S?SNTNO="8">Her?condition?is?presently?stabilizing?and?her?physicians?
are?pleased?with?her?progress.''</S>?
<S?SNTNO="9">Another?spokewoman?for?the?actress,?Lisa?Del?Favaro,?
said?Miss?Taylor's?family?was?at?her?bedside.</S>?
<S?SNTNO="13">``It?is?serious,?but?they?are?really?pleased?with?her?
progress.</S>?
<S?SNTNO="14">She's?not?well.</S>?
<S?SNTNO="15">She's?not?on?her?deathbed?or?anything,''?Ms.?Sam?said?
late?Monday.</S>?
<S?SNTNO="22">During?a?nearly?fatal?bout?with?pneumonia?in?1961,?
Miss?Taylor?underwent?a?tracheotomy,?an?incision?into?her?windpipe?to?
help?her?breathe.</S>?
</TEXT>?
</DOC>
?2.? How?does?a?state-of-the-art?system?differ?from?
average?human?performance?at?different? inter-
human?agreement?levels???
We? present? our? results? in? the? next? section? using? 303?
newspaper?articles?from?the?DUC?2001?single?document?
summarization?task.?Besides?the?original?documents,?we?
also? have? three? human? summaries,? one? lead? summary?
(B1),? and? one? automatic? summary? from? one? top? per-
forming?system?(T)?for?each?document.?
5? Results?
In? order? to? determine? the? empirical? upper? and? lower?
bounds? of? inter-human? agreement,?we? first? ran? cross-
human?evaluation?using?unigram?co-occurrence?scoring?
through? six? human? summary? pairs,? i.e.? (H1,H2),?
(H1,H3),?(H2,H1),?(H2,H3),?(H3,H1),?and?(H3,H2).?For?
a? summary? pair? (X,Y),?we? used?X? as? the?model? sum-
mary?and?Y?as?the?system?summary.?Figure?4?shows?the?
distributions?of?four?different?scenarios.?The?MaxH?dis-
tribution? picks? the? best? inter-human? agreement? scores?
for?each?document,?the?MinH?distribution?the?minimum?
one,? the?MedH?distribution? the?median,? and? the?AvgH?
distribution? the? average.?The? average?of? the?best? inter-
human? agreement? and? the? average? of? average? inter-
human?agreement?differ?by?about?10?percent?in?unigram?
co-occurrence?score?and?18?percent?between?MaxH?and?
MinH.? These? big? differences? might? come? from? two?
sources.?The? first? one? is? the? limitation? of? the? unigram?
0
10
20
30
40
50
60
70
80
0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00
Unigram?Co-occurrence?Scores
#?
o
f?I
n
st
an
ce
s
AvgH MaxH MedH MinH
Average?MAX?=?0.50
Average?AVG?=?0.40
Average?MED?=?0.39
Average?MIN?=?0.32
Figure? 4.? DUC? 2001? single? document? inter-
human? unigram? co-occurrence? score? distribu-
tions? for? maximum,? minimum,? average,? and?
median.?
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
D4
1.A
P8
81
21
1-0
02
7
D5
3.F
BI
S3
-2
29
42
D3
1.L
A0
21
68
9-
02
27
D3
4.A
P8
80
91
4-0
07
9
D5
3.A
P8
80
81
6-0
23
4
D2
8.L
A1
10
59
0-
00
38
D1
9.A
P8
80
33
0-0
11
9
D1
4.A
P9
01
01
0-0
03
6
D2
2.L
A0
70
18
9-
00
80
D2
7.L
A1
00
78
9-
00
07
D1
2.F
T9
34
-1
10
14
D2
2.A
P8
81
21
6-0
01
7
D3
7.F
BI
S3
-1
19
19
D1
9.L
A1
02
18
9-
01
51
D0
5.F
T9
41
-1
54
7
D5
7.L
A1
10
58
9-
00
82
D3
4.A
P8
80
91
3-0
20
4
D4
5.A
P9
00
62
5-0
16
0
D5
0.A
P8
81
22
2-0
11
9
D1
4.A
P9
01
01
2-0
03
2
D4
1.S
JM
N9
1-
06
07
10
22
D4
3.F
T9
23
-5
85
9
D0
8.A
P8
90
31
6-0
01
8
D1
9.A
P8
80
62
3-0
13
5
D4
3.F
T9
33
-8
94
1
D4
4.F
T9
34
-9
11
6
D1
2.W
SJ
87
02
27
-0
14
9
D0
4.F
T9
23
-5
08
9
D1
5.A
P8
90
30
2-0
06
3
D0
4.F
T9
23
-6
03
8
D3
7.A
P8
90
70
4-0
04
3
D1
2.W
SJ
87
01
23
-0
10
1
D1
5.A
P8
90
51
1-0
12
6
D1
5.A
P9
00
52
1-0
06
3
D0
6.F
T9
22
-1
02
00
D3
4.A
P9
00
60
1-0
04
0
Document?IDs
U
n
ig
ra
m
?C
o-
oc
cu
rr
en
ce
?S
co
re
s
MaxH B1 T E100 E150 FT Avg?MaxH Avg?B1 Avg?T Avg?E100 Avg?E150 Avg?FT
Figure?5.?DUC?2001?single?document? inter-human,?baseline,?system,?100-word,?150-word,?and?full? text?
oracle?extracts?unigram?co-occurrence?score?distributions?(#?of?sentences<=30).?Document?IDs?are?sorted?
by?decreasing?MaxH.?
?co-occurrence?scoring?applied?to?manual?summaries?that?
it?cannot? recognize?synonyms?or?paraphrases.?The?sec-
ond?one?is?the?true? lack?of?agreement?between?humans.?
We?would? like? to?conduct?an? in-depth?study? to?address?
this? question,? and?would? just? assume? the? unigram? co-
occurrence?scoring?is?reliable.?
In? other? experiments,? we? used? the? best? inter-human?
agreement?results?as?the?reference?point?for?human?per-
formance?upper?bound.?This?also? implied? that?we?used?
the? human? summary? achieving? the? best? inter-human?
agreement?score?as?our?reference?summary.?
Figure? 5? shows? the? unigram? co-occurrence? scores? of?
human,?baseline,? system?T,? and? three?oracle? extraction?
systems?at?different?extraction?lengths.?We?generated?all?
possible? sentence? combinations? that? satisfied? 100?5?
words?constraints.?Due? to?computation-intensive?nature?
of?this?task,?we?only?used?documents?with?fewer?than?30?
sentences.? We? then? computed? the? unigram? co-
occurrence?score?for?each?combination,?selected?the?best?
one?as?the?oracle?extraction,?and?plotted?the?score?in?the?
figure.?The?curve?for?100?5?words?oracle?extractions?is?
the?upper?bound? that? a? sentence? extraction? system? can?
achieve? within? the? given? word? limit.? If? an? automatic?
system?is?allowed?to?extract?more?words,?we?can?expect?
that? longer? extracts? would? boost? system? performance.?
The?question? is?how?much?better? and?what? is? the?ulti-
mate? limit??To? address? these? questions,?we? also? com-
puted? unigram? co-occurrence? scores? for? oracle?
extractions?of?150?5?words?and?full?text4.?The?perform-
ance?of? full? text? is? the?ultimate?performance?an?extrac-
tion?system?can? reach?using? the?unigram?co-occurrence?
scoring? method.?We? also? computed? the? scores? of? the?
lead?baseline?system?(B1)?and?an?automatic?system?(T).??
The? average? unigram? co-occurrence? score? for? full? text?
(FT)?was?0.833,?150?5?words?(E150)?was?0.796,?100?5?
words? (E100)? was? 0.650,? the? best? inter-human? agree-
ment?(MaxH)?was?0.546,?system?T?was?0.465,?and?base-
line?was?0.456.?It?is?interesting?to?note?that?the?state-of-
the-art?system?performed?at? the?same? level?as? the?base-
line?system?but?was?still?about?10%?away?from?human.?
The?10%?difference?between?E100?and?MaxH?(0.650?vs.?
0.546)? implies?we?might? need? to? constraint?humans? to?
focus? their?summaries? in?certain?aspects? to?boost? inter-
human? agreement? to? the? level?of?E100;?while? the?15%?
and?24%?improvements?from?E100?to?E150?and?FT?in-
dicate?compression?would?help?push?overall?system?per-
formance? to?a?much?higher? level,? if?a?system? is?able? to?
compress? longer? summaries? into? a? shorter?without? los-
ing?important?content.?
To? investigate? relative? performance? of? humans,? sys-
tems,? and? oracle? extracts? at? different? inter-human?
agreement? levels,?we? created? three? separate? document?
sets? based? on? their? maximum? inter-human? agreement?
(MaxH)?scores.?Set?Set?A?had?MaxH?score?greater?than?
or?equal?to?0.70,?set?B?was?between?0.70?and?0.60,?and?
???????????????????????????????????????????????????????????
4?We? used? full? text? as? extract? and? computed? its? unigram? co-
occurrence?score?against?a?reference?summary.?
Figure? 7.? DUC? 2001? single? document? inter-
human,?baseline,?system,?and?full? text?unigram?
co-occurrence?score?distributions?(Set?B).?
Figure? 6.? DUC? 2001? single? document? inter-
human,?baseline,?system,?and?full? text?unigram?
co-occurrence?score?distributions?(Set?A).?
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
D4
1.A
P8
81
21
1-0
02
7
D1
1.A
P8
90
40
3-0
12
3
D1
4.A
P8
80
90
2-0
06
2
D4
1.A
P8
90
80
1-0
02
5
D0
6.S
JM
N9
1-
06
19
10
81
D4
1.L
A0
51
59
0-
00
65
D0
6.W
SJ
91
07
10
-0
14
8
D5
3.F
BI
S3
-2
29
42
D2
8.L
A1
10
49
0-
01
84
D3
1.L
A0
30
88
9-
01
63
D1
3.S
JM
N9
1-
06
25
54
34
D2
4.L
A0
51
19
0-
01
85
D3
1.L
A0
21
68
9-
02
27
D0
5.F
T9
31
-3
88
3
D0
6.S
JM
N9
1-
06
28
30
83
D3
1.A
P8
91
00
6-0
02
9
D5
0.A
P8
80
71
4-0
14
2
D3
4.A
P8
80
91
4-0
07
9
D1
4.A
P8
80
62
9-0
15
9
D1
3.A
P9
00
30
6-0
10
5
D3
1.L
A0
30
78
9-
00
47
D1
4.L
A1
03
08
9-
00
70
Document?IDs
U
ni
g
ra
m
?C
o
-o
cc
u
rr
en
ce
?S
co
re
s
MaxH B1 T AvgMaxH Avg?B1 Avg?T
Avg?FT FT Avg?E100 Avg?E150
Avg?E150?=?0.863
Avg?FT?=?0.924
Avg?E100?=?0.705
Avg?MaxH?=?0.741
Avg?T?=?0.525
Avg?B1?=?0.516
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
D5
3.A
P8
80
81
6-0
23
4
D0
5.F
T9
21
-9
31
0
D4
1.L
A0
81
49
0-
00
30
D2
4.A
P9
00
42
4-0
03
5
D3
7.F
BI
S4
-2
76
02
D0
6.L
A0
71
59
0-
00
68
D2
8.L
A1
10
59
0-
00
38
D3
1.L
A0
61
58
9-
01
43
D3
2.A
P9
00
32
3-0
03
6
D3
7.A
P9
01
01
3-0
04
6
D5
6.A
P8
81
12
6-0
00
7
D0
6.A
P8
90
32
2-0
01
0
D1
9.A
P8
80
33
0-0
11
9
D1
4.A
P8
80
91
3-0
12
9
D0
4.F
T9
23
-5
79
7
D4
4.F
T9
32
-5
85
5
D1
4.A
P9
01
01
0-0
03
6
D3
7.A
P8
80
51
0-0
17
8
D4
1.A
P8
90
80
5-0
12
6
D2
2.A
P8
80
70
5-0
10
9
D5
0.A
P9
00
91
0-0
02
0
D3
1.S
JM
N9
1-
06
08
42
28
D3
4.A
P9
00
52
9-0
00
5
D2
2.L
A0
70
18
9-
00
80
D0
4.F
T9
23
-5
83
5
D1
4.A
P8
81
22
2-0
12
6
D2
4.A
P9
00
51
2-0
03
8
D2
7.L
A1
00
78
9-
00
07
D3
1.A
P8
81
00
9-0
07
2
D4
5.A
P8
80
52
0-0
26
4
D0
8.A
P8
80
31
8-0
05
1
D1
5.F
BI
S4
-6
77
21
D1
2.F
T9
34
-1
10
14
D3
7.A
P9
00
42
8-0
10
8
D4
5.
FT
92
1-
30
5
D5
4.L
A0
92
79
0-
00
10
D5
6.S
JM
N9
1-
06
13
63
05
Dcoument?IDs
U
ni
g
ra
m
?C
o
-o
cc
u
rr
en
ce
?S
co
re
s
MaxH B1 T FT AvgMaxH Avg?B1
Avg?T Avg?FT Avg?E100 Avg?E150
Avg?E150?=?0.840
Avg?E100?=?0.698
Avg?FT?=?0.917
Avg?MaxH?=?0.645
Avg?B1?=?0.509
Avg?T?=?0.490
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
D2
2.A
P8
81
21
6-0
01
7
D4
4.F
T9
33
-1
08
81
D4
3.A
P8
90
13
1-0
28
0
D0
6.L
A0
11
88
9-
00
67
D2
7.A
P8
90
72
2-0
08
1
D4
1.S
JM
N9
1-
06
14
21
26
D5
7.A
P9
01
20
3-0
16
6
D3
1.S
JM
N9
1-
06
01
22
24
D2
8.S
JM
N9
1-
06
31
21
20
D3
0.A
P9
00
41
6-0
18
8
D2
7.W
SJ
91
11
21
-0
13
6
D3
4.A
P8
80
91
3-0
20
4
D2
7.W
SJ
91
12
12
-0
08
0
D0
6.W
SJ
91
04
05
-0
15
4
D1
5.L
A1
01
69
0-
00
40
D5
0.A
P8
81
22
2-0
11
9
D0
8.A
P8
90
30
7-0
15
0
D4
4.F
T9
33
-5
70
9
D3
7.A
P9
00
42
8-0
00
5
D5
0.A
P8
91
21
3-0
00
4
D5
4.W
SJ
91
10
31
-0
01
2
D1
9.L
A0
71
58
9-
00
76
D1
4.A
P9
00
82
9-0
12
0
D4
3.F
T9
11
-3
46
3
D3
1.A
P8
80
92
7-0
11
7
D2
8.L
A1
21
18
9-
00
17
D0
8.A
P8
90
31
6-0
01
8
D4
4.F
T9
34
-8
62
8
D0
8.A
P9
00
72
1-0
11
0
D1
9.A
P8
80
62
3-0
13
5
D2
2.A
P8
80
70
5-0
01
8
D3
2.A
P8
90
32
6-0
08
1
D4
3.F
T9
33
-8
94
1
D5
3.A
P8
80
61
3-0
16
1
Document?IDs
U
ni
g
ra
m
?C
o
-o
cc
u
rr
en
ce
?S
co
re
s
MaxH B1 T AvgMaxH Avg?B1 Avg?T
Avg?FT FT Avg?E100 Avg?E150
Avg?E150?=?0.790
Avg?E100?=?0.645
Avg?FT?=?0.897
Avg?MaxH?=?0.536
Avg?T?=?0.435
Avg?B1?=?0.423
Figure? 8.? DUC? 2001? single? document? inter-
human,?baseline,?system,?and?full? text?unigram?
co-occurrence?score?distributions?(Set?C).?
?set?C?between?0.60?and?0.50.?A?had?22?documents,?set?B?
37,?and?set?C?100.?Total?was?about?52%?(=159/303)?of?
the? test? collection.?The? 100?5? and? 150?5?words? aver-
ages?were? computed? over? documents?which? contain? at?
most?30?sentences.?The?results?are?shown? in?Figures?6,?
7,?and?8.?In?the?highest?inter-human?agreement?set?(A),?
we? found? that? average?MaxH,? 0.741,?was? higher? than?
average? 100?5? words? oracle? extract,? 0.705;? while? the?
average? automatic? system? performance? was? around?
0.525.? This? is? good? news? since? the? high? inter-human?
agreement?and?the?big?difference?(0.18)?between?100?5?
words? oracle? and? automatic? system? performance? pre-
sents? a? research? opportunity? for? improving? sentence?
extraction? algorithms.?The? scores? of?MaxH? (0.645? for?
set?B?and?0.536?for?set?C)?in?the?other?two?sets?are?both?
lower?than?100?5?words?oracles?(0.698?for?set?B,?5.3%?
lower,? and? 0.645? for? set? C,? 9.9%? lower).? This? result?
suggests? that?optimizing?sentence?extraction?algorithms?
at? the? Set? C? level?might? not? be?worthwhile? since? the?
algorithms? are? likely? to? overfit? the? training? data.? The?
reason? is? that? the? average? run? time? performance? of? a?
sentence?extraction?algorithm?depends?on?the?maximum?
inter-human? agreement.? For? example,? given? a? training?
reference? summary?TSUM1? and? its? full?document?TDOC1,?
we?optimize?our?sentence?extraction?algorithm?to?gener-
ate?an?oracle?extract?based?on?TSUM1?from?TDOC1.?In?the?
run?time,?we?test?on?a?reference?summary?RSUM1?and?its?
full?document?RDOC1.? In? the?unlikely?case? that?RDOC1? is?
the?same?as?TDOC1?and?RSUM1? is? the?same?as?TSUM1,? i.e.?
TSUM1?and?RSUM1?have?unigram?co-occurrence?score?of?1?
(perfect? inter-human? agreement? for? two? summaries? of?
one?document),?the?optimized?algorithm?will?generate?a?
perfect?extract?for?RDOC1?and?achieve? the?best?perform-
ance? since? it? is?optimized?on?TSUM1.?However,?usually?
TSUM1?and?RSUM1?are?different.?Then?the?performance?of?
the?algorithm?will?not?exceed?the?maximum?unigram?co-
occurrence?score?between?TSUM1?and?RSUM1.?Therefore?it?
is? important? to? ensure? high? inter-human? agreement? to?
allow? researchers? room? to?optimize?sentence?extraction?
algorithms?using?oracle?extracts.???
Finally,?we? present? the? effect? of? compression? ratio? on?
inter-human? agreement? (MaxH)? and? performance? of?
baseline?(B1),?automatic?system?T?(T),?and?full?text?ora-
cle?(FT)? in?Figure?9.?Compression?ratio? is?computed? in?
terms?of?words?instead?of?sentences.?For?example,?a?100?
words? summary?of? a? 500?words?document?has? a? com-
pression? ratio?of?0.80? (=1?100/500).?The? figure? shows?
that?three?human?summaries?(H1,?H2,?and?H3)?had?dif-
ferent? compression? ratios? (CMPR?H1,?CMPR?H2,? and?
CMPR?H3)? for? different? documents? but? did? not? differ?
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
D2
4.L
A0
51
19
0-
01
85
D1
9.A
P8
80
21
7-0
17
5
D2
4.A
P9
00
51
1-0
15
9
D5
6.A
P8
81
12
6-0
00
7
D5
3.F
BI
S3
-2
29
42
D4
4.F
T9
34
-1
33
50
D5
7.A
P8
91
01
7-0
20
4
D0
4.F
T9
23
-6
03
8
D3
7.A
P8
80
51
0-0
17
8
D2
2.L
A0
70
18
9-
00
80
D4
4.F
T9
22
-3
17
1
D3
1.A
P8
81
00
9-0
07
2
D3
1.S
JM
N9
1-
06
01
22
24
D0
6.A
P9
01
02
9-0
03
5
D0
8.A
P9
01
23
1-0
01
2
D1
5.L
A1
01
69
0-
00
40
D4
4.F
T9
33
-2
76
0
D0
8.S
JM
N9
1-
06
19
30
81
D0
8.A
P8
80
31
8-0
05
1
D1
5.A
P9
00
52
1-0
06
3
D0
6.A
P8
90
32
2-0
01
0
D3
1.S
JM
N9
1-
06
08
42
28
D3
2.A
P8
90
50
2-0
20
5
D4
5.S
JM
N9
1-
06
18
20
91
D3
2.A
P9
00
31
3-0
19
1
D3
9.A
P8
81
01
7-0
23
5
D3
2.L
A0
40
78
9-
00
51
D5
3.A
P8
81
22
7-0
18
5
D5
0.A
P8
91
21
0-0
07
9
D0
6.L
A0
80
79
0-
01
11
D5
4.L
A1
02
19
0-
00
45
D3
7.S
JM
N9
1-
06
14
30
70
D1
3.W
SJ
91
07
02
-0
07
8
D2
2.W
SJ
88
09
23
-0
16
3
Document?IDs
U
ni
g
ra
m
?C
o-
oc
cu
rr
en
ce
?S
co
re
s
B1 MaxH T CMPR?H1 CMPR?H2 CMPR?H3
FT Linear?(B1) Linear?(MaxH) Linear?(T) Linear?(FT)
Figure?9.?DUC?2001?single?doc?inter-human,?baseline,?and?system?unigram?co-occurrence?score?versus?
compression?ratio.?Document?IDs?are?sorted?by?increasing?compression?ratio?CMPR?H1.?
?much.?The?unigram?co-occurrence?scores?for?B1,?T,?and?
MaxH?were?noisy?but?had? a?general? trend? (Linear?B1,?
Linear? T,? and? Linear? MaxH)? of? drifting? into? lower?
performance? when? compression? ratio? increased? (i.e.?
when? summaries? became? shorter);? while? the? per-
formance? of? FT? did? not? exhibit? a? similar? trend.? This?
confirms? our? earlier? hypothesis? that? humans? are? less?
likely? to? agree? at? high? compression? ratio? and? system?
performance?will?also?suffer?at?high?compression? ratio.?
The?constancy?of?FT?across?different?compression?ratios?
is? reasonable? since? FT? scores? should? only? depend? on?
how? well? the? unigram? co-occurrence? scoring? method?
captures?content?overlap?between?a?full?text?and?its?ref-
erence? summaries? and? how? likely? humans? use?
vocabulary?outside?the?original?document.?
6? Conclusions?
In? this? paper? we? presented? an? empirical? study? of? the?
potential? and? limitations? of? sentence? extraction? as? a?
method? of? automatic? text? summarization.?We? showed?
the?following:?
(1)? How?to?use?oracle?extracts?to?estimate?the?per-
formance? upper? bound? of? sentence? extraction?
methods?at?different?extract?lengths.?We?under-
stand?that?summaries?optimized?using?unigram?
co-occurrence? score? do? not? guarantee? good?
quality? in? terms? of? coherence,? cohesion,? and?
overall?organization.?However,?we?would?argue?
that?a?good?summary?does?require?good?content?
and?we?will?leave?how?to?make?the?content?co-
hesive,? coherent,? and? organized? to? future? re-
search.??
(2)? Inter-human?agreement?varied?a?lot?and?the?dif-
ference?between?maximum?agreement? (MaxH)?
and? minimum? agreement? (MinH)? was? about?
18%?on? the?DUC?2001?data.?To?minimize? the?
gap,?we?need?to?define?the?summarization?task?
better.? This? has? been? addressed? by? providing?
guided? summarization? tasks? in? DUC? 2003?
(DUC? 2002).?We? guesstimate? the? gap? should?
be?smaller?in?DUC?2003?data.?
(3)? State-of-the-art?systems?performed?at?the?same?
level?as?the?baseline?system?but?were?still?about?
10%? away? from? the? average? human? perform-
ance.??
(4)? The? potential? performance? gains? (15%? from?
E100? to? E150? and? 24%? to? FT)? estimated? by?
oracle?extracts?of?different?sizes? indicated? that?
sentence? compression? or? sub-sentence? extrac-
tion?are?promising?future?directions.?
(5)? The?relative?performance?of?humans?and?oracle?
extracts? at? three? inter-human? agreement? inter-
vals?showed?that?it?was?only?meaningful?to?op-
timize? sentence? extraction? algorithms? if? inter-
human? agreement?was? high.?Although? overall?
high? inter-human?agreement?was? low?but?sub-
sets? of? high? inter-human? agreement? did? exist.?
For? example,? about? human? achieved? at? least?
60%? agreement? in? 59? out? of? 303? (~19%)?
documents?of?30?sentences?or?less.?
(6)? We? also? studied? how? compression? ratio? af-
fected? inter-human?agreement?and?system?per-
formance,? and? the? results? supported? our?
hypothesis? that? humans? tend? to? agree? less? at?
high? compression? ratio,? and? similar? between?
humans?and?systems.?How?to?take?into?account?
this?factor?in?future?summarization?evaluations?
is?an?interesting?topic?to?pursue?further.?
Using?exhaustive?search?to?identify?oracle?extraction?has?
been? studied?by?other? researchers?but? in?different? con-
texts.?Marcu?(1999a)?suggested?using?exhaustive?search?
to?create?training?extracts?from?abstracts.?Donaway?et?al.?
(2000)?used?exhaustive?search?to?generate?all?three?sen-
tences?extracts? to?evaluate?different?evaluation?metrics.?
The?main?difference?between?their?work?and?ours?is?that?
we? searched? for? extracts? of? a? fixed? number? of? words?
while?they?looked?for?extracts?of?a?fixed?number?of?sen-
tences.??
In?the?future,?we?would? like?to?apply?a?similar?method-
ology? to?different? text?units,? for?example,?sub-sentence?
units?such?as?elementary?discourse?unit?(Marcu?1999b).?
We?want? to? study?how? to? constrain? the? summarization?
task? to? achieve? higher? inter-human? agreement,? train?
sentence? extraction? algorithms? using? oracle? extracts? at?
different? compression? sizes,? and? explore? compression?
techniques?to?go?beyond?simple?sentence?extraction.?
References?
Donaway,? R.L.,? Drummey,? K.W.,? and? Mather,? L.A.?
2000.? A? Comparison? of? Rankings? Produced? by?
Summarization?Evaluation?Measures.? In? Proceeding?
of?the?Workshop?on?Automatic?Summarization,?post-
conference?workshop?of?ANLP-NAACL-2000,?Seat-
tle,?WA,?USA,?69?78.?
DUC.?2002.?The?Document?Understanding?Conference.??
http://duc.nist.gov.??
Edmundson,? H.P.? 1969.? New? Methods? in? Automatic?
Abstracting.??Journal?of?the?Association?for?Comput-
ing?Machinery.??16(2).?
Goldstein,? J.,? M.? Kantrowitz,? V.? Mittal,? and? J.? Car-
bonell.? 1999.? Summarizing? Text? Documents:? Sen-
tence? Selection? and? Evaluation? Metrics.? In?
Proceedings?of? the?22nd? International?ACM?Confer-
ence? on?Research? and?Development? in? Information?
Retrieval?(SIGIR-99),?Berkeley,?CA,?USA,?121?128.?
Hovy,?E.?and?C.-Y.?Lin.?1999.?Automatic?Text?Summa-
rization? in? SUMMARIST.? In? I.? Mani? and? M.?
?Maybury? (eds),? Advances? in? Automatic? Text? Sum-
marization,?81?94.?MIT?Press.?
Kupiec,?J.,?J.?Pederson,?and?F.?Chen.?1995.?A?Trainable?
Document? Summarizer.? In? Proceedings? of? the? 18th?
International?ACM?Conference?on?Research?and?De-
velopment? in? Information?Retrieval? (SIGIR-95),?Se-
attle,?WA,?USA,?68?73.?
Lin,?C.-Y.? and?E.?Hovy.?2002.?Manual? and?Automatic?
Evaluations? of? Summaries.? In? Proceedings? of? the?
Workshop? on? Automatic? Summarization,? post-
conference? workshop? of? ACL-2002,? pp.? 45-51,?
Philadelphia,?PA,?2002.?
Lin,?C.-Y.?and?E.H.?Hovy.?2003.?Automatic?Evaluation?
of? Summaries?Using?N-gram? Co-occurrence? Statis-
tics.? In? Proceedings? of? the? 2003?Human? Language?
Technology? Conference? (HLT-NAACL? 2003),? Ed-
monton,?Canada,?May?27???June?1,?2003.?
Luhn,?H.?P.?1969.?The?Automatic?Creation?of?Literature?
Abstracts.? IBM? Journal? of? Research? and? Develop-
ment.?2(2),?1969.?
Marcu,?D.?1999a.?The?automatic?construction?of? large-
scale? corpora? for? summarization? research.? Proceed-
ings? of? the? 22nd? International?ACM?Conference? on?
Research?and?Development? in? Information?Retrieval?
(SIGIR-99),?Berkeley,?CA,?USA,?137?144.?
Marcu,?D.?1999b.?Discourse?trees?are?good?indicators?of?
importance?in?text.?In?I.?Mani?and?M.?Maybury?(eds),?
Advances? in? Automatic? Text? Summarization,? 123?
136.?MIT?Press.?
McKeown,? K.,? R.? Barzilay,? D.? Evans,? V.? Hatzivassi-
loglou,? J.? L.? Klavans,? A.? Nenkova,? C.? Sable,? B.?
Schiffman,?S.?Sigelman.?2002.?Tracking?and?Summa-
rizing?News?on?a?Daily?Basis?with?Columbia?s?News-
blaster.? In? Proceedings? of? Human? Language?
Technology? Conference? 2002? (HLT? 2002).? San?
Diego,?CA,?USA.?
NIST.?2002.?Automatic?Evaluation?of?Machine?Transla-
tion?Quality?using?N-gram?Co-Occurrence?Statistics.?
Over,? P.? and?W.? Liggett.? 2002.? Introduction? to?DUC-
2002:?an? Intrinsic?Evaluation?of?Generic?News?Text?
Summarization? Systems.? In? Proceedings? of? Work-
shop? on? Automatic? Summarization? (DUC? 2002),?
Philadelphia,?PA,?USA.?
http://www-nlpir.nist.gov/projects/duc/pubs/?
2002slides/overview.02.pdf?
Papineni,? K.,? S.? Roukos,? T.?Ward,?W.-J.? Zhu.? 2001.?
Bleu:?a?Method?for?Automatic?Evaluation?of?Machine?
Translation.? IBM? Research? Report? RC22176?
(W0109-022).?
Radev,? D.R.? and? K.R.? McKeown.? 1998.? Generating?
Natural?Language?Summaries?from?Multiple?On-line?
Sources.?Computational?Linguistics,?24(3):469?500.?
Strzalkowski,?T,?G.?Stein,?J.?Wang,?and?B,?Wise.?A?Ro-
bust?Practical?Text?Summarizer.?1999.?In?I.?Mani?and?
M.? Maybury? (eds),? Advances? in? Automatic? Text?
Summarization,?137?154.?MIT?Press.?
White,?M.,?T.?Korelsky,?C.?Cardie,?V.?Ng,?D.? Pierce,?
and?K.?Wagstaff.?2001.?Multidocument?Summariza-
tion? via? Information? Extraction.? In? Proceedings? of?
Human? Language? Technology? Conference? 2001?
(HLT?2001),?San?Diego,?CA,?USA.?
?
?
