Extracting Pronunciation-translated Names from Chinese  
Texts using Bootstrapping Approach 
Jing Xiao 
School of Computing, 
National University of Singapore 
xiaojing@comp.nus.edu.sg 
Jimin Liu 
School of Computing, 
National University of Singapore 
liujm@comp.nus.edu.sg 
Tat-Seng Chua 
School of Computing, 
National University of Singapore 
chuats@comp.nus.edu.sg 
 
Abstract  
Pronunciation-translated names (P-Names) 
bring more ambiguities to Chinese word 
segmentation and generic named entity 
recognition. As there are few annotated 
resources that can be used to develop a good 
P-Name extraction system, this paper 
presents a bootstrapping algorithm, called 
PN-Finder, to tackle this problem. Starting 
from a small set of P-Name characters and 
context cue-words, the algorithm iteratively 
locates more P-Names from the Internet. 
The algorithm uses a combination of 
P-Name and context word probabilities to 
identify new P-Names. Experiments show 
that our PN-Finder is able to locate a large 
number of P-Names (over 100,000) from the 
Internet with a high recognition accuracy of 
over 85%. Further tests on the MET-2 test 
set show that our PN-Finder can achieve a 
performance of over 90% in F1 value in 
locating P-Names. The results demonstrate 
that our PN-Finder is effective. 
1 Introduction 
Pronunciation-translated names (P-Names) are 
those foreign names that are translated to Chinese 
characters according to their pronunciations. A 
P-Name sometimes forms part of but not a 
complete named entity. For instance, in the place 
name ?? (Berkeley University), only 
the term ?? (Berkeley) is a P-Name, while 
?? (University) is not since it is translated 
semantically.  
The ability to recognize P-Names helps to reduce 
ambiguities in word segmentation and improve the 
performance of Chinese information retrieval 
since many unknown words are P-Names, 
especially for international Chinese news. Unlike 
English, there is no blank between words in 
Chinese, in which a word is a linguistic token 
consisting of one or more characters. In addition, the 
same characters may appear in multiple context with 
different meanings (Chua and Liu, 2002). The 
presence of P-Names brings more ambiguities to 
Chinese word segmentation since every character in 
a P-Name can be used as a common character. 
Intuitively, we can extract the P-Names based on the 
distinctive sequence of characters that they are  used 
as compared to common words. In addition, we can 
use local context around the P-Names to confirm 
and classify them into person or part of location and 
organization names. One way to perform these tasks 
effectively is to rely on statistics derived from a 
large corpus in which the P-Names are annotated. 
While some annotated corpuses with general named 
entities are available such as the PKUC (Yu, 1999) 
and MET-2 (Chinchor, 2001), there is no such 
annotated corpus for P-Names. While annotated data 
is difficult to obtain, un-annotated data is readily 
available and plentiful, especially on the Internet. To 
take advantage of that, we need to tackle two major 
problems. The first is how to gather sufficient 
distinct P-Names from the Internet, and the second is 
how to use the available resources to derive reliable 
statistical information to characterize the P-Names. 
The problem of gathering sufficient reliable 
information from a small initial set of seed resources 
has been tackled in bootstrapping research for 
information extraction (Agichtein and Gravano, 
2000; Brin, 1998; Collins and Singer, 1999; 
Mihalcea and Moldovan, 2001; Riloff and Jones, 
1999). Bootstrapping approach aims to perform 
unsupervised text processing to extract information 
from open resources such as the Internet using 
minimum manual labor. Given the lack of annotated 
training samples for P-Name extraction, this paper 
introduces a bootstrapping algorithm, called 
PN-Finder. It starts from a small set of seed samples, 
and iteratively locates, extracts and classifies the 
new and more P-Names. It works in conjunction 
with a general Chinese named entity recognizer 
(Chua and Liu, 2002) to extract general named 
entities. 
In the remaining parts of this paper, we describe 
the details of PN-Finder in Section 2 and its 
application in locating P-Names from new 
documents in Section 3. Section 4 presents the 
experimental results using the MET-2 test corpus. 
Section 5 contains our conclusion and outline for 
future work. 
2 Bootstrapping Algorithm for Locating 
P-Names 
Currently, there is no standard corpus that 
annotates all P-Names. Since annotating thousands 
of P-Names is more difficult than collecting 
thousands of P-Names from the Internet, we recur 
to using the Internet search engine to collect a 
large set of P-Names. Figure 1 illustrates our main 
components in bootstrapping process. 
 
 
 
 
Figure 1: Main components of the bootstrapping 
The inputs to the PN-Finder are:  
a) A seed P-Name character set Cs(0) consisting of 
5 characters {??, ??, ??, ?	?, ?
?}. 
b) A set of seed context cue words CW(0) 
consisting of 60 context words, such as 
{?NULL?, ??, ??, ??, ??, ??}. 
These are typical context words found around 
person, location and organization names in 
PKUC1 (the PoS Corpus of Peking University), 
which contains one month of news from the 
People Daily.  
c) A set of P-Name candidates P(0), which is null at 
the beginning. 
d) A common word dictionary extracted from 
PKUC by removing proper nouns, numbers and 
non-Chinese symbols. It contains about 37,000 
words. 
                                                      
1
 http://icl.pku.edu.cn/Introduction/corpustagging.htm 
From the initial seeds, we perform the followings: 
a) We use every two characters in Cs(i-1) as query to 
retrieve relevant web pages from the Internet 
using a commercial search engine. We then 
extract possible P-Names from the returned web 
pages to update P(i). 
b) We find a most probable new P-Name character. 
Update Cs(i-1) to Cs(i) by adding the new character. 
c) We bootstrap new context words around the new 
P-Names found to derive CW(i). We then perform 
the lexical chaining to generalize these context 
words to generate semantic classes. 
d) We repeat the process from step (a) until any of 
the following conditions is satisfied: (i) when no 
new P-Name is found; (ii) when the desired 
number of iterations is reached; or (iii) when the 
number of P-Names found exceeds a desired 
number. 
The following subsections discuss the details of  
the bootstrapping process. 
2.1 Querying and Extracting the P-Names 
from the Web 
The first step of the algorithm is to derive good 
queries from the character set Cs(m-1) to search the 
Internet to obtain new web pages. If we use all single 
characters from Cs(m-1) to perform the search, we are 
likely to get too many pages containing irrelevant 
information. As a compromise, we use every two 
characters cicj in Cs(m-1) (except those combinations 
that have been used in the previous iterations) to 
search the Internet using Google (by using its 
language tool2). We consider only up to 300 entries 
returned by Google. We divide the content of the 
web pages into text segments by using the 
non-alphanumeric characters as delimiters. We 
extract those text segments that contain the search 
characters ci, cj or both and store them in R(m). For 
example, from the web page given in Figure 2, the 
text segments extracted include: strings ?
		

? and ?
		
? from the first 
entry; and strings ?	
?, ? 
	
!"#$%&'(? and ?)*
	
+? from the second entry. 
Given R(m), we next extract the possible P-Names. 
Firstly, we segment those entries in R(m) by 
performing the longest forward match using the 
common word dictionary. We then remove all 
                                                      
2
 http://www.google.com/intl/zh-CN/ 
Seed P-Name characters 
Seed context cue words 
 Webpages 
P-Names Generate new P-Name characters 
And new context cue words 
Search Engine  
Search Engine  
 Evaluate 
StringMatch 
non-Chinese letters and common words containing 
more than one character. From the remaining 
string segments in R(m), we locate all sub-strings 
with at  
 
Figure 2: A web page returned by Google 
least 2-character in length and contain the query 
terms ci, cj or cicj. We extract those sub-strings that 
appear at least ?n (we use 3) times as P-Name 
candidates by string matching. We store the new 
P-Name candidates found in P(m-1) to obtain P(m). 
For example, if we use ?	, 
? obtained from Cs(0) 
as query to Google, among the returned entries, we 
will have: 
                                              ?()(	
)()?? 
              ?()()()? 
 ?(WTO)()()()?? 
                                              ?()( )?? 
                                              ?!"(#$)?? 
Here the bracketed words are common words or 
English letters and they are removed from string  
matching. The sub-string ?,	
? appears 
5 times and it is matched as a possible P-Name.  
2.2 Deriving New P-Name Characters 
Given the set of P-Name candidates in P(m), we 
next use both the context words and corpus 
statistics to confirm the P-Name and extract new 
P-Name characters.  
2.2.1 Classifying P-Names 
From observation, context information is useful to  
comfirm a P-Name and determine its left and right 
boundary. Thus we use one-word context to confirm 
and classify P-Name candidates into person names 
or part of location or organization names. For each 
context word wc in CW(m), we first compute its 
probability vector of occurrences, PV(wc), around 
person, location and organization names in PKUC as 
follows:  
 ( ) , , , , ,c p p l l o oPV w c c c c c c? + ? + ? +=< >  (1) 
where: ( ) xx c
p l o
n
c w
n n n
+
+
+ + +
=
+ +
 (1.1) 
 
olp
x
cx
nnn
n
wc
???
?
?
++
=)(  (1.2) 
Here x?{p, l, o}, and n
-p ( or n+p), n-l (or n+l), n-o (or 
n+o) respectively give the number of times wc 
appears at the left (or right) boundary of person (p), 
location (l) and organization (o) names in PKUC. c
-x 
(or c+x) gives the probability that the P-Name is of 
type x, if this cue-word is at the left (or right) 
boundary of the P-Name. 
Given a P-Name candidate pk(m) in P(m), we extract 
the set of its left and right context words as Wcl and 
Wcr. We then derive the average probability vectors 
of Wcl = <cl-p, cl+p, cl-l, cl+l, cl-o, cl+o> and Wcr = <cr-p, 
c
r
+p, c
r
-l, c
r
+l, c
r
-o, c
r
+o>, and use these to compute the 
confidence vector of pk(m) as: 
 
( )( ) , ,mk p l oCV p c c c=< >    (2) 
where cp=cl-p+cr+p, cl=cl-l+cr+l, co=cl-o+cr+o. Here we 
simply average the probabilities of the left and right 
context words to derive the final probability vector. 
We assign pk(m) to be part of a named entity of type x, 
if cx ? ?p for x?{p, l, o}. Here we set ?p to be 0.8. In 
case that there are more than one value greater than 
?p, we select the one with the highest value in the 
type vector as the type of that P-Name.  
2.2.2 Evaluating P-Names 
We next derive an objective measure to evaluate 
how likely a candidate in P(m) could be a P-Name. 
We observe that a string is likely to be a P-Name if: 
(a) it contains some sub-strings that frequently 
appear in typical P-Names such as ??, ??, 
??, etc; and (b) it has context words in CW(m-1) set 
that indicates that it has high probability of being 
part of a named entity. Thus for each P-Name 
candidate pk(m) (pk(m)=c1c2?cn) in P(m), we compute: 
 )(/)()( )(2)(1)( mkmkmk psMpsps ?+= ?  (3) 
 
1 2( ) 2 3
1 1 1 2
1 1 1 1 1 1
( ) ( ) ( ) ( )n N n N n Nmk j i j i i j i i i
i j i j i j
s p n c n c c n c c c? ? ?
? ?
+ + +
= = = = = =
= + +
? ? ? ? ? ?
  
 
( )
2 ( ) m ax( , , )mk p l os p c c c=                                    (3.2) 
where n is the number of characters in pk(m), and N 
equals |P(m)|. nj(ci), nj(cici+1) and nj(cici+1ci+2) are 
respectively number of times the character strings 
ci, cici+1 and cici+1ci+2 in pk(m) also appear in other 
P-Name candidates in P(m). ? and ? are predefined 
constants (here we use  ? =0.5 and ? =1.5). 
Equation (3.1) gives higher weight to pk(m) that has 
better match with longer string sequence of, say, 
cici+1ci+2 with other known P-Names candidates. 
Equation (3.2) selects the highest confidence value 
of context words around pk(m) as support for pk(m). 
As s1 and s2 are of different scales, we normalize s1 
by dividing it by M, the maximum s1 values found 
in the current iteration, before fusing the two 
values in Equation (3). 
2.2.3 Generating New P-Name Characters 
Since we would like to obtain more new P-Names 
during bootstrapping, in each iteration, we would 
like to expand the P-Name character set. In order 
to select the most likely P-Name characters, we 
derive a quasi-probability, Conf(ci(m)), to estimate 
how likely a character ci(m) in the P-Name 
candidate set P(m) could be used as a P-Name 
character. To do this, we make use of both the 
PKUC corpus and P(m). We observe that most 
characters in P(m) also appear in the PKUC corpus, 
sometimes as P-Name characters sometimes as 
common characters. Thus, intuitively we estimate 
Conf(ci(m)) by its occurrences in both PKUC and 
P(m) as: 
( )
( ) ( )1
1( )
1
( )
( ) l n ( ( ) )
( )
c
c
c
N
m
k N
m mk
i kN km
k n e g
k
s p
C o n f c s p
s p N
=
=
=
?
= ?
?
+
?
  
Here we assume that there are Nc P-Name 
candidates in P(m) that contain ci(m); and Nneg is the 
number of times that ci(m) is used as 
single-character word in PKUC. Equation (4) aims 
to identify characters that appear frequently as part 
of P-Names, but rarely as part of common words. 
It also favors characters that appear in more 
probable P-Names through the s(pk(m)) measures. 
Although Equation (4) is effective in identifying 
individual P-Name characters, it is not good at 
locating the sequences of P-Name characters that 
form the P-Names. This is because there are many 
characters that have low Conf(ci(m)) values that are 
part of a P-Name. For example, in a P-Name ?
?, the character ?? has low confidence to be a 
P-Name character as defined by Equation (4). 
However, it co-occurs with high confident P-Name 
characters such as ?? and ??. To overcome this 
problem, we modify the confidence value of each 
character by considering its neighbors (context) to 
derive a smoothed confidence measure in Equation 
(5). 
)}(),(max{
)()(
1
)(
1
)(
+? ???
+=
+?
i
cB
i
cB
ii
cConfecConfe
cConfcSConf
ii?
 
 
where ?  is a predefined constant (we use ?  = 1), 
and 
)(
)()(;)(
)()( 11
i
ii
i
i
ii
i
cC
ccC
cB
cC
ccC
cB ??++ == . 
Conf(ci) is defined in Equation (4); C(ci) and C(cicj) 
is respectively the co-occurrence of characters ci and 
cicj in the P-Name set. Equation (5) tries to 
supplement the confidence of ci by its context, that 
is, it uses the higher of the bi-gram statistics with its 
preceding and succeeding word to enhance its 
confidence. We rank all the characters in P(m) using 
Equation (5) and add the top new character into 
CS(m-1) to obtain CS(m). 
2.3 Deriving New Context Words 
In addition to finding new P-Name characters, there 
is also a need to expand the context word set CW(m-1) 
in order to help identify more P-Names. As 
mentioned before, if at least one of cp, cl, co values of 
a P-Name candidate in Equation (2) is greater than a 
threshold ?p, we regard it as part of a named entity. 
For these P-Names which could be possible part of 
named entities, the following steps are performed: 
a) We retrieve all their context words in R(m). 
b) We add all new context words  to form CW(m). 
c) We update probability vectors of the new context 
words using Equation (1). 
d) We group these context words under the category 
of c
-x or c+x (for x?{p, l, o}) if their probabilities 
under that category is greater than a threshold ?g 
(say, 0.5). 
e) We then perform lexical chaining using HowNet 
to generalize the context words under each of the 
6 categories separately. The general lexical 
chaining algorithm is given in detail in Chua and 
Liu (2002). 
(3.1) 
(4) 
(5) 
f) After lexical chaining, some semantically 
related words are grouped together. We update 
the confidence vectors of the semantic groups 
by averaging the confidence values of words in 
each of the semantic groups. 
At the end of this process, we obtain a new set of 
context word CW(m) which contains some 
generalized context word classes. 
3 Identifying P-Names from New Texts 
At the end of the bootstrapping process, we obtain 
expanded lists of likely P-Name characters Cs(m), 
context cue words CW(m) and P-Names P(m). Given 
a new document, we want to use these resources to 
identify all P-Names. The process is carried out as 
follows: 
a) We first use our common word dictionary to 
remove all common words. 
b) Next we use knowledge of P-Name candidates    
and corpus statistics to identify a sequence of     
likely P-Name characters. Any sub-string in   
which the Sconf(ci) (see Equation (5)) of each    
consecutive character in that string  is greater     
than a pre-specified threshold ?c (we use 5) is     
considered as a P-Name. 
c) A frequently occurring problem during testing 
is how to handle new characters not found in 
the Cs(m) set that we do not know their 
confidence values. Such problem occurs as a 
same foreign name may be translated to 
different P-Names with similar Chinese PinYin. 
For these characters, we adopt the similar 
homophone approach to relate unknown 
characters to the known characters in Cs(m) set 
with similar Chinese PinYin. 
4 Evaluation 
We devise several tests to evaluate our extraction 
scheme with bootstrapping. We use the MET-2 
test corpus for two of the tests, and PKUC as basic 
language resource to support the process. We use 
PKUC to extract common word dictionary, which 
consists of about 37,000 words. We also use 
PKUC to extract and evaluate typical context cue 
words around person, location and organization 
names. Our experiments start from a ?seed? 
P-Name character set:  
Cs(0) = {??, ??, ??, ??, ?	?};  
and a set of 60 context cue words. 
4.1 Obtaining P-Names from the Internet 
We perform the bootstrapping process as discussed 
in Section 2 to extract P-Names from the Internet, 
and stopped after about 650 iterations. We manually 
count the number of correct P-Names obtained at the 
end of every 65-iterations. We also use the first 
100,000 P-Names found at the end of the 
bootstrapping process as the ground truth to 
compute the accuracy of P-Name identification. 
Figure 3 presents the results of the P-Name 
extraction process. From the figure, we can see that 
as we increased the number of iterations, the number 
of P-Names obtained also increased proportionally. 
This demonstrates that our bootstrapping process is 
consistent. We also observe that the system is able to 
maintain a high accuracy of over 85% even when the 
number of P-Names found approaches 100,000. 
This demonstrates that our method is effective. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
65 130 195 260 325 390 455 520 585 650
Ac
cu
rr
ac
y
0
20000
40000
60000
80000
100000
N
um
.
 
of
 
P-
N
am
es
Acccuracy P-Names
Figure 3: Obtaining P-Names with Bootstrapping 
4.2 Extracting P-Names from MET-2 set 
We use MET-2 test corpus to test the effectiveness 
of our approach to identify P-Names from new texts 
as discussed in Section 3. We consider a P-Name as 
correctly extracted only when every of its character 
are correctly identified. The results are presented in 
Table 1. The results show that we are able to achieve 
a recall of over 95% and precision of close to 90%. 
The results are encouraging as we did not use the 
training resource of MET-2 corpus to train the 
system, which is expected to lead to higher 
accuracy. 
Table 1: Results of P-Name extraction from MET2 
Actual # System Nc Np Nm Ns Rc Pr 
457 491 437 20 0 34  95.6% 89% 
Nc = number of P-Names correctly recognized. 
Np = number of P-Names partially recognized. 
Nm = number of P-Names missed. 
Ns = number of P-Names found but not in the annotated list. 
Recall (Rc) = Nc/(Nc + Np + Nm);  
Precision (Pr) = Nc /(Nc + Np + Ns).  
As a by-product of the PN-Finder, we obtained a 
large set of context words. We found that we can 
use these context words to correctly classify about 
25% of the extracted P-Names in MET-2 test set 
into person names or part of location or 
organization names using the method described in 
Section 2.2. The employing of context words to 
classify P-Names is mainly to confirm more 
P-Names and P-Name characters. 
4.3 Contributions of PN-Finder to a 
Generic NE Recognition Module 
The most important contribution of PN-Finder is 
that it can be used to improve the performance of a 
generic Chinese named entity recognizer as 
discussed in Chua and Liu (2002). Here, we 
conducted several trials by using the PN-Finder to 
extract a different number of P-Names. We use the 
first 100,000 P-Names found by the PN-Finder, 
together with the pattern rules in the general 
named entity recognizer, to conduct a baseline test. 
This test merely performs direct table look-up to 
locate all possible P-Names. Table 2 lists the 
performance of the general NE recognition system 
by using an increasing number of P-Names found 
by the PN-Finder, together with the use of the 
confidence statistics, context words obtained from 
the current sets of P-Names and pattern rules. The 
results indicate that as we increase the number of 
P-Names found by the PN-Finder, the performance 
of the general NE recognition system is improved 
steadily until it reaches over 92% in average F1 
value.  
Table 2: Contributions to general NE recognition 
# of P-Names used Ave F1 
100,000 (baseline) 71.3 
40,000 88.9 
60,000 90.5 
80,000 91.7 
100,000 92.3 
5 Conclusion and Future Work 
The presence of P-Names brings more ambiguities 
to Chinese word segmentation and general 
Chinese named entity recognition. However, there 
is a dearth of annotated corpus for extracting and 
classifying P-Names. To cope with the problem of 
sparse training resources, this paper presents a 
bootstrapping module to identify P-Names and 
classify them into parts of named entitites if 
possible. The PN-Finder could also contribute to 
general Chinese named entity recognition and 
achieve promising performance on the MET-2 test 
corpus.  
Currently, we use only a single word as the context, 
more context could be considered in the future 
research. We also aim to extend this method to 
extract organization names from Chinese documents 
obtained from the Internet. 
 
References  
Agichtein E. and Gravano L. (2000).  Snowball: 
Extracting Relations from Large Plain-Text 
Collections. Proceedings of the 5th ACM International 
Conference on Digital Libraries. 
Brin S. (1998).  Extracting Patterns and Relations from 
the World Wide Web.  WebDB Workshop at 6th 
International Conference on Extending Database 
Technology, EDBT? 98. 
Chinchor A. Nancy (2001). Overview of MUC7/MET-2. 
available at:  
http://www.itl.nist.gov/iaui/894.02/related_projects/muc/
proceedings/muc_7_proceedings/overview.html 
Chua T.S. and Liu J.M. (2002), Learning Pattern Rules 
for Chinese Named Entity Extraction. To Appear in 
AAAI?02. 
Collins M. and Singer Y. (1999).  Unsupervised Models 
for Named Entity Classification.  In Proceedings of the 
Joint SIGDAT Conference on Empirical Methods in 
Natural Language Processing and Very Large Corpora.  
Liu J.M. and Chua T.S. (2001), Building semantic 
Perceptron net for topic spotting, In Proceeding of 
Association for Computational Linguistics 39th 
Anniversary Meeting, 306-313 
Mihalcea F. R. and Moldovan I. D. (2001)  A Highly 
Accurate Bootstrapping Algorithm for Word Sense 
Disambiguation.  International Journal on Artificial 
Intelligence Tools. Vol.10, No 1-2(2001). pp. 5-21 
Riloff E. and Jones R. (1999)  Learning Dictionaries for 
Information Extraction by Multi-Level Bootstrapping.  
In Proceedings of the Sixteenth National Conference on 
Artificial Intelligence, pp. 1044-1049. 
Yu S. (1999), The Specification and Manual of Chinese 
Word Segmentation and Part of Speech Tagging, 
available at: 
 http://www.icl.pku.edu.cn/Introduction/corpustagging.htm 
