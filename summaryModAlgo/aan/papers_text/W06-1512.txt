Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 91?96,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Semantic Interpretation of Unrealized Syntactic Material in LTAG 
 
Olga Babko-Malaya 
University of Pennsylvania 
malayao@ldc.upenn.edu 
 
 
  
 
Abstract 
This paper presents a LTAG-based 
analysis of gapping and VP ellipsis, 
which proposes that resolution of the 
elided material is part of a general dis-
ambiguation procedure, which is also re-
sponsible for resolution of underspecified 
representations of scope.  
1  Introduction 
The problem of ellipsis resolution is to recover 
the interpretation of the elided material. For ex-
ample, in (1), the elided VP is interpreted as be-
ing identical to the verb in the preceding sen-
tence. Likewise, in the gapping structures, as 
shown in (2), the interpretation of a gap is being 
identified with the interpretation of the preceding 
verb.   
  
(1) Mary likes Bill.  Jane does too.  
(2) Mary ate beans and others -- rice.  
 
Whereas some approaches assume syntactic 
identity between the antecedent and the elided 
material (e.g. Fiengo and May 1994),  others 
suggest that VP ellipsises are proforms, semanti-
cally identified with their antecedents (see Dal-
rymple et al1991, Shieber et al1996, Hardt 1993, 
1999).   
This paper follows semantic approaches to el-
lipsis resolution. It adopts the LTAG semantics 
of Kallmeyer and Romero 2004 and proposes 
that resolution of ellipsises and gaps is part of a 
general disambiguation procedure, which is also 
responsible for resolution of underspecified rep-
resentations of scope. 
2 LTAG Semantics with Semantic Uni-
fication 
In LTAG framework (Joshi and Schabes 1997), 
the basic units are (elementary) trees, which can 
be combined into bigger trees by substitution or 
adjunction. LTAG derivations are represented by 
derivation trees that record the history of how the 
elementary trees are put together. Given that 
derivation steps in LTAG correspond to predi-
cate-argument applications, it is usually assumed 
that LTAG semantics is based on the derivation 
tree, rather than the derived tree (Kallmeyer and 
Joshi 2003).  
Semantic composition which we adopt is 
based on LTAG semantics with semantic unifica-
tion (Kallmeyer and Romero 2004). In the deri-
vation tree, elementary trees are replaced by their 
semantic representations and corresponding fea-
ture structures.  Semantic representations are as 
defined in Kallmeyer and Joshi 2003, except that 
they do not have argument variables. These rep-
resentations consist of a set of formulas (typed ?-
expressions with labels) and a set of scope con-
straints.  
Each semantic representation is linked to a 
feature structure. Feature structures, as illustrated 
by different examples below, include a feature i 
whose values are individual variables and fea-
tures p and MaxS, whose values are proposi-
tional labels. Semantic composition consists of 
feature unification. After having performed all 
unifications, the union of all semantic representa-
tions is built.  
Consider, for example, the semantic represen-
tations and feature structures associated with the 
elementary trees of the sentence shown in (3).    
 
(3)  Mary dates Bill 
            S                         
                            l1: date(v1, v2 ) 
    NP      VP             
[i:v1]             
       date             NP    [i: v2]          
 
   NP                            NP           
          Mary(x)                     Bill (y) 
 
  Mary                       Bill            
  [i: x]                        [i: y]  
 
 
91
Derivation tree:      date 
                            1       2 
                       mary            bill 
 
Semantic composition proceeds on the derivation 
tree and consists of feature unification:  
 
(4)      l1: date(v1, v2 )                                                               
              1 [i: v1]                                                                      
              2 [i: v2 ]                                               
              1             2                                                                                 
                                                                  
    mary(x)               bill(y) 
     [i: x]                      [i: y]    
                   
Performing two unifications,  v1=x, v2=y, we ar-
rive at the final interpretation of this sentence: 
l1: date(x, y), bill(y), mary(x). This representa-
tion is interpreted conjunctively, with free vari-
ables being existentially bound.    
Quantificational NPs are analyzed as multi-
component TAGs, where the scope part of the 
quantifier introduces the proposition containing 
the quantifier, and the predicate-argument part 
introduces the restrictive clause (see Kallmeyer 
and Joshi 2003).  
 
(5) Every student likes some course 
.       S*                                                      S 
                                                                                                  
                                       
         NP [i: x, p: P1]                       NP           VP                          
                                        [p: l1, i: v1]                                 
every  student                                      likes      NP                     
                                              l1: like(v1, v2)   [p:l1, i:v2]                                  
                                                   
                                       
 
.       S*                                               
                                                                                                  
                                       
         NP [i: y, p: P2]                  
                                         
    Some course 
 
      
 
 
Final representation   
 
 
 
 
 
 
 
The final representation of this sentence is un-
derspecified for scope, given that there are no 
constraints which restrict the relative scope of 
every and some. In order to obtain one of the 
readings, a disambiguation mapping is needed: 
Disambiguations:                                                           
1. R2 ->l4, R3 ->l5, N2 ->l1, N3 -> l2:   
some(y,course(y), every(x,student(x), like(x, y))) 
2. R2->l4, R3->l5, N3->l1, N2->l3:                                                     
every(x, student(x), some(y, course(y), like(x, y)) 
 
Disambiguations are functions from proposi-
tional variables to propositional labels that re-
spect the scope constraints, such that after having 
applied this mapping, the transitive closure of the 
resulting scope is a partial order.  
3 The Problem of Ellipsis Resolution in 
LTAG semantics 
Given LTAG semantics, there are two possible 
approaches to resolution of the elided material: 
reconstruction can be done as part of the unifica-
tion process or as part of the disambiguation pro-
cedure. If reconstruction was done as unification, 
the semantic representation of the elided material 
would be disambiguated in the final representa-
tion. On the other hand, it is well known that 
resolution of ellipsises and gaps can be ambigu-
ous. For example, the sentence in (6), discussed 
in Siegel 1987 and Johnson 2003 among others, 
has 2 interpretations:1 
 
(6) Ward can?t eat caviar and his guests -- dried 
beans
Can?t (eat (ward, caviar)) & eat (his guests, dried 
beans)) 
Can?t (eat(ward, caviar)) & can?t (eat(his guests, 
dried beans))                                                                              
 
As this example shows, the gap in (6) can be re-
constructed by selecting either the verb or the 
negated modal as its antecedent. The two inter-
pretations represent different scope readings be-
tween the conjunction and negation, which 
should be analyzed as underspecified in LTAG 
semantics. Resolution of gaps, therefore, cannot 
be done as part of unification, since it depends on 
the disambiguated interpretation. The question is 
whether it is possible to define an underspecified 
representation of these two readings, and what 
kind of resolution mechanism can be used to dis-
ambiguate these interpretations? 
                                                
1
 Other cases of ambiguous interpretations of the elided 
material are discussed in section 7. 
l2: every(x, R2, N2) 
l3: some(y, R3, N3) 
l4: student(x) 
l4 ? R2, P1 ? N2 
l5: course(y) 
l5 ? R3, P2 ? N3 
  l2: every(x, R2, N2) 
l4: student(x)  l4 ?R2 
l3: some(y, R3, N3) 
l5: course(y)  l5 ? R3 
l1: like(x, y)   l1 ?N2   l1 ?N3 
 
92
4 LTAG Semantics of Gapping  
In LTAG semantics, semantic representations are 
introduced by lexicalized trees. In order to ac-
count for the analysis of gapping and VP ellipsis, 
this paper proposes that semantics should be de-
fined on both lexicalized and non-lexicalized 
trees. Specifically, we propose that  
Interpretation of a gap (or elided VP) is the se-
mantic interpretation of a non-lexicalized S tree. 
The semantic representations of lexicalized S 
trees under this new approach are derived com-
positionally, given the meaning of a nonlexical-
ized S tree and the meaning of a verb.  
(7)      S                                       
  
 NP[i:v1]  VP          V [Ag: v3, Pat: v4, MaxS: C1]             
                                      
                               date        l0: date(v3, v4), l0?C1                                                                             
        V            NP [i:v2] 
[Ag: v, Pat: u, MaxS: C]     
l2: ?u?v.C (v2)(v1)  
 
Non-lexicalized trees introduce a propositional 
label and a propositional variable, illustrated by 
l2 and C above.  If a tree is a transitive S-tree, 
there are two lambda bound variables, which cor-
respond to the Agent and Patient features of the 
verb. Performing feature unifications (v3=v, 
v4=u,C1=C) and scope constraint disambigua-
tions (C->l0), the proposition l2 will be reduced to: 
?u.?v.date(v, u)(v2)(v1)= date(v1, v2).  
Given this proposal, we suggest that the se-
mantics of gaps, VPE and other types of elided 
material is introduced by non-lexicalized trees. 
For example, the analysis of the sentence in (2) is 
shown in (7). Performing feature unifications 
(l2=P1, l3=P2, v=v1=v2, u=u1=u2, C=C1=C2) yields 
the final representation, where l2 and l3 are un-
derspecified. There is only one disambiguation 
of the variable C in this sentence: C -> l0, which 
gives us the desired interpretation of the sen-
tence: 
 
l2: ?u?v.eat(v, u) (y)(x) = eat(x, y) 
l3: ?u?v.eat(v, u) (w)(z) = eat(z, w) 
 
Resolution of the gap in this sentence is en-
forced by the feature structure of ?and?, which 
unifies MaxS as well as Agent and Patient fea-
tures. This analysis therefore accounts for the 
fact that gapping ?is intimately entangled with 
the syntax of coordination (as opposed to VP 
ellipsis)? (Johnson 2003). On the other hand, as 
the next example illustrates, it is crucial that pro-
positional variables introduced by non-
lexicalized trees are not unified during semantic 
composition, but rather are identified with their 
antecedents as part of the disambiguation proce-
dure.  
 
(7) Mary ate beans and others -- rice.  
 
          S   [p: l2, Ag: v1, Pat: u1, MaxS:C1]      
                
  Mary    VP 
                                                                                                              
        V         beans 
      eat           
          S 
 
 
  S   [p: P1, Ag: v, Pat: u, MaxS:C]             
 
      and          S   [p: P2, Ag: v, Pat: u, MaxS:C]      
  l1: P1 ? P2 
 
          S    [p:l3, Ag:v2, Pat:u2, MaxS:C2]          
                   
others      VP 
 
                          rice 
 
Final Representation: 
 
 
 
 
 
The sentence in (8), shown below, differs from 
the previous one in the presence of a negated 
modal. The interpretation of this modal intro-
duces a proposition l9: can?t(N9) and a constraint 
P3 ? N9 . After P3 is unified with the proposition 
l0, the final representation has two constraints on 
the variable l0: l0? C and l0? N9, and therefore 
two possible disambiguations. In the disambigua-
tion 1, C is mapped to l0, introduced by the verb 
?eat?, and propositions l2 and l3 are reduced to 
eat(x, y) and eat(z, w). In the disambiguation 2, 
the variable C is mapped to l9, introduced by the 
modal, and l2 and l3 are reduced to can?t(eat(x, 
y)) and can?t(eat(z, w)). These disambiguations 
yield the desired interpretations of this sentence.  
 
 (8) Ward can?t eat caviar and his guests -- dried 
beans  
l3: ?u2?v2.C2 (w)(z) 
others(z), rice(w) 
l2: ?u1 ?v1.C1 (y)(x)  
l0:  eat(v1, u1), l0? C1 
Mary(x), beans(y)  
 
l1: l2 ? l3                     
l2: ?u?v.C (y)(x)            l3: ?u?v.C (w)(z) 
l0: eat(v, u)   l0 ? C  
mary(x), beans(y), others(z), rice(w) 
 
93
          S   [p: l2, Ag: v1, Pat: u1, MaxS:C1]      
                
  Ward    VP [p: l0] 
                                                                                                                            
        V          caviar 
      eat                                       
 
                                VP [p: P3] 
                                           
        S             Can?t      VP   l9: can?t(N9)  P3 ? N9     
 
  S   [p: P1, Ag: v, Pat: u, MaxS:C]             
 
      and          S   [p: P2, Ag: v, Pat: u, MaxS:C]      
l1: P1 ? P2 
 
          S    [p:l3, Ag:v2, Pat:u2, MaxS:C2]          
                   
guests      VP 
 
                          beans 
Final Representation 
 
 
 
 
Disambiguation 1:  C->l0, N9 ->l1:     
can?t (eat(x, y) ? eat(z, w)) 
             l2                  l3 
 
Disambiguation 2:  C->l9, N9->l0:     
can?t(eat(x, y))  ?  can?t (eat(z, w))  
        l2                               l3 
 
Resolution of gaps under this analysis is done as 
part of the scope resolution procedure on under-
specified representations. A crucial feature of 
this analysis is that the propositions l2 and l3 are 
?underspecified? in the final representation and 
the variable C is computed during the 
disambiguation, i.e. when all scope ambiguities 
are being resolved.  In this respect this analysis 
differs from previous approaches, where the final 
representation did not include any variables, ex-
cept for the arguments of quantifiers or other 
scopal elements.2 
                                                
2
 However, see Babko-Malaya 2004, where a similar 
analysis is proposed to account for the semantics of coor-
dinated structures with quantified NPs.  
5 LTAG Analysis of VP Ellipsis 
The analysis of gapping presented above can be 
easily extended to the analysis of VP ellipsis. 
VPE differs from gapping in that it is not re-
stricted to coordinated structures. Whereas in the 
examples above resolution of gaps was enforced 
by the feature structure of ?and?, in the case of 
VPE, a similar unification, forced by pragmatic 
constraints, results in recovering the elided mate-
rial.  
As the example in (9) illustrates, our analysis 
of VPE assumes the following modification of 
the semantics of non-lexicalized trees: proposi-
tions introduced by non-lexicalized trees have 
one lambda-bound variable, so that each argu-
ment is introduced by a separate proposition. For 
example, the interpretation of a transitive tree 
below has two propositions l1 and l2, and two 
propositional variables C1 and C2. The proposi-
tion l2 corresponds to the meaning of a VP, 
which is missing in the standard TAG-based 
analyses
.
 This decomposition of the meaning of a 
nonlexicalized tree, therefore, can be independ-
ently motivated by the existence of modifiers 
which predicate of VPs. We further assume that 
the MaxS feature of the S tree corresponds to the 
variable introduced by the agent (or the highest-
ranked argument). 
 
(9)    Mary likes Bill. Jane does too.                                                     
 
                S  [Ag: v, Pat: u, MaxS: C1]                                             
 
[i:v3] NP       VP                                                                              
                               
NP [i:x]   V           NP  [i: v4]                                                
mary(x)      [Ag: v, Pat: u, MaxS: C2]                                   
   
                                   NP[i: y]  bill(y           
               V [Ag: v3, Pat: v4, MaxS: C]             
                                                                                        
               like      l0: like(v3, v4) l0?C                      
   
Final 
Representation: 
 
 
 
Applying disambiguations C2 -> l0, C1 -> l2 , we 
derive the following propositions: 
 
l2: ?u.like(v, u) (y)=like(v, y) 
l1: ?v.like(v, y) (x)=like(x, y) 
 
l3: ?u2?v2.C2 (w)(z) 
guests(z), beans(w) 
l2: ?u1 ?v1.C1 (y)(x)  
l0:  eat(v1, u1), l0? C1 
ward(x), caviar(y)  
l1: l2 ? l3           l0:  eat(v, u)   
l9: can?t(N9)       l0? N9     l0? C  
l2: ?u?v C (y)(x)     l3: ?u?v C (w)(z)       
guests(z), beans(w), caviar(y), ward(x)  
 
l1: ?v C1 (v3)  
l2: ?u C2 (v4)    l2 ? C1 
 
l1: ?v C1 (x)  
l2: ?u C2 (y)    l2 ? C1 
l0:  like(v, u),  l0? C2 
Mary(x), Bill(y)  
 
94
Now consider the second sentence: Jane does 
too: 
          S   [Ag: v3,  MaxS: C3]                                                            
 
NP[i:v5]  VP        l3: ?v3.C3 (v5)                                
                
 
NP [i: r]     V                                                                                           
  jane(r) 
 
Final 
Representation: 
 
This sentence introduces an intransitive tree and 
one propositional variable C3. This variable is 
not constrained within the sentence, and parallel 
to other pro-forms, it gets its interpretation from 
the previous discourse. Specifically, the interpre-
tation of the second sentence is derived by unifi-
cation of the S features of the second and the first 
S-trees in (9):  C3=C1, v3=v. Given that C1 is 
mapped to l2 above, it corresponds to the propo-
sition being reconstructed:  C3(=C1) -> l2 
l3: ?v.like(v, u) (r) = like(r, u) 
6 Scope Parallelism 
Many previous approaches impose parallelism 
constraints on the interpretation of the elided ma-
terial (e.g. Fox 2000, Asher et al2001 among 
others). Under the present analysis, scope paral-
lelism comes for free. Consider, for example, the 
following sentence discussed in Dalrymple et al
1991, among others, where ambiguity is resolved 
in the same way in both the antecedent and at the 
ellipsis site: John gave every student a test, and 
Bill did too. The final interpretation of the first 
sentence is given in (10) and has 2 possible dis-
ambiguations.  
 
 (10) John gave every student a test. 
 
 
 
 
 
 
 
 
The surface reading (every >> some) is derived 
by the following mapping:  C3->l0, C2->l3, R7->l8, 
N5 -> l2,  C1-> l7,  R5->l9, N7 -> l5  
l2: give(v, y, z) 
l5: some(x, test(x), give(v, y, z)) 
l7:every(y,student(y),some(x,test(x),give(v,y, z))) 
l1:every(y,student(y),some(x,test(x),give(x, y, z))) 
The interpretation of the second sentence is 
derived by unifying the S-features of the S-trees 
(as shown in the previous section). As the result, 
the variables C3 and v3 are unified with the vari-
ables C1 and v. Given that C1 is being mapped to 
the proposition l7 above, C3 is being recon-
structed as the proposition every(y, student(y), 
some(x, test(x), give(v, y, z)) and l3 corresponds 
to the desired reading of this sentence:   
  
(11) Bill did too.  
 
C3 (=C1) -> l7  
                                        v3=v 
l3: ?v. every(y, student(y),some(x, test(x), give(v, 
y, z))) (r) = every(y, student(y), some(x, test(x), 
give(r, y, z)))    
The inverse reading (where some>>every) can 
be obtained by the following mapping C3->l0,  
C2->l3, R7->l8, N7 -> l2,  C1-> l5,  R5->l9, N5 -> l7  
l2: give(v, y, z) 
l7: every(y, student(y), give(v, y, z)) 
l5:some(x,test(x),every(y,student(y),give(v,y, z))) 
l1: some(x,test(x),every(y,student(y),give(x, y, z))) 
 Now, when the second sentence is interpreted, 
C3 is unified with C1, which is being mapped to 
l5: C3(=C1) -> l5. The proposition l3, then, is re-
duced to: ?v.some(x, test(x), every(y, student(y), 
give(v, y, z))) (r) = some(x, test(x), every(y, stu-
dent(y), give(r, y, z))) 
As this example illustrates, scope parallelism 
follows from the present analysis, given that C3 
is unified with a disambiguated interpretation of 
a VP. It can also be shown that the wide scope 
puzzle (Sag 1980), shown in (12) is not unex-
pected under this approach, however, the analy-
sis of this phenomenon is beyond the scope of 
this paper. 3  
 
(12) A nurse saw every patient. Dr.Smith did too. 
some(x, nurse(x), every(y, patient(y), see(x, y))) 
*every(y, patient(y), some(x, nurse(x), see(x, y))) 
 
                                                
3
 As Hirschbuhler 1982, Fox 2000 among others noted,  
there are constructions where subjects of VPE  can have 
narrow scope relative to nonsubjects.  For example, the 
sentence A Canadian flag was hanging in front of every 
building. An American flag was too  has a reading in which 
each building has both an American and a Canadian flag 
standing in front of it.  The existence of such readings does 
not present a problem for the present analysis, if we adopt 
an analysis of quantificational NPs  proposed in Babko-
Malaya 2004.   
 
l3: ?v3 C3 (r)  
Jane(r) 
 
l4:  Bill(r) 
l3:  ?v3.C3 (r) 
 
l0:  give(v, u, w) 
l1: ?v.C1 (x)      l2: ?u.C2 (y)    l2 ? C1 
l3: ?w.C3 (z)           l3 ? C2 
l7:  every(y, R7, N7)     l5: some(z, R5, N5) 
l8:  student(y)     l9: test(z)    john(x) 
l0? C3 l0? N5 l0? N7 l8? R7 l9? R5  
95
7 Antecedent Contained Deletion(ACD) 
Further evidence for the proposed analysis comes 
from sentences with ACD, discussed in Sag 
1980, Egg and Erk 2001, Asher et al2001, Ja-
cobson (to appear), and illustrated in (13): 
 
(13) John wants Mary to read every book Bill 
does.  
 
The elided material in this sentence is under-
stood as either ?Bill reads? or ?Bill wants Mary 
to read?. Given that ?want? and ?every? can take 
different scope, four possible readings are ex-
pected. However, puzzling in this case is the un-
availability of one of these readings: *John wants 
that for every book that Bill wants Mary to read, 
she reads it. Let us consider the final interpreta-
tion of this sentence: 
 
 
 
 
 
 
 
 
 
The non-lexicalized S tree introduces a proposi-
tion l3 and variables C and v3. These variables 
can be unified with either S features of the 
?read?-tree (i.e. C1 and v), or S features of the 
?want?-tree (i.e. C2 and v0).  In the first case, the 
small ellipsis interpretation is derived, and both 
scope readings are available: C = C1, v3 = v   
C/C1 -> l6, C4-> l1  
 
l2: read(x, y),   l3: read(z, y) 
every >> want:   
N5 -> lo, C2 -> l4, N4 -> l2, R5 ->l8 
l5:every(y, book(y)&read(z, y),want(r, read(x, y)) 
                                      l3                                            l2 
want >> every: 
C2 -> l4,  N4 -> l5, N5 -> l2, R5 ->l8 
l0:want(r,every(y,book(y)&read(z,y), read(x, y))) 
                                                      l3                      l2 
If C and v3 are unified with S features of the 
?want?-tree, then the large ellipsis interpretation 
is derived: C = C2, v3 = v0, C/C2 -> l4, N4 -> l2, C4 
-> l1, C1 -> l6 
l0: want(r, read(x, y)),     l3: want(z, read(x, y)) 
 
The reading where every >> want is derived by 
the following constraints: N5-> l0, C1-> l1, R5 ->l8  
l5: every(y, book(y) & want(z, read(x,y)),  
want(r, read(x, y))                     l3 
           l0 
The fourth possible reading, where want >> 
every, however, is predicted to be unavailable 
under the present assumptions. This reading, 
want(r, every(y, book(y) & want(z, read(x, y)), 
read(x, y)),  cannot be derived, since it requires 
the proposition l3 to be ?inserted? within the 
proposition l0. 
References 
Asher N., D. Hardt and J.Busquets. 2001. Discourse 
Parallelism, Scope, and Ellipsis?, Journal of Se-
mantics, 18(1), pp. 1-25.   
Babko-Malaya O. 2004 ?LTAG Semantics of NP-
Coordination? in Proc. of TAG+7, Vancouver  
Dalrymple M., S.Shieber and F.Pereira 1991. Ellipsis 
and Higher-Order Unification. In Linguistics and 
Philosophy 14. 
Egg, M. and K.Erk 2001. A compositional approach 
to VP ellipsis 8th International Conference on 
HPSG,Trondheim, Norway 
Fiengo R. and R. May 1994. Indices and Identity. 
MIT Press, Cambridge 
Fox, D. 2000 Economy and Semantic Intepretation, 
MIT Press  
Hardt, D. 1993. VP Ellipsis: Form, Meaning and 
Processing. PhD Diss. Univ. of PA  
Hardt, D. 1999. Dynamic Interpretation of VP Ellip-
sis. Linguistics and Philosophy. 22.2. Heim, I. 
2001 
Jacobson, P. (to appear) Direct Compositionality and 
Variable-Free Semantics: The Case of Antecedent 
Contained Deletion?, in K. Johnson (ed.), Topics in 
Ellipsis, Oxford University Press. 
Johnson, K. 2003. In search of the Middle Field. Ms. 
Univ. of Mass.  
Joshi A. and Y. Schabes 1997. Tree-Adjoining 
Grammars, in G. Rozenberg and A. Salomaa (eds.) 
Handbook of Formal Languages, Springer, Berlin  
Kallmeyer, L. and A.K Joshi 2003. Factoring Predi-
cate Argument and Scope Semantics:  Underspeci-
fied Semantics with LTAG. Research on Language 
and Computation 1(1-2), 358. 
Kallmeyer, L. and M. Romero. 2004. LTAG Seman-
tics with Semantic Unification. In Proceedings of  
TAG+7, Vancouver, Canada  
Sag, Ivan 1980 Deletion and Logical Form. Garland 
Press: New York 
Shieber, S., F.Pereira, and M.Dalrymple 1996. Inter-
actions of Scope and Ellipsis. In Linguistics and 
Philosophy 19, pp.527-552. 
l4: want(v0, N4)    l0: ?v0.C2 (want) (r) 
l1: read(v, u)   l2: ?v.C1 (read) (x)  
l6: ?u.C4 (read) (y)     l6 ? C1    l8: book(y) ? l3 
l5: every(y, R5, N5)     l3: ?v3.C (z) 
mary(x),  john(r), bill(z) 
l1? C1, l4? C2, l1? N5, l8? R5, l1?N4 
 
96
