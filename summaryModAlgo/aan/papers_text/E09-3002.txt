Proceedings of the EACL 2009 Student Research Workshop, pages 10?18,
Athens, Greece, 2 April 2009. c?2009 Association for Computational Linguistics
A Memory-Based Approach to the Treatment of Serial Verb Construction
in Combinatory Categorial Grammar
Prachya Boonkwan??
? School of Informatics ? National Electronics
University of Edinburgh and Computer Technology Center
10 Crichton Street 112 Phahon Yothin Rd.
Edinburgh EH8 9AB, UK Pathumthani 12120, Thailand
Email: p.boonkwan@sms.ed.ac.uk
Abstract
CCG, one of the most prominent grammar
frameworks, efficiently deals with deletion
under coordination in natural languages.
However, when we expand our attention
to more analytic languages whose degree
of pro-dropping is more free, CCG?s de-
composition rule for dealing with gapping
becomes incapable of parsing some pat-
terns of intra-sentential ellipses in serial
verb construction. Moreover, the decom-
position rule might also lead us to over-
generation problem. In this paper the
composition rule is replaced by the use
of memory mechanism, calledCCG-MM.
Fillers can be memorized and gaps can be
induced from an input sentence in func-
tional application rules, while fillers and
gaps are associated in coordination and se-
rialization. Multimodal slashes, which al-
low or ban memory operations, are utilized
for ease of resource management. As a
result, CCG-MM is more powerful than
canonical CCG, but its generative power
can be bounded by partially linear indexed
grammar.
1 Introduction
Combinatory Categorial Grammar (CCG, Steed-
man (2000)) is a prominent categorial grammar
framework. Having a strong degree of lexical-
ism (Baldridge and Kruijff, 2003), its grammars
are encoded in terms of lexicons; that is, each lex-
icon is assigned with syntactic categories which
dictate the syntactic derivation. One of its strik-
ing features is the combinatory operations that al-
low coordination of incomplete constituents. CCG
is nearly context-free yet powerful enough for
natural languages as it, as well as TAG, LIG,
and HG, exhibits the lowest generative power in
the mildly context-sensitive grammar class (Vijay-
Shanker and Weir, 1994).
CCG accounts for gapping in natural languages
as a major issue. Its combinatory operations re-
solve deletion under coordination, such as right-
node raising (SV&SVO) and gapping (SVO&SO).
In case of gapping, a specialized rule called de-
composition is used to handle with forward gap-
ping (Steedman, 1990) by extracting the filler re-
quired by a gap from a complete constituent.
However, serial verb construction is a challeng-
ing topic in CCG when we expand our attention
to more analytic languages, such as Chinese and
Thai, whose degree of pro-dropping is more free.
In this paper, I explain how we can deal with
serial verb construction with CCG by incorpo-
rating memory mechanism and how we can re-
strict the generative power of the resulted hy-
brid. The integrated memory mechanism is mo-
tivated by anaphoric resolution mechanism in Cat-
egorial Type Logic (Hendriks, 1995; Moortgat,
1997), Type Logical Grammar (Morrill, 1994;
Ja?ger, 1997; Ja?ger, 2001; Oehrle, 2007), and CCG
(Jacobson, 1999), and gap resolution in Memory-
Inductive Categorial Grammar (Boonkwan and
Supnithi, 2008), as it is designed for associating
fillers and gaps found in an input sentence. Theo-
retically, I discuss how this hybrid efficiently helps
us deal with serial verb construction and how far
the generative power grows after incorporating the
memory mechanism.
Outline: I introduce CCG in ?2, and then mo-
tivate the need of memory mechanism in dealing
with serial verb construction in CCG in ?3. I de-
scribe the hybrid model of CCG and the filler-gap
memory in ?4. I then discuss the margin of gener-
ative power introduced by the memory mechanism
in ?5. Finally, I conclude this paper in ?6.
10
2 Combinatory Categorial Grammar
CCG is a lexicalized grammar; i.e. a grammar is
encoded in terms of lexicons assigned with one
or more syntactic categories. The syntactic cat-
egories may be atomic elements or curried func-
tions specifying linear directions in which they
seek their arguments. A word is assigned with a
syntactic category by the turnstile operator `. For
example, a simplified English CCG is given below.
(1) John ` np sandwiches ` np
eats ` s\np/np
The categories X\Y (and X/Y) denotes that X seeks
the argument Y from the left (right) side.
Combinatory rules are used to combine words
forming a derivation of a sentence. For basic
combination, forward (>) and backward (<) func-
tional applications, defined in (2), are used.
(2) X/Y Y ? X [>]
Y X\Y ? X [<]
We can derive the sentence John eats sandwiches
by the rules and the grammar in (1) as illustrated
in (3). CCG is semantic-transparent; i.e. a logical
form can be built compositionally in parallel with
syntactic derivation. However, semantic interpre-
tation is suppressed in this paper.
(3) John eats sandwiches
np s\np/np np
s\np
s
For coordination of two constituents, the coor-
dination rules are used. There are two types of
coordination rules regarding their directions: for-
ward coordination (> &) and backward coordina-
tion (< &), defined in (4).
(4) & X ? [X]& [> &]
X [X]& ? X [< &]
By the coordination rules, we can derive the sen-
tence John eats sandwiches and drinks coke in (5).
(5) John eats sandwiches and drinks coke
np s\np/np np & s\np/np np
> >
s\np s\np
>&
[s\np]&
<&
s\np
<
s
Beyond functional application and coordina-
tion, CCG also makes use of rules motivated by
combinators in combinatory logics: functional
composition (B), type raising (T), and substitution
(S), namely. Classified by directions, the func-
tional composition and type raising rules are de-
scribed in (6) and (7), respectively.
(6) X/Y Y/Z ? X/Z [> B]
Y\Z X\Y ? X\Z [< B]
(7) X ? Y/(Y\X) [> T]
X ? Y\(Y/X) [< T]
These rules permit associativity in derivation re-
sulting in that coordination of incomplete con-
stituents with similar types is possible. For ex-
ample, we can derive the sentence John likes but
Mary dislikes sandwiches in (8).
(8) John likes but Mary dislikes sandwiches
np s\np/np & np s\np/np np
>T >T
s/(s\np) s/(s\np)
>B >B
s/np s/np
>&
[s/np]&
<&
s/np
>
s
CCG also allows functional composition with
permutation called disharmonic functional com-
position to handle constituent movement such as
heavy NP shift and dative shift in English. These
rules are defined in (9).
(9) X/Y Y\Z ? X\Z [> B?]
Y/Z X\Y ? X/Z [< B?]
By disharmonic functional composition rules,
we can derive the sentence I wrote briefly a long
story of Sinbad as (10).
(10) I wrote briefly a long story of Sinbad
np s\np/np s\np\(s\np) np
>B?
s\np/np
>
np
<
s
To handle the gapping coordination SVO&SO,
the decomposition rule was proposed as a separate
mechanism from CCG (Steedman, 1990). It de-
composes a complete constituent into two parts for
being coordinated with the other incomplete con-
stituent. The decomposition rule is defined as fol-
lows.
(11) X ? Y X\Y [D]
where Y and X\Ymust be seen earlier in the deriva-
tion. The decomposition rule allows us to de-
rive the sentence John eats sandwiches, and Mary,
noodles as (12). Steedman (1990) stated that En-
glish is forward gapping because gapping always
11
takes place at the right conjunct.
(12) John eats sandwiches and Mary noodles
np s\np/np np & np np
> >T <T
s\np s/VP VP\(VP/np)
< >B?
s s\(VP/np)
D >&
VP/np s\(VP/np) [s\(VP/np)]&
<&
s\(VP/np)
<
s
where VP = s\np.
A multimodal version of CCG (Baldridge,
2002; Baldridge and Kruijff, 2003) restricts gener-
ative power for a particular language by annotating
modalities to the slashes to allow or ban specific
combinatory operations. Due to the page limita-
tion, the multimodal CCG is not discussed here.
3 Dealing with Serial Verb Construction
CCG deals with deletion under coordination by
several combinatory rules: functional composi-
tion, type raising, disharmonic functional compo-
sition, and decomposition rule. This enables CCG
to handle a number of coordination patterns such
as SVO&VO, SV&SVO, and SVO&SO. However,
the decomposition rule cannot solve some patterns
of SVC in analytic languages such as Chinese and
Thai in which pro-dropping is prevalent.
The notion serial verb construction (SVC) in
this paper means a sequence of verbs or verb
phrases concatenated without connectives in a sin-
gle clause which expresses simultaneous or con-
secutive events. Each of the verbs is marked or un-
derstood to have the same grammatical categories
(such as tense, aspect, and modality), and shares
at least one argument, i.e. a grammatical subject.
As each verb is tensed, SVC is considered as coor-
dination with implicit connective rather than sub-
ordination in which either infinitivization or sub-
clause marker is made use. Motivated by Li and
Thompson (1981)?s generalized form of Chinese
SVC, the form of Chinese and Thai SVC is gener-
alized in (13).
(13) (Subj)V1(Obj1)V2(Obj2) . . .Vn(Objn)
The subject Subj and any objects Obji of the verb
Vi can be dropped. If the subject or one of the ob-
jects is not dropped, it will be understood as lin-
early shared through the sequence. Duplication of
objects in SVC is however questionable as it dete-
riorates the compactness of utterance.
In order to deal with SVC in CCG, I considered
it syntactically similar to coordination where the
connective is implicit. The serialization rule (?)
was initially defined by imitating the forward co-
ordination rule in (14).
(14) X ? [X]& [?]
This rule allows us to derive by CCG some types
of SVC in Chinese and Thai as exemplified in (15)
and (16), respectively.
(15) wo?
I
zhe?
fold
zh??
paper
zuo`
make
y??
one
ge
CL
he?zi
box
?I fold paper to make a box.?
(16) khao
he
r:p
hurry
VN
run
k
h
a:m
cross
t
h
 anon
road
?He hurriedly runs across the road.?
One can derive the sentence (15) by considering
zhe? ?fold? and zuo` ?make? as s\np/np and ap-
plying the serialization rule in (14). In (16), the
derivation can be done by assigning r:p ?hurry?
and VN ?run? as s\np, and kha:m ?cross? as
s\np/np.
Since Chinese and Thai are pro-drop languages,
they allow some arguments of the verbs to be pro-
dropped, particularly in SVC. For example, let us
consider the following Thai sentence.
(17) kla:
Kla
p	aj
goDIR
t	a:m
followV1
ha:
seekV2
n	aj
in
raj;POi
cane-field
tc	@:
findV3
l	a:j
Laay
tc a
FUT
d	@:n
walkV4
tc a:k
leaveV5
p	aj
goDIR
Lit: ?Kla goes out, he follows Laay (his cow), he
seeks it in the cane field, and he finds that it will
walk away.?
Sem: ?Kla goes out to seek Laay in the cane field
and he finds that it is about to walk away.?
The sentence in (17) are split into two SVCs: the
series of V1 to V3 and the series of V4 to V5, be-
cause they do not share their tenses. The direc-
tional verb p	aj ?go? performs as an adverb identi-
fying the outward direction of the action.
Syntactically speaking, there are two possible
analyses of this sentence. First, we can consider
the SVC V4 to V5 as a complement of the SVC
V1 to V3. Pro-drops occur at the object positions
of the verbs V1, V2, and V3. On the other hand,
we can also consider the SVC V1 to V3 and the
SVC V4 to V5 as adjoining construction (Muan-
suwan, 2002) which indicates resultative events in
Thai (Thepkanjana, 1986) as exemplified in (18).
(18) p t 
Piti
t	:
hit
N	u:
snake
t ok
fall
na:m
water
?Piti hits a snake and it falls into the water.?
12
In this case, the pro-drop occurs at the subject po-
sition of the SVC V4 to V5, and can therefore
be treated as object control (Muansuwan, 2002).
However, the sentence in (17) does not show resul-
tative events. I then assume that the first analysis
is correct and will follow it throughout this paper.
We have consequently reached the question that
the verb tc	@: ?find? should exhibit object control
by taking two arguments for the object and the
VP complementary, or it should take the entire
sentence as an argument. To explicate the prolif-
eration of arguments in SVC, we prefer the first
choice to the second one; i.e. the verb tc	@: ?find? is
preferably assigned as s\np/(s\np)/np. In (17),
the object l	a:j ?Laay? is dropped from the verbs V1
and V2 but appears as one of V3?s arguments.
Let us take a closer look on the CCG analysis
of (17). It is useful to focus on the SVCs of the
verbs V1-V2 and V3. It is shown below that the
decomposition rule fails to parse the tested sen-
tence through its application illustrated in (19).
(19) Kla go follow seek find Laay FUT walk
in cane-field leave go
np s\np/np s\np/(s\np)/np np s\np
>
s\np/(s\np)
>
s\np
D
? ? ? ? ?
The verbs V1 and V2 are transitive and assigned
as s\np/np, while V4 and V5 are intransitive and
assigned as s\np. From the case (19), it follows
that the decomposition rule cannot capture some
patterns of intra-sentential ellipses in languages
whose degree of pro-dropping is more free. Both
types of intra-sentential ellipses which are preva-
lent in SVC of analytic languages should be cap-
tured for the sake of applicability.
The use of decomposition rule in analytic lan-
guages is not appealing for two main reasons.
First, the decomposition rule does not support cer-
tain patterns of intra-sentential ellipses which are
prevalent in analytic languages. As exemplified
in (19), the decomposition rule fails to parse the
Thai SVC whose object of the left conjunct is pro-
dropped, since the right conjunct cannot be de-
composed by (11). To tackle a broader coverage of
intra-sentential ellipses, the grammar should rely
on not only decomposition but also a supplement
memory mechanism. Second, the decomposition
rule allows arbitrary decomposition which leads to
over-generation. From their definitions the vari-
able Y can be arbitrarily substituted by any syn-
tactic categories resulting in ungrammatical sen-
tences generated. For example we can derive the
ungrammatical sentence *Mary eats noodles and
quickly by means of the decomposition rule in
(20).
(20) * Mary eats noodles and quickly
np s\np/np np & s\np\(s\np)
> >&
s\np [s\np\(s\np)]&
D
s\np s\np\(s\np)
<&
s\np\(s\np)
<
s\np
<
s
The issues of handling ellipses in SVC and
overgeneration of the decomposition rule can be
resolved by replacing the decomposition rule with
a memory mechanism that associates fillers to
their gaps. The memory mechanism also makes
grammar rules more manageable because it is
more straightforward to identify particular syn-
tactic categories allowed or banned from pro-
dropping. I will show how the memory mecha-
nism improves the CCG?s coverage of serial verb
construction in the next section.
4 CCG with Memory Mechanism
(CCG-MM)
As I have elaborated in the last section, CCG
needs a memory mechanism (1) to resolve intra-
sentential ellipses in serial verb construction of an-
alytic languages, and (2) to improve resource man-
agement for over-generation avoidance. To do so,
such memory mechanism has to extend the gener-
ative power of the decomposition rule and improve
the ease of resource management in parallel.
The memory mechanism used in this paper is
motivated by a wide range of previous work from
computer science to symbolic logics. The notion
of memory mechanism in natural language pars-
ing can be traced back to HOLD registers in ATN
(Woods, 1970) in which fillers (antecedents) are
held in registers for being filled to gaps found
in the rest of the input sentence. These regis-
ters are too powerful since they enable ATN to
recognize the full class of context-sensitive gram-
mars. In Type Logical Grammar (TLG) (Morrill,
1994; Ja?ger, 1997; Ja?ger, 2001; Oehrle, 2007),
Gentzen?s sequent calculus was incorporated with
variable quantification to resolve pro-forms and
VP ellipses to their antecedents. The variable
quantification in TLG is comparable to the use
of memory in storing antecedents and anaphora.
13
In Categorial Type Logic (CTL) (Hendriks, 1995;
Moortgat, 1997), gap induction was incorporated.
Syntactic categories were modified with modal-
ities which permit or prohibit gap induction in
derivation. However, logical reasoning obtained
from TLG and CTL are an NP-complete prob-
lem. In CCG, Jacobson (1999) attempted to ex-
plicitly denote non-local anaphoric requirement
whereby she introduced the anaphoric slash (|) and
the anaphoric connective (Z) to connect anaphors
to their antecedents. However, this framework
does not support anaphora whose argument is
not its antecedent, such as possessive adjectives.
Recently, a filler-gap memory mechanism was
again introduced to Categorial Grammar, called
Memory-Inductive Categorial Grammar (MICG)
(Boonkwan and Supnithi, 2008). Fillers and gaps,
encoded as memory modalities, are modified to
syntactic categories, and they are associated by the
gap-resolution connective when coordination and
serialization take place. Though their framework
is successful in resolving a wide variety of gap-
ping, its generative power falls between LIG and
Indexed Grammar, theoretically too powerful for
natural languages.
The memory mechanism introduced in this pa-
per deals with fillers and gaps in SVC. It is similar
to anaphoric resolution in ATN, Jacobson?s model,
TLG, and CTL. However, it also has prominent
distinction from them: The anaphoric mechanisms
mentioned earlier are dealing with unbounded de-
pendency or even inter-sentential ellipses, while
the memory mechanism in this paper is dealing
only with intra-sentential bounded dependency in
SVC as generalized in (13). Moreover, choices of
filler-gap association can be pruned out by the use
of combinatory directionality because the word or-
der of analytic languages is fixed. It is notice-
able that we can simply determine the grammat-
ical function (subject or object) of arbitrary np?s
in (13) from the directionality (the subject on the
left and the object on the right). With these rea-
sons, I therefore adapted the notions of MICG?s
memory modalities and gap-resolution connective
(Boonkwan and Supnithi, 2008) for the backbone
of the memory mechanism.
In CCG with Memory Mechanism (CCG-MM),
syntactic categories are modalized with memory
modalities. For each functional application, a
syntactic category can be stored, or memorized,
into the filler storage and the resulted category is
modalized with the filler 2. A syntactic category
can also be induced as a gap in a unary deriva-
tion called induction and the resulted category is
modalized with the gap 3.
There are two constraint parameters in each
modality: the combinatory directionality d ? {<
,>} and the syntactic category c, resulting in the
filler and the gap denoted in the forms 2dc and 3
d
c ,
respectively. For example, the syntactic category
2<np3
>
nps has a filler of type np on the left side and
a gap of type np on the right side.
The filler 2dc and the gap 3
d
c of the same di-
rectionality and syntactic categories are said to be
symmetric under the gap-resolution connective ?;
that is, they are matched and canceled in the gap
resolution process. Apart from MICG, I restrict
the associative power of ? to match only a filler
and a gap, not between two gaps, so that the gener-
ative power can be preserved linear. This topic will
be discussed in ?5. Given two strings of modali-
ties m1 and m2, the gap-resolution connective ?
is defined in (21).
(21) 2dcm1 ?3
d
cm2 ? m1 ?m2
3dcm1 ? 2
d
cm2 ? m1 ?m2
?  ? 
The notation  denotes an empty string. It means
that a syntactic category modalized with an empty
modality string is simply unmodalized; that is, any
modalized syntactic categories X are equivalent to
the unmodalized ones X.
Since the syntactic categories are modalized by
a modality string, all combinatory operations in
canonical CCG must preserve the modalities af-
ter each derivation step. However, there are two
conditions to be satisfied:
Condition A: At least one operands of functional
application must be unmodalized.
Condition B: Both operands of functional com-
position, disharmonic functional composi-
tion, and type raising must be unmodalized.
Both conditions are introduced to preserve the
generative power of CCG. This topic will be dis-
cussed in ?5.
As adopted from MICG, there are two memory
operations: memorization and induction.
Memorization: a filler modality is pushed to
the top of the memory when an functional appli-
cation rule is applied, where the filler?s syntactic
category must be unmodalized. Let m be a modal-
14
ity string, the memorization operation is defined in
(22).
(22) X/Y mY ? 2<X/YmX [> MF ]
mX/Y Y ? 2>Y mX [> MA]
Y mX\Y ? 2<Y mX [< MA]
mY X\Y ? 2>X\YmX [< MF ]
Induction: a gap modality is pushed to the top
of the memory when a gap of such type is induced
at either side of the syntactic category. Let m be a
modality string, the induction operation is defined
in (23).
(23) mX/Y ? 3>Y mX [> IA]
mY ? 3<X/YmX [> IF ]
mX\Y ? 3<Y mX [< IA]
mY ? 3>X\YmX [< IF ]
Because the use of memory mechanism eluci-
dates fillers and gaps hidden in the derivation, we
can then replace the decomposition rule of the
canonical CCG with the gap resolution process of
MICG. Fillers and gaps are associated in the co-
ordination and serialization by the gap-resolution
connective ?. For any given m1,m2, if m1 ? m2
exists then always m1 ? m2 ? . Given two
modality strings m1 and m2 such that m1 ? m2
exists, the coordination rule (?) and serialization
rule (?) are redefined on ? in (24).
(24) m1X & m2X ? X [?]
m1X m2X ? X [?]
At present, the memory mechanism was devel-
oped in Prolog for the sake of unification mecha-
nism. Each induction rule is nondeterministically
applied and variables are sometimes left uninstan-
tiated. For example, the sentence in (12) can be
parsed as illustrated in (25).
(25) John eats sandwiches and Mary noodles
np s\np/np np & np np
>MF >IF
2
<
s\np/nps\np 3
<
X1/np
X1
< <
2
<
s\np/nps 3
<
X2\np/np
X2
?
s
Let us consider the derivation in the right conjunct.
The gap induction is first applied on np resulting
in 3<X1/npX1, where X1 is an uninstantiated vari-
able. Then the backward application is applied, so
that X1 is unified with X2\np. Finally, the left
and the right conjuncts are coordinated yielding
that X2 is unified with s and X1 with s\np. For
convenience of type-setting, let us suppose that we
can always choose the right type in each induction
step and suppress the unification process.
Table 1: Slash modalities for memory operations.
- Left + Left
- Right ? /
+ Right . ?
Once we instantiate X1 and X2, the derivation
obtained in (25) is quite more straightforward than
the derivation in (12). The filler eats is intro-
duced on the left conjunct, while the gap of type
s\np/np is induced on the right conjunct. The co-
ordination operation associates the filler and the
gap resulting in a complete derivation.
A significant feature of the memory mechanism
is that it handles all kinds of intra-sentential el-
lipses in SVC. This is because the coordination
and serialization rules allow pro-dropping in ei-
ther the left or the right conjunct. For example, the
intra-sentential ellipses pattern in Thai SVC illus-
trated in (19) can be derived as illustrated in (26).
(26) Kla go follow seek find Laay FUT walk
in cane-field leave go
np s\np/np s\np/(s\np)/np np s\np
>IA >MA
3
>
nps\np 2
>
nps\np/(s\np)
>
2
>
nps\np
?
s\np
<
s
By replacing the decomposition rule with the
memory mechanism, CCG accepts all patterns of
pro-dropping in SVC. It should also be noted that
the derivation in (20) is per se prohibited by the
coordination rule.
Similar to canonical CCG, CCG-MM is also
resource-sensitive; that is, each combinatory op-
eration is allowed or prohibited with respect to the
resource we have (Baldridge and Kruijff, 2003).
Baldridge (2002) showed that we can obtain a
cleaner resource management in canonical CCG
by the use of modalized slashes to control combi-
natory behavior. His multimodal schema of slash
permissions can also be applied to the memory
mechanism in much the same way. I assume that
there are four modes of memory operations ac-
cording to direction and allowance of memory op-
erations as in Table 1.
The modes can be organized into the type hier-
archy shown in Figure 1. The slash modality ?,
the most limited mode, does not allow any mem-
ory operations on both sides. The slash modalities
/ and . allow memorization and induction on the
15
?






?
?
?
?
?
?
?
/
?
?
?
?
?
?
?
?
.








?
Figure 1: Hierarchy of slash modalities for mem-
ory operations.
left and right sides, respectively. Finally, the slash
modality ? allows memorization and induction on
both sides. In order to distinguish the memory op-
eration?s slash modalities from Baldridge?s slash
modalities, I annotate the first as a superscript
and the second as a subscript of the slashes. For
example, the syntactic category s\/?np denotes
that s\np allows permutation in crossed functional
composition (?) and memory operations on the
left side (/). As with Baldridge?s multimodal
framework, the slash modality ? can be omitted
from writing. By defining the slash modalities, it
follows that the memory operations can be defined
in (27).
(27) mX/.Y Y ? 2>Y mX [> MF ]
X//Y mY ? 2<X//YmX [> MA]
Y mX\/Y ? 2<Y mX [< MA]
mY X\.Y ? 2>X\.YmX [< MF ]
mX/.Y ? 3>Y mX [> IA]
mY ? 3<X//YmX [> IF ]
mX\/Y ? 3<Y mX [< IA]
mY ? 3>X\.YmX [< IF ]
When incorporating with the memory mech-
anism and the slash modalities, CCG becomes
flexible enough to handle all patterns of intra-
sentential ellipses in SVC which are prevalent in
analytic languages, and to manage its lexical re-
source. I will now show that CCG-MM extends
the generative power of the canonical CCG.
5 Generative Power
In this section, we will informally discuss the mar-
gin of generative power introduced by the memory
mechanism. Since Vijay-Shanker (1994) showed
that CCG and Linear Indexed Grammar (LIG)
(Gazdar, 1988) are weakly equivalent; i.e. they
generate the same sets of strings, we will first
compare the CCG-MM with the LIG. As will be
shown, its generative power is beyond LIG; we
will find the closest upper bound in order to locate
it in the Chomsky?s hierarchy.
We will follow the equivalent proof of Vijay-
Shanker and Weir (1994) to investigate the gen-
erative power of CCG-MM. Let us first assume
that we are going to construct an LIG G =
(VN , VT , VS , S, P ) that subsumes CCG-MM. To
construct G, let us define each of its component as
follows.
VN is a finite set of syntactic categories,
VT is a finite set of terminals,
VS is a finite set of stack symbols having the form
2dc , 3
d
c , /c, or \c,
S ? VN is the start symbol, and
P is a finite set of productions, having the form
A[] ? a
A[? ? l] ? A1[] . . . Ai[? ? l
?] . . . An[]
where each Ak ? VN , d ? {<,>}, c ? VN ,
l, l? ? VS , and a ? VT ? {}.
The notation for stacks uses [? ? l] to denote an ar-
bitrary stack whose top symbol is l. The linearity
of LIG comes from the fact that in each produc-
tion there is only one daughter that share the stack
features with its mother. Let us also define ?(?)
as the homomorphic function that converts each
modality in a modality string ? into its symmetric
counterpart, i.e. a filler 2dc into a gap3
d
c , and vice
versa. The stack in this LIG is used for storing
(1) tailing slashes of a syntactic category for har-
monic/disharmonic functional composition rules,
and (2) modalities of a syntactic category for gap
resolution.
We start out by transforming the lexical item.
For every lexical item of the formw ` Xwhere X is
a syntactic category, add the following production
to P :
(28) X[] ? w
We add two unary rules for converting between
tailing slashes and stack values. For every syntac-
tic category X and Y1, . . . , Yn, the following rules
are added.
(29) X|1Y1 . . . |nYn[??] ? X[? ? |1Y1 . . . |nYn]
X[? ? |1Y1 . . . |nYn] ? X|1Y1 . . . |nYn[??]
where the top of ?? must be a filler or a gap, or
?? must be empty. This constraint preserves the
ordering of combinatory operations.
We then transform the functional application
rules into LIG productions. From Condition A,
we can generalize the functional application rules
in (2) as follows.
16
(30) mX/Y Y ? mX
X/Y mY ? mX
mY X\Y ? mX
Y mX\Y ? mX
where m is a modality string. Condition A pre-
serves the linearity of the generative power in that
it prevents the functional application rules from in-
volving the two stacks of the daughters at once.
We can convert the rules in (30) into the following
productions.
(31) X[??] ? X[? ? /Y] Y[]
X[??] ? X[/Y] Y[??]
X[??] ? Y[??] X[\Y]
X[??] ? Y[] X[? ? \Y]
We can generalize the harmonic and dishar-
monic, forward and backward composition rules
in (6) and (9) as follows.
(32) X/Y Y|1Z1 . . . |nZn ? X|1Z1 . . . |nZn
Y|1Z1 . . . |nZn X\Y ? X|1Z1 . . . |nZn
where each |i ? {\, /}. By Condition B, we ob-
tain that all operands are unmodalized so that we
can treat only tailing slashes. That is, Condition
B prevents us from processing both tailing slashes
and memory modalities at once where the linear-
ity of the rules is deteriorated. We can therefore
convert these rules into the following productions.
(33) X[??] ? X[/Y] Y[??]
X[??] ? Y[??] X[\Y]
The memorization and induction rules de-
scribed in (27) are transformed into the following
productions.
(34) X[? ? 2<X/Y] ? X[/Y] Y[??]
X[? ? 2>Y ] ? X[? ? /Y] Y[]
X[? ? 2<Y ] ? Y[] X[? ? \Y]
X[? ? 2>X\Y] ? Y[??] X[\Y]
X[? ?3>Y ] ? X[? ? /Y]
X[? ?3<X/Y] ? Y[??]
X[? ?3<Y ] ? X[? ? \Y]
X[? ?3>X\Y] ? Y[??]
However, it is important to take into account the
coordination and serialization rules, because they
involve two stacks which have similar stack val-
ues if we convert one of them into the symmetric
form with ?. Those rules can be transformed as
follows.
(35) X[] ? X[??] &[] X[?(??)]
X[] ? X[??] X[?(??)]
It is obvious that the rules in (35) are not LIG pro-
duction; that is, CCG-MM cannot be generated by
any LIGs; or more precisely, CCG-MM is prop-
erly more powerful than CCG. We therefore have
to find an upper bound of its generative power.
Though CCG-MM is more powerful than CCG
and LIG, the rules in (35) reveal a significant prop-
erty of Partially Linear Indexed Grammar (PLIG)
(Keller and Weir, 1995), an extension of LIG
whose productions are allowed to have two or
more daughters sharing stack features with each
other but these stacks are not shared with their
mother as shown in (36).
(36) A[] ? A1[] . . . Ai[??] . . . Aj [??] . . . An[]
Whereby restricting the power of the gap-
resolution connective, the two stacks of the daugh-
ters are shared but not with their mother. An in-
teresting trait of PLIG is that it can generate the
language {wk|w is in a regular language and k ?
N}. This is similar to the pattern of SVC in which
a series of verb phrase can be reduplicated.
To conclude this section, CCG-MM is more
powerful than LIG but less powerful than PLIG.
From (Keller and Weir, 1995), we can position the
CCG-MM in the Chomsky?s hierarchy as follows:
CFG < CCG = TAG = HG = LIG < CCG-MM ? PLIG
? LCFRS < CSG.
6 Conclusion and Future Work
I have presented an approach to treating serial
verb construction in analytic languages by incor-
porating CCG with a memory mechanism. In the
memory mechanism, fillers and gaps are stored
as modalities that modalize a syntactic category.
The fillers and the gaps are then associated in the
coordination and the serialization rules. This re-
sults in a more flexible way of dealing with intra-
sentential ellipses in SVC than the decomposition
rule in canonical CCG. Theoretically speaking, the
proposed memory mechanism increases the gen-
erative power of CCG into the class of partially
linear indexed grammars.
Future research remains as follows. First, I will
investigate constraints that reduce the search space
of parsing caused by gap induction. Second, I will
apply the memory mechanism in solving discon-
tinuous gaps. Third, I will then extend this frame-
work to free word-ordered languages. Fourth and
finally, the future direction of this research is to
develop a wide-coverage parser in which statistics
is also made use to predict memory operations oc-
curing in derivation.
17
References
Jason Baldridge and Geert-Jan M. Kruijff. 2003. Mul-
timodal combinatory categorial grammar. In Pro-
ceedings of the 10th Conference of the European
Chapter of the ACL 2003, pages 211?218, Budapest,
Hungary.
Jason Baldridge. 2002. Lexically Specified Deriva-
tional Control in Combinatory Categorial Gram-
mar. Ph.D. thesis, University of Edinburgh.
Prachya Boonkwan and Thepchai Supnithi. 2008.
Memory-inductive categorial grammar: An ap-
proach to gap resolution in analytic-language trans-
lation. In Proceedings of The Third International
Joint Conference on Natural Language Processing,
volume 1, pages 80?87, Hyderabad, India, January.
Gerald Gazdar. 1988. Applicability of indexed
grammars to natural languages. In U. Reyle and
C. Rohrer, editors, Natural Language Parsing and
Linguistic Theories, pages 69?94. Reidel, Dor-
drecht.
Petra Hendriks. 1995. Ellipsis and multimodal catego-
rial type logic. In Proceedings of Formal Grammar
Conference, pages 107?122. Barcelona, Spain.
Pauline Jacobson. 1999. Towards a variable-free se-
mantics. Linguistics and Philosophy, 22:117?184,
October.
Gerhard Ja?ger. 1997. Anaphora and ellipsis in type-
logical grammar. In Proceedings of the 11th Amster-
dam Colloquium, pages 175?180, Amsterdam, the
Netherland. ILLC, Universiteit van Amsterdam.
Gerhard Ja?ger. 2001. Anaphora and quantification
in categorial grammar. In Lecture Notes in Com-
puter Science; Selected papers from the 3rd Interna-
tional Conference, on logical aspects of Computa-
tional Linguistics, volume 2014/2001, pages 70?89.
Bill Keller and David Weir. 1995. A tractable exten-
sion of linear indexed grammars. In In Proceedings
of the 7th European Chapter of ACL Conference.
Charles N. Li and Sandra A. Thompson. 1981. Man-
darin Chinese: A Functional Reference Grammar.
Berkeley: University of California Press.
Michael Moortgat. 1997. Categorial type logics. In
van Benthem and ter Meulen, editors, Handbook of
Logic and Language, chapter 2, pages 163?170. El-
sevier/MIT Press.
Glyn Morrill. 1994. Type logical grammar. In Catego-
rial Logic of Signs. Kluwer, Dordrecht.
Nuttanart Muansuwan. 2002. Verb Complexes in Thai.
Ph.D. thesis, University at Buffalo, The State Uni-
versity of New York.
Richard T. Oehrle, 2007. Non-Transformational Syn-
tax: A Guide to Current Models, chapter Multi-
modal Type Logical Grammar. Oxford: Blackwell.
Mark Steedman. 1990. Gapping as constituent coordi-
nation. Linguistics and Philosophy, 13:207?263.
Mark Steedman. 2000. The Syntactic Process. The
MIT Press, Cambridge, Massachusetts.
Kingkarn Thepkanjana. 1986. Serial Verb Construc-
tions in Thai. Ph.D. thesis, University of Michigan.
K. Vijay-Shanker and David J. Weir. 1994. The equiv-
alence of four extensions of context-free grammars.
Mathematical Systems Theory, 27(6):511?546.
William A. Woods. 1970. Transition network gram-
mars for natural language analysis. Communica-
tions of the ACM, 13(10):591?606, October.
18
