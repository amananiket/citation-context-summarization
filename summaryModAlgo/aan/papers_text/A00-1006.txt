Translation using Information on Dialogue Participants 
Setsuo Yamada, E i i ch i ro  Sumi ta  and  H idek i  Kashioka 
ATR Interpreting Telecommunications Research Laboratories* 
2-2, Hikaridai, Seika-cho, Soraku-gun, 
Kyoto, 619-0288, JAPAN 
{ syamada, sumita, kashioka} @itl.atr.co.jp t 
Abstract 
This paper proposes a way to improve the trans- 
lation quality by using information on dialogue 
participants that is easily obtained from out- 
side the translation component. We incorpo- 
rated information on participants' ocial roles 
and genders into transfer ules and dictionary 
entries. An experiment with 23 unseen dia- 
logues demonstrated a recall of 65% and a preci- 
sion of 86%. These results howed that our sim- 
ple and easy-to-implement method is effective, 
and is a key technology enabling smooth con- 
versation with a dialogue translation system. 
1 I n t roduct ion  
Recently, various dialogue translation systems 
have been proposed (Bub and others, 1997; 
Kurematsu and Morimoto, 1996; Rayner and 
Carter, 1997; Ros~ and Levin, 1998; Sumita 
and others, 1999; Yang and Park, 1997; Vi- 
dal, 1997). If we want to make a conversation 
proceed smoothly using these translation sys- 
tems, it is important o use not only linguis- 
tic information, which comes from the source 
language, but also extra-linguistic nformation, 
which does not come from the source language, 
but, is shared between the participants of the 
conversation. 
Several dialogue translation methods that 
use extra-linguistic information have been pro- 
posed. Horiguchi outlined how "spoken lan- 
guage pragmatic information" can be trans- 
lated (Horiguchi, 1997). However, she did not 
apply this idea to a dialogue translation system. 
LuperFoy et al proposed a software architec- 
*Current affiliation is ATR Spoken Language Trans- 
lation Research Laboratories 
Current mail addresses are 
{ setsuo.yarnada, eiichiro.sumita, hideki.kashioka} 
@slt. atr. co.jp 
ture that uses '% pragmatic adaptation" (Lu- 
perFoy and others, 1998), and Mima et al pro- 
posed a method that uses "situational informa- 
tion" (Mima and others, 1997). LuperFoy et al 
simulated their method on man-machine inter- 
faces and Mima et al preliminarily evaluated 
their method. Neither study, however, applied 
its proposals to an actual dialogue translation 
system. 
The above mentioned methods will need time 
to work in practice, since it is hard to obtain 
the extra-linguistic nformation on which they 
depend. 
We have been paying special attention to "po- 
liteness," because a lack of politeness can inter- 
fere with a smooth conversation between two 
participants, uch as a clerk and a customer. It 
is easy for a dialogue translation system to know 
which participant is the clerk and which is the 
customer from the interface (such as the wires 
to the microphones). 
This paper describes a method of "polite- 
ness" selection according to a participant's so- 
cial role (a clerk or a customer), which is eas- 
ily obtained from the extra-linguistic environ- 
ment. We incorporated each participant's so- 
cial role into transfer ules and transfer dictio- 
nary entries. We then conducted an experiment 
with 23 unseen dialogues (344 utterances). Our 
method achieved a recall of 65% and a preci- 
sion of 86%. These rates could be improved to 
86% and 96%, respectively (see Section 4). It 
is therefore possible to use a "participant's so- 
cial role" (a clerk or a customer in this case) 
to appropriately make the translation results 
"polite," and to make the conversation proceed 
smoothly with a dialogue translation system. 
Section 2 analyzes the relationship between a
particular participant's social role (a clerk) and 
politeness in Japanese. Section 3 describes our 
proposal in detail using an English-to-Japanese 
37 
translation system. Section 4 shows an exper- 
iment and results, followed by a discussion in 
Section 5. Finally, Section 6 concludes this pa- 
per. 
2 A Par t i c ipant ' s  Soc ia l  Ro le  and  
Po l i teness  
This section focuses on one participant's social 
role. We investigated Japanese outputs of a di- 
alogue translation system to see how many ut- 
terances hould be polite expressions in a cur- 
rent translation system for travel arrangement. 
We input 1,409 clerk utterances into a Transfer 
Driven Machine Translation system (Sumita 
and others, 1999) (TDMT for short). The in- 
puts were closed utterances, meaning the sys- 
tem already knew the utterances, enabling the 
utterances to be transferred at a good quality. 
Therefore, we used closed utterances as the in- 
puts to avoid translation errors. 
As a result, it was shown that about 70% 
(952) of all utterances should be improved to use 
polite expressions. This result shows that a cur- 
rent translation system is not enough to make 
a conversation smoothly. Not surprisingly, if all 
expressions were polite, some Japanese speakers 
would feel insulted. Therefore, Japanese speak- 
ers do not have to use polite expression in all 
utterances. 
We classified the investigated ata into dif- 
ferent ypes of English expressions for Japanese 
politeness, i.e., into honorific titles, parts of 
speech such as verbs, and canned phrases, 
as shown in Table 1; however, not all types 
appeared in the data. For example, when 
the clerk said "How will you be paying, Mr. 
Suzuki," the Japanese translation was made 
polite as "donoyouni oshiharaininarimasu-ka 
suzuki-sama" in place of the standard expres- 
sion "donoyouni shiharaimasu-ka suzuki-san." 
Table 1 shows that there is a difference in 
how expressions should be made more polite ac- 
cording to the type, and that many polite ex- 
pressions can be translated by using only local 
information, i.e., transfer rules and dictionary 
entries. In the next section, we describe how to 
incorporate the information on dialogue partic- 
ipants, such as roles and genders, into transfer 
rules and dictionary entries in a dialogue trans- 
lation system. 
3 A Method  of  Us ing  In fo rmat ion  
on  D ia logue  Par t i c ipants  
This section describes how to use information 
on dialogue participants, such as participants' 
social roles and genders. First, we describe 
TDMT, which we also used in our experiment. 
Second, we mention how to modify transfer 
rules and transfer dictionary entries according 
to information on dialogue participants. 
3.1 Transfer  Dr iven  Mach ine  
Trans la t ion  
TDMT uses bottom-up left-to-right chart pars- 
ing with transfer rules as shown in Figure 1. 
The parsing determines the best structure and 
best transferred result locally by performing 
structural disambiguation using semantic dis- 
tance calculations, in parallel with the deriva- 
tion of possible structures. The semantic dis- 
tance is defined by a thesaurus. 
(source pattern) 
==~ 
J ((target pattern 1) 
((source xample 1) 
(source xample 2) 
? "- ) 
(target pattern 2) 
?o* ) 
Figure 1: Transfer ule format 
A transfer ule consists of a source pattern, 
a target pattern, and a source example. The 
source pattern consists of variables and con- 
stituent boundaries (Furuse and Iida, 1996). 
A constituent boundary is either a functional 
word or the part-of-speech of a left constituent's 
last word and the part-of-speech of a right con- 
stituent's first word. In Example (1), the con- 
stituent boundary IV-CN) is inserted between 
"accept" and "payment," because "accept" is 
a Verb and "payment" is a Common Noun. 
The target pattern consists of variables that cor- 
respond to variables in the source pattern and 
words of the target language. The source exam- 
ple consists of words that come from utterances 
referred to when a person creates transfer ules 
(we call such utterances closed utterances). 
Figure 2 shows a transfer ule whose source 
pattern is (X (V-CN) Y). Variable X corre- 
sponds to x, which is used in the target pat- 
tern, and Y corresponds to y, which is also 
38 
Table 1: Examples of polite expressions 
Type: verb, title 
Eng: How will you be paying, Mr. Suzuki 
Standard: donoyouni shiharaimasu-ka suzuki-san 
Polite: donoyouni o_shiharaininarimasu-ka suzuki-sama 
Gloss: How pay-QUESTION suzuki-Mr. 
Type: verb, common noun 
Eng: We have two types of rooms available 
Standard: aiteiru ni-shurui-no heya-ga ariraasu 
Polite: aiteiru ni-shurui-no oheya-ga gozaimasu 
Gloss: available two-types-of room-TOP have 
Type: auxiliary verb 
Eng: You can shop for hours 
Standard: suujikan kaimono-wo surukotogadekimasu 
Polite: suujikan kaimono-wo shiteitadakemasu 
Gloss: for hours make-OBJ can 
Type: pronoun 
Eng: Your room number, please 
Standard: anatano heya bangou-wo 
Polite: okyakusamano heya bangou-wo 
Gloss: Your room number-so obj 
onegaishirnasu 
onegaishimasu 
please 
Type: canned phrase 
Eng: How can I help you 
Standard: dou shimashitaka 
Polite: douitta goyoukendeshouka 
Gloss: How can I help you 
Example (1) 
Eng: We accept payment by credit card 
Standard: watashitachi-wa kurejitlo-kaado-deno shiharai-wo ukelsukemasu 
Polite: watashidomo-wa kurejitto-kaado-deno o_shiharai-wo ukeshimasu 
Gloss: We-TOP credit-card-by payment-OBJ accept 
used in the target pattern. The source exam- 
ple (("accept") ("payment")) comes from Ex- 
ample (1), and the other source examples come 
from the other closed utterances. This transfer 
rule means that if the source pattern is (X (V- 
CN) Y) then (y "wo" x) or (y "ni" x) is selected 
as the target pattern, where an input word pair 
corresponding to X and Y is semantically the 
most similar in a thesaurus to, or exactly the 
same as, the source example. For example, if 
an input word pair corresponding to X and Y 
is semantically the most similar in a thesaurus 
to, or exactly the same as, (("accept") ("pay- 
ment")), then the target pattern (y "wo" x) is 
selected in Figure 2. As a result, an appropriate 
target pattern is selected. 
After a target pattern is selected, TDMT cre- 
ates a target structure according to the pattern 
(X (V-CN) Y) 
((y "wo" x) 
((("accept") ("payment")) 
(("take") ("picture"))) 
(y "hi" x) 
((("take") ("bus")) 
(("get") ("sunstroke"))) 
) 
Figure 2: Transfer ule example 
by referring to a transfer dictionary, as shown 
in Figure 3. If the input is "accept (V -CN)  
payment," then this part is translated into "shi- 
harai wo uketsukeru." "wo" is derived from the 
target pattern (y "wo" x), and "shiharai" and 
"uketsukeru" are derived from the transfer dic- 
tionary, as shown in Figure 4. 
39 
(source pattern) 
(((target pattern 11) :pattern-cond 11
(target pattern 12) :pattern-cond 12 
itarget pattern In) :default) 
((source xample 1) 
? oo ) 
(((source xample 1) ~ (target word lt) :word-cond 11 
(source example 1) --* (target word 12) :word-cond 12 
?? .  
(source example 1) --* (target word lm) :default) 
o . "  ) 
(((target pattern 21) :pattern-cond 21 
. . .  ) ) )  
Figure 5: Transfer ule format with information on dialogue participants 
(((source word 1) --* (target word 11) :cond 11 I 
(source word 1) -* (target word 12) :cond 12 I 
I . . .  
(source word 1) -~ (target word lk) :default)\[ 
o*.  ) I 
Figure 6: Dictionary format with information on dialogue participants 
((source word) ~ (target word) 
? " .  ) 
Figure 3: Transfer dictionary format 
(("accept") --* ("uketsukeru') I ("payment") --* ("shiharai"))  
Figure 4: Transfer dictionary example 
(X "sama") 
((("Mr." x) :h-gender male 
("Ms." x) :h-gender female 
("Mr-ms." x)) 
(("room number"))) 
) 
Figure 7: Transfer ule example with the par- 
ticipant's gender 
3.2 Transfer Rules and Entr ies 
according to Information on 
Dialogue Part ic ipants 
For this research, we modified the transfer ules 
and the transfer dictionary entries, as shown in 
Figures 5 and 6. In Figure 5, the target pattern 
"target pattern 11" and the source word "source 
example 1" are used to change the translation 
according to information on dialogue partici- 
pants. For example, if ":pattern-cond 11" is de- 
fined as ":h-gender male" as shown in Figure 7, 
then "target pattern 11" is selected when the 
hearer is a male, that is, "("Mr." x)" is selected. 
Moreover, if ":word-cond 11" is defined as ":s- 
role clerk" as shown in Figure 8, then "source 
example 1" is translated into "target word 11" 
when the speaker is a clerk, that is, "accept" is 
translated into "oukesuru." Translations uch 
as "target word 11" are valid only in the source 
pattern; that is, a source example might not 
always be translated into one of these target 
words. If we always want to produce transla- 
tions according to information on dialogue par- 
ticipants, then we need to modify the entries 
in the transfer dictionary like Figure 6 shows. 
Conversely, if we do not want to always change 
the translation, then we should not modify the 
entries but modify the transfer ules. Several 
conditions can also be given to ":word-cond" 
and ":pattern-cond." For example, ":s-role cus- 
tomer and :s-gender female," which means the 
speaker is a customer and a female, can be 
given. In Figure 5, ":default" means the de- 
40 
fault target pattern or word if no condition is 
matched. The condition is checked from up to 
down in order; that is, first, ":pattern-cond 11," 
second, ":pattern-cond 1~," ... and so on. 
(X (V-CN) Y) 
((y "wo" x) 
((("accept") ("payment")) 
(("take") ("picture"))) 
((("accept") -~ ("oukesuru"):s-role clerk 
( "accept" ) --+ ( "uketsukeru" ) )) 
) 
Figure 8: Transfer ule example with a partici- 
pant's role 
((("payment") --~ ("oshiharai") :s-role clerk 
( "payment" ) ---* ( "shiharai" )) 
(("we") --* ("watashidomo") :s-role clerk 
("we") --~ ("watashltachi"))) 
Figure 9: Transfer dictionary example with a 
speaker's role 
Even though we do not have rules and en- 
tries for pattern conditions and word condi- 
tions according to another participant's infor- 
mation, such as ":s-role customer'(which means 
the speaker's role is a customer) and ":s-gender 
male" (which means the speaker's gender is 
male), TDMT can translate xpressions corre- 
sponding to this information too. For example, 
"Very good, please let me confirm them" will 
be translated into "shouchiitashimasita kakunin 
sasete itadakimasu" when the speaker is a clerk 
or "soredekekkoudesu kakunin sasete kudasai" 
when the speaker is a customer, as shown in 
Example (2). 
By making a rule and an entry like the ex- 
amples shown in Figures 8 and 9, the utter- 
ance of Example (1) will be translated into 
"watashidomo wa kurejitto kaado deno oshi- 
harai wo oukeshimasu" when the speaker is a 
clerk. 
4 An  Exper iment  
The TDMT system for English-to-Japanese at 
the time Of the experiment had about 1,500 
transfer ules and 8,000 transfer dictionary en- 
tries. In other words, this TDMT system was 
capable of translating 8,000 English words into 
Japanese words. About 300 transfer ules and 
40 transfer dictionary entries were modified to 
improve the level of "politeness." 
We conducted an experiment using the trans- 
fer rules and transfer dictionary for a clerk with 
23 unseen dialogues (344 utterances). Our input 
was off-line, i.e., a transcription of dialogues, 
which was encoded with the participant's social 
role. In the on-line situation, our system can 
not infer whether the participant's social role is 
a clerk or a customer, but can instead etermine 
the role without error from the interface (such 
as a microphone or a button). 
In order to evaluate the experiment, we clas- 
sifted the Japanese translation results obtained 
for the 23 unseen dialogues (199 utterances from 
a clerk, and 145 utterances from a customer, 
making 344 utterances in total) into two types: 
expressions that had to be changed to more po- 
lite expressions, and expressions that did not. 
Table 2 shows the number of utterances that in- 
cluded an expression which had to be changed 
into a more polite one (indicated by "Yes") and 
those that did not (indicated by "No"). We ne- 
glected 74 utterances whose translations were 
too poor to judge whether to assign a "Yes" or 
"No." 
Table 2: The number of utterances to be 
changed or not 
Necessity | The number 
of change I of utterances 
Yes 104 
No 166 
Out of scope 74 
Total \[ 344 
* 74 translations were too poor to handle for the 
"politeness" problem, and so they are ignored in this 
paper. 
The translation results were evaluated to see 
whether the impressions of the translated re- 
sults were improved or not with/without mod- 
ification for the clerk from the viewpoint of 
"politeness." Table 3 shows the impressions 
obtained according to the necessity of change 
shown in Table 2. 
The evaluation criteria are recall and preci- 
sion, which are defined as follows: 
Recall = 
number of utterances whose impression is better 
number of utterances which should be more polite 
41 
Example (2) 
Eng: Very good, please let me confirm them 
Standard: wakarimasita kakunin sasete 
Clerk: shouchiitashimasita kakunin sase~e 
Customer: soredekekkoudesu kakunin sasete 
Gloss: very good con:firm let me 
kudasai 
itadakimasu 
kudasai 
please 
Table 3: Evaluation on using the speaker's role 
Necessity 
of change 
Yes 
(lo4) 
No 
(166) 
~ Impression 
better 
same 
worse  
no-diff 
better 
s alTle 
worse  
no-diff 
The number 
of utterances 
68 
5 
3 
28 
0 
3 
0 
163 
bet ter :  Impression of a translation is better. 
same:  Impression of a translation has not changed. 
worse: Impression of a translation is worse. 
no-diff: There is no difference between the two 
translations. 
Precision = 
number of utterances whose impression is better 
number of utterances whose expression has been 
changed by the modified rules and entries 
The recall was 65% (= 68 - (68 + 5 + 3 + 28)) 
and the precision was 86% (= 68 -: (68 + 5 + 3 + 
0+3+0)).  
There are two main reasons which bring down 
these rates. One reason is that TDMT does not 
know who or what the agent of the action in 
the utterance is; agents are also needed to se- 
lect polite expressions. The other reason is that 
there are not enough rules and transfer dictio- 
nary entries for the clerk. 
It is easier to take care of the latter problem 
than the former problem. If we resolve the lat- 
ter problem, that is, if we expand the transfer 
rules and the transfer dictionary entries accord- 
ing to the "participant's social role" (a clerk and 
a customer), then the recall rate and the preci- 
sion rate can be improved (to 86% and 96%, 
respectively, as we have found). As a result, we 
can say that our method is effective for smooth 
conversation with a dialogue translation system. 
5 D iscuss ion  
In general, extra-linguistic information is hard 
to obtain. However, some extra-linguistic infor- 
mation can be easily obtained: 
(1) One piece of information is the participant's 
social role, which can be obtained from the in- 
terface such as the microphone used. It was 
proven that a clerk and customer as the social 
roles of participants are useful for translation 
into Japanese. However, more research is re- 
quired on another participant's social role. 
(2) Another piece of information is the par- 
ticipant's gender, which can be obtained by a 
speech recognizer with high accuracy (Takezawa 
and others, 1998; Naito and others, 1998). We 
have considered how expressions can be useful 
by using the hearer's gender for Japanese-to- 
English translation. 
Let us consider the Japanese honorific title 
"sama" or "san." If the heater's gender is male, 
then it should be translated "Mr." and if the 
hearer's gender is female, then it should be 
translated "Ms." as shown in Figure 7. Ad- 
ditionally, the participant's gender is useful for 
translating typical expressions for males or fe- 
males. For example, Japanese "wa" is often at- 
tached at the end of the utterance by females. 
It is also important for a dialogue translation 
system to use extra-linguistic information which 
the system can obtain easily, in order to make 
a conversation proceed smoothly and comfort- 
ably for humans using the translation system. 
We expect hat other pieces of usable informa- 
tion can be easily obtained in the future. For 
example, age might be obtained from a cellular 
telephone if it were always carried by the same 
person and provided with personal information. 
In this case, if the system knew the hearer was a 
child, it could change complex expressions into 
easier ones. 
6 Conc lus ion  
We have proposed a method of translation us- 
ing information on dialogue participants, which 
42 
is easily obtained from outside the translation 
component, and applied it to a dialogue trans- 
lation system for travel arrangement. This 
method can select a polite expression for an 
utterance according to the "participant's social 
role," which is easily determined by the inter- 
face (such as the wires to the microphones). For 
example, if the microphone is for the clerk (the 
speaker is a clerk), then the dialogue translation 
system can select a more polite expression. 
In an English-to-Japanese translation system, 
we added additional transfer ules and transfer 
dictionary entries for the clerk to be more po- 
lite than the customer. Then, we conducted an 
experiment with 23 unseen dialogues (344 ut- 
terances). We evaluated the translation results 
to see whether the impressions of the results im- 
proved or not. Our method achieved a recall of 
65% and a precision of 86%. These rates could 
easily be improved to 86% and 96%, respec- 
tively. Therefore, we can say that our method 
is effective for smooth conversation with a dia- 
logue translation system. 
Our proposal has a limitation in that if the 
system does not know who or what the agent 
of an action in an utterance is, it cannot ap- 
propriately select a polite expression. We are 
considering ways to enable identification of the 
agent of an action in an utterance and to ex- 
pand the current framework to improve the level 
of politeness even more. In addition, we intend 
to apply other extra-linguistic nformation to a 
dialogue translation system. 
References  
Thomas Bub et al 1997. Verbmobih The 
combination of deep and shallow processing 
for spontaneous speech translation. In the 
1997 International Conference on Acoustics, 
Speech, and Signal Processing: ICASSP 97, 
pages 71-74, Munich. 
Osamu Furuse and Hitoshi Iida. 1996. In- 
cremental translation utilizing constituent 
boundary patterns. In Proceedings of 
COLING-96, pages 412-417, Copenhagen. 
Keiko Horiguchi. 1997. Towards translating 
spoken language pragmatics in an analogical 
framework. In Proceedings ofA CL/EA CL-97 
workshop on Spoken Language Translation, 
pages 16-23, Madrid. 
Akira Kurematsu and Tsuyoshi Morimoto. 
1996. Automatic Speech Translation. Gordon 
and Breach Publishers. 
Susann LuperFoy et al 1998. An architecture 
for dialogue management, context tracking, 
and pragmatic adaptation i  spoken dialogue 
system. In Proceedings of COLING-A CL'98, 
pages 794-801, Montreal. 
Hideki Mima et al 1997. A situation-based 
approach to spoken dialogue translation be- 
tween different social roles. In Proceedings of
TMI-97, pages 176-183, Santa Fe. 
Masaki Naito et al 1998. Acoustic and lan- 
guage model for speech translation system 
ATR-MATRIX. In the Proceedings of the 
1998 Spring Meeting of the Acoustical Soci- 
ety of Japan, pages 159-160 (in Japanese). 
Manny Rayner and David Carter. 1997. Hy- 
brid language processing in the spoken lan- 
guage translator. In the 1997 International 
Conference on Acoustics, Speech, and Signal 
Processing: ICASSP 97, pages 107-110, Mu- 
nich. 
Carolyn Penstein Ros~ and Lori S. Levin. 1998. 
An interactive domain independent approach 
to robust dialogue interpretation. In Proceed- 
ings of COLING-ACL'98, pages 1129-1135, 
Montreal. 
Eiichiro Sumita et al 1999. Solutions to prob- 
lems inherent in spoken-language translation: 
The ATR-MATRIX approach. In the Ma- 
chine Translation Summit VII, pages 229- 
235, Singapore. 
Toshiyuki Takezawa et al 1998. A Japanese- 
to-English speech translation system: ATR- 
MATRIX. In the 5th International Con- 
ference On Spoken Language Processing: 
ICSLP-98, pages 2779-2782, Sydney. 
Enrique Vidal. 1997. Finite-state speech-to- 
speech translation. In the 1997 International 
Conference on Acoustics, Speech, and Signal 
Processing: ICASSP 97, pages 111-114, Mu- 
nich. 
Jae-Woo Yang and Jun Park. 1997. An exper- 
iment on Korean-to-English and Korean-to- 
Japanese spoken language translation. In the 
1997 International Conference on Acoustics, 
Speech, and Signal Processing: ICASSP 97, 
pages 87-90, Munich. 
43 
