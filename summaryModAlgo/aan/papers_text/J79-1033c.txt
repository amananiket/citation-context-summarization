American Journal of Computational Linguistics 
P R O C E E D I N G S  
1 3 T H  A N N U A L  f l ' E E T I N G  
ASSOCIATION FOR COMPUTATIONAL LINGUI STI cs 
Timothy C. D i l l e r ,  E d i t o r  
Sperry-Univac 
St. Paul, Minnesata 55101 
Microfiche 33 
Copyright @ 1975 by the Association for Computational Linguistics 
PREFACE 
The papers comprising th i s  microfiche (the second of 
f ive)  present in expanded form (as submitted by their  
authors) the s i x  talks given in Session 2: Language Gene- 
ration Systems. Various aspects of generation are consi- 
dered, among them: relat ionsHips  between parsing and 
generation (Knaus), planning modules and data structures 
basic to story development (Meehan) , semantic networks and 
linguistic generatorq (Shapiro and Slocum), message struc- 
tures and translation strategies (McDonald) , and l ex ica l  
processes i n  compound noun formation (Rhyne). Thanks to 
Martin K a y  for chairing this session. 
Timothy  C .  Diller 
Program C o m m i t t e e  Chairman 
TABLE OF CONTENTS 
A Rxtsbework for Writing Generation Grammars for Inter-  
active Computer Programs mvid Mcmnald . . . . . . . . .  4 
. . . . . .  Incremental Sentence Processing Rodger m u s  18 
A Lexical Process Model of Nominal Compounding in 
. . . . . . . . . . . . . . . . .  English James R. Rhyne 33 
Generation as Parsing from a Network i n t o  a Linear 
String Stuar t  C. shepiro . . . . . . . . . . . . . . . . .  45 
Speech Generation from Semantic Nets J~Adthdn S ~ O C W  . . 63 
Using Planning Structures to Generate Stories ~ a m s  R. 
. . . . . . . . . . . . . . . . . . . . . . . . .  Heehan 78 
American Jourdal of Computational tinguktics Microfiche 33 4 
Artificial Intelligence Ldbora t o r y  
Massachusetts Ins ti tute of Technology 
Cambridge, Massachusetts 02139 
ABSTRACT 
This paper outlines t h e  stucture and operation o f  the 
1 ingui s t i c  component from a language generation system in an 
interactive program. The component receives messages 
describing what i s  to b e  s a i d  f o r m u l a t e d  in t h e  
representation of the main prograr and produces fluent 
English utterances appropriate t o  t he  current discourse 
situation. T h e  component is data-directed and uses a 
procedural grammar, organized as a set of strategies. 
Interactive, speclalist prograas presently under developwent will 
heed to produce fluent, intentional English utterances in responce to 
particular, complex t i t u t l o n s .  This creates a requlroaont for language 
generating facilities that I s  not faced in transformational grarapar, 
rochanical translation programs, or paraphrase generating programs. As 
a component of rn interactive, specialist program, the production of t h e  
English must be driven direct lr  by the communicative intentions of the 
program and by the discourse situation, 
We can imagine tha t  the overall program consist,? o f  a number of 
cooperating modules - f o r  parsing and interpreting what i s  said t o  it, 
ior  solving ptoblens in its domain, for managing i t s  renary, and, i n  
particular, f o r  generating u t t e rances  t o  c o m ~ u n i c a t e  w l  t h  Its users* 
This generation component can be p r o f i t a b l y  v iewed as having three 
aspects or msub-corponentsw. 
1) Situation/doaain specie1 i s t s  t ha t  a r e  activated when  t h e  program 
recognizes what situation it i s  in+ They then decide what message 
will be produced. They will decide what effect  on the  listener is 
desired, and exactly what objects  and relations a re  t o  be nentioned. 
F o t  example, an appoint~ent scheduling program might be told to 
*scm~ule a group meeting for  F r i d a y w  and then  find t h a t  a critical 
aentber o f  the group i s  uncxvailable, The situation specialists in 
t h e  scheduling prograr a re  t h e  ones t o  decide  whether i t  is more 
appropriate t o  s i m p l y  say " 1  can'tR, O F  w h e t h e r  t o  v o l u n t c p  
information - w I  can't; Mitch won't be back u W l t  Mondayn. 
2) Models of the audience and t h e  discourse situation to use  i n  
construct2ng utterances. There must be a r e c o r d  of t h e  p a s t  
conversation to gulcfe in the selection a f  p r o n o u n s ,  A l s o ,  the 
program must have nodels of, and heuristics about  what  the audience 
a l r e a d y  knows  and t h e r e f o r e  doesn't have t o  be t o l d .  T h i s  
Informtion l a y  be very specific and domain dependent. Fot  exarple, 
In chess, one can say "the white queen could take e knightn. There  
is no need t o  say "a black k n l p h t w ,  because t h i s  information is 
supplied by inferences from what one knows about c h e s s  - inferences 
that the spcarer assures the listener shares. 
3) Llnpu!rtic know1 edge about how to construct understandable utterances 
in the English Isnpuagc. Obviously, t h i s  lnformatlon vill Include a 
lexicon assoclatlng objects and relations from t h e  min program with 
rtrate&i@~ for realizing them in English (particular words, p h r a s e s ,  
syntactic constructions, etc.) .  There is also a tremendous amount 
of informatian which describes the characteristics of the English 
language and the conditions of  i t s  use. It specif ies  rhe allowable 
arrangements of strategies and what niodlfications or alternatives t o  
them nay be appropriate in particular circumstances. 
Of the three aspects just described, my work has concentrated on 
the th ird .  What follows i s  drawn from sy thesis McDonald ' 75 )  and from 
ongoing research. 
The Lingufetio Component 
The 1 inguistic knowledge required for  generat ing utterances i s  put 
into one component whose job i s  t o  take a message from the  sltuatlon 
specialists and cpnstruct a t r a n s l a t l w  of  tha t  message In English. The 
messages are in the representation used by the main program and the 
s 1  tuation specialists. Tho translation is done by a data-directed 
process wherein the elenents and structure o f  the message i t se l f  provide 
the control. 
The design of the 1 ingui stics component was arrived a t  independent 
of any particular main program, f o r  the  simple reason that  no programs 
o f  adequate complexity were available a t  the time. However, a t  the 
p r e s e n t  t i m e  a grammar and f c x l c o n  is being d e v e l o p e d  t o  use with a t  
l e a s t  two prograRs being developed by o t h e r  people  a t  MIT. They are  an 
a p p o i n t m e n t  s c h e d u l i n g  program (Goldstein ' 7 5 )  and an advisor t o  a i d  
users of MACSYMA (Genesereth '75). The s h o r t  d i a l o g  below i s  an example 
of the  degree of f l u e n c y  we arc hop ing  t o  eventually achieve. The 
d l a l o g  ts between a scheduling prograa a c t i n g  as an appolntaent 
secretary (P), and a s tudent  ( 5 ) .  
(5) I want t o  see Professor Winston sometime in the  next few days. 
(PI H e r s  p r e t t y  busy a l l  week. Can i t  wai t?  
(S) No, it can't, All  I need i s  h i s  signature on a f o r b  
(PI Well, maybe he can squeeze you in tommorrow ~ o r n l n g .  Give me 
your name and check back in an hour.  
Messages 
Using the current message fo raa t  and Ignoring t h e  d e t a i l s  of the 
schedulerts representation, t h e  phrase "maybe he can squeeze you in 
t o ~ m o r r o w ~  could have c o w  from a Pessage like t h i s  one, p u t  t o g e t h e r  by 
one of t h e  situation specialists. 
Message- 1 features. ( prediction ) 
event (event actor ( W i n s t o n )  
action ( f i t  p e r s o n - i n t o  du l l  schedule> 
t h e  (31-10-75, gar-12am) 
hedge <fs possible) 
aim-at-audience hedge 
Messages have features describing the  program's communicative intentions 
- what sort of ut te rance  is t h i s  t o  be; what effect i s  it t o  have. 
Messages l i s t  the  objects t o  be desert-bed (the r i g h t  hand column) along 
with annotations f o r  each object ( l e f t  hand co1u.n) to show how they 
relate t o  t h e  rest of the message. The phrases on the r i g h t  in angle 
brackets represent actual  s t r u c t u r e s  from t h e  schedu le r  wf t h  those  
The Lexicon 
Translatl~n ftor tho  in te rna l  reprcscntai  ton o f  s coaputcr program 
t o  natural language has the  same sort  o f  p r o b l e w  as translating b e t w ~ e n  
t w o  natural languages.  T k  same concepts  nay not be a v a i l a b l e  as 
prim1 t i v o s  in both rcpresents.tions, and the conventions o f  t h e  target 
Isnguape my require additional information t h a t  was not in the source. 
Generally speaking translation cannot be one for  one. 
What English phrase is best for a particular element in a program's 
message will depend on what i s  in t h e  r e s t  of the message and of what 
the external c o n t e x t  is. In such circunstances, translation by table- 
lookup is inadequate. In this component, in order t o  allow a l l  factors 
t o  be considered, t h e  t r a n s l a t i o n  o f  each  element ias d o n e  by 
individualized procedures called wcorposersH. 
For  each main program t h a t  t h e  linguistic componen t  becomes 
associated with, a lexicon must be created which will list the elements 
of  the rain program's representation that  cou ld  appear in a message 
(1. C. w p r C d l ~ t l ~ n H ,  " e v e n t w ,  w < W i n s t o n P ,  e t c .  ) .  With each element i s  
recorded the  composer tha t  will be run when the  time comes t o  produce en 
English description f o r  it (examples will be given s h o r t l y ) .  Some 
conposers nay be applicable f o r  a whole c l a s s  o f  elements, such as 
"eventsw. They would know the structure t h a t  a l l  events have in common 
(e .g .  actor, actlon, tine) and would know how t o  i n t e r p r e t  t h e  
idiosyncratic d e t a i l s  o f  each even t  by using data  in the lexicon 
associated with them. 
The Grammar - strategies 
The bulk o f  the g r a u a r  con&ists of  "strategiesw. Strategies arc 
associated with particular languages ra ther  than w i t h  par t icular  main 
prograas as composers are.  A g i v e n  s trategy  may be used f o r  several  
d i f f e r e n t  purposes. A typical case i s  the strategy u s e - s , ? m p ~ r e s e n t -  
tense: a clause in the simple present  ("prices risew) my be understood 
as future,  cond'itlonal, or  timeless, according t o  what other phrases arc 
present, 
Each composer ray know of several  strategies, or  Coabinatlons of 
strategies which it could use in dcscrlbing an ele .cnt  f r o m  the message, 
It w i T 1  choose between the& according t o  the c o n t e x t  - usually d e t a i l s  
o f  the element or syntactic constraints iaposed by previously selected 
strategies. T h e  strategies themselves do no reasoning; t h e y  are 
implemented as functions which the  corposers call to  do  a l l  the actual 
corsst'ruction o f  the utterance. 
The Tr~nslat ion Prooesa 
A t  t h i s  p o i n t .  the out1 ine of  t h e  data-dr Iven translation process 
can be su~rnriztd. A message is glven f o r  t rans la t ion .  The  e l e ~ e n t s  of 
the  aessage are associated i n  a lexicon with procedures  t o  describe 
the.. The procedures a r e  run; they cal l  grs~latica1 strategies; and 
t h e  strategies construct the English utterance. 
Of course, i f  t h i s  were a l l  t h e r e  was t o  it, the process would 
never run, betause a l l  of the  subprocesses aust be throughly  coordinated 
i f  they are n o t  to " t r i p  over t h e i r  own fee t" ,  or ,  for t h a t  ~ a t t e r ,  i f  
ordinary human beings are t o  bo able t o  design the.. In a system where 
the  knowledge o f  what to do i s  d i s t r i b u t e d  over a l a r g e  number of 
separate procedures, contro l  structure assumes central. iaportance. 
Plans 
Before d t ~ c r i b i n g  the control structure, I m u s t  l a y  o u t  some 
additional aspects o f  the design of  t h e  ilngulstlcs coaponent. 
There i s  no 
i n t e r l i n g u a  or intermediate level of structure c o ~ p a r a b l c  to the dkep 
structures  of Transformttlonal G r a ~ s a r ,  o r  the sewnt l c  n e t s  of S l ~ a o n s  
(73) or Goldban ( 7 4 ) .  
Detorminln~ t h e  appropriate sutface s t r u c t u r e ,  however, r equ ires  
p l a n n f n p ,  i f  f o r  no other reason than t h a t  the Message can o n l y  be 
examined one piece ax a t h e .  The en t i r e  utterance must be organized 
before a detailed analysis and translation can get underway. As this is 
done, the w p r o t o - u t t e r a n c e w  i s  r e p r e s e n t e d  i n  t e r n s  o f  a s o r t  of 
scaffolding - a representatiqp of the ult imate surface structure tree 
insofar as its deta i l s  are  known w i t h  e x t e n s i v e  annotation, explicit and 
implicit, t o  p o i n t  out where elements that  are n o t  y e t  described may be 
positioned, and t o  implement the  graamatical restrictions on possible 
future details as dictated by what has already been done. 
The scaffolding t h a t  i s  constructed in the  translation o f  each 
message i s  called i t s  w p 4 a 0 w .  Plans are made up o f  syntactic nodes of 
the usual s o r t  - clauses ,  noun groups, e t c ,  - and nodes may have 
features in t h e  Banner of  tysteni; grammar Winograd ' 7 2 ~  Nodes have 
subplans c o n s i s t i n g  o f  a l i s t  of named slots marking the possible 
potftlons f o r  sub-constituents, given in t h e  order ~f t h o  eventual 
surface structure. Possible slots would be wsubJectw,  *.%in verbw,  
"noun headw, wpre-verb-adverbw, and so on. The syntactic node t y p e s  
will each have a nuaber of -possible plans,  corresponding" t o  t h e  
d i f f erent  possible arrangements or sub-consti tuents that may occur wl t h  
t h o  d i f f e r e n t  combinat ions  o f  f e a t u r e s  t h a t  tho  Mdc may have, 
Depending on t h o  r t a g e  o f  t h e  translation process ,  a s l o t  may bc 
" f l 1 l o d w  with a pointer t o  an lnternal o b j e c t  fro .  the message, a 
syntactic node, a word or idior, a r  noth ing .  
The translation proaaea 
Tho translation i s  done i n  two phases. The second phase does n o t  
begin until the f i r s t  i s  coapletely finished. During the f i r s t  phase, a 
p l a n  is se lected and t h e  eleaents of  t h e  message are transferred, 
l a r g e l y  untouched; t o  the  s l o t s  of the plan and features added t o  i t s  
nodes. During the second phase, the plan is wwalktdR topdown and from 
l e f t  t o  r i g h t .  Conpostrs f o r  mssage e l e ~ e h t s  in t h e  plan's s l o t s  are 
activated t o  produce English descriptions f o r  the  elcments as t h e y  are 
reached in turn .  B o t h  processes a r e  data-directed, t h e  f i r s t  by t h e  
particular conten ts  of  the message and t h e  second by the  structure o f  
the p l a n  and t h e  contents o f  i t s  s lo t s .  
There are  sound linguistic reasons f o r  t h i s  two stage processing. 
Most parts of a lessage Bay be translated in terms of very modular 
sysltactic and lexical  units. But o t h e r  p a r t s  a r e  translated in  terms o f  
relations between such units, expressed usually by ordering or clause- 
level  syntactic aechanislps. The exact f o r @  o f  t h e  s ~ a l l e r  units cannot 
be deternlned until their larger scale  relations have been fixed. 
Accordingly, t h e  objective of the  f i r s t  phase is t o  determine w h a t  
global relationships are required and t o  choose the p l a n ,  features, and 
positions of message elemnts within the plan's s lots  tha t  will realfzt 
those relationships. Once this has been done, Engl tsh descriptions for  
the elements can be made Independent of each o the r  and will not need t o  
be changed af ter  they  arc i n i t i a l l y  created. 
One o f  the l o s t  i apor tan t  features o f  n a t u r a l  language is the  
ability t o  omit,  prono~inal i z e ,  or otherwise abbreviate elements in 
certain contexts. T h e  o n l y  known r u l e s  and hllristlcs for  using this 
feature r r o  phrased in terms of Surface structure configurations and 
temporal ordering. Because t he  second ~ h a s e  works d i r e c t l y  in thcse 
terms,  s t a t i n g  a n d  u s i n g  t h e  available heuristics becoaos a 
s t ra igh t?  orwsrd, tractable problem. 
"Maybe h e  can eg.ueeze you in tommoww morning" 
The  rest of this paper will try to put solae f lesh on your picture  
of how this linguistics conponent works by following the translation of 
t h e  message given in the beginning t o  the sentence above. The message 
was this. 
Massage- 1 features* ( prediction ) 
event (event actor <Winston> 
action. t f i t  person into full schedule) 
time <31-10-75,9aar-l2rm>) 
h-@biie <is possible, 
aim-at-audience hedge 
The intentional features  of a message tend t o  require the n o s t  global  
representation in the f Inal utterance, because that i s  where indicators 
for questions, special emphasis, speclal formats lee n. conpari son), and 
the  like w i l l  be found. By convention then. the composers associated 
wl th  the intentions are given the job of arranging for the disposition 
of a l l  o f  the  messake elements. T h e  to ta l  aperatlon of phase one 
consists of  executing the composer associated with each feature,  one 
af  $er the other. 
Thls aessage has only one feature, so i t s  composer will assume a l )  
tho work. Thc linguistics component is implemented in MACLISP, features 
(and annotations and s l o t s  and nodes) are atoms, and coar>Qsers ass 
functions on t h e i r  property l i s t s .  
Prediction 
composer-with (lambda ... ) 
Making a prediction is a speech act, an& wo nay expect there t o  be 
particular forms in a language for expressing thee, for  example, the use 
a f  t h e  explicit "willw for the future tense. Knowledge o f  these would 
De part o f  the  composer. Inside the  aain program, or the  situation 
special l s t ,  the concept o f  a prediction may always inc lude  certain 
parts: what is predicted, the time, any hedges, and so on. These part 
are d i r e c t l y  re f l ec ted  in thc makeup of the elements present in the 
message, and t h e i r  annotations mark what internal r o l e s  t h e 7  have. 
There does no t  need to be a direc t  correspondence between these and t h e  
parts in the l inguistic forms used, the  actual correspondence i s  pa r t  of 
the knowledge of the prediction cosposer. 
Typically, f o r  any feature,  one particular annotated e l e ~ e n t  will 
be of greatest l ~ p o r t a n c e  in seting the cha rac t e r  of t h e  whole 
utterance. For predictions, this is t h e  "eventw. T h e  prediction 
composer chooses a plan f o r  the utterance t o  f i t  the requireaents of the 
event-element. The realization of any other  elements will be restricted 
t o  be compatible w i t h  i t .  
T h e  prediction composer docs not need to know t h e  element's 
linguistic correlates i t s e l f ,  i t  can delegate the work to the composer 
for the  element i t s e l f .  The element look l ike this, 
(event actor <Winston> 
action < f i t  person i n t o  f u l l  schedule> 
tine t31-10-75,9am-lZaa>) 
The first word points to the name of the composer, and the p a i r s  g i v e  
particular details.  There i s  nothing special about the words used here 
(actor, action, tlme), Just a$ long as t h e  composer is designed to 
expect the inforwatton in those places that the message-asseabler wants 
to put  it. The event composerfs strategy is to use a clause, and t h e  
choice of plan is determined by the character o f  the event's "actionw. 
The action is " < f i t  person into full schedulerw, and i t  will have 
two relevant properties in the  lexicon: "plan*, and ".appingW. klan is 
e i ther  the nane of  a standard p l a n  t o  be used; or an actual p l a n ,  
partially f i l l e d  w i t h  words (1. e. i t  can be a phrase). "Mappingw is an 
association l i s t  showing how t h e  subelements of the message are t o  be 
transferred t o  the plan. 
< f i t  person i n t o  f u l l  schedule) 
PLAN 
node-i (clause trans1 particle) 
slots frontings n i l  
subject nil 
vg node-j (verb-group particle) 
slots modal nil 
pre-vb-adv n i l  
mvb "squeezew 
p r t  "inw 
object1 <person being talked about) 
post-modifiers nil 
MAPP I NG 
((  actor subject ) 
( time post-modifiers)) 
The event composer proceeds t o  instanticte the nodes i n  the  phrase and 
make the transfers; the prediction composer then takes the resulting 
plan,  and makes i t  the plan of  the whole utterance. 
Two message elements remain, b u t  actually there is o n l y  one, 
because waim-at-audiancew is supplying additional informati~n about the 
hedge. T h e  annotation means t h a t  the c o n t e n t s  o f  t h e  hedge (<is 
possible>) ere pore something tha t  we want to tell the audience than a 
detail o f  the prediction. This will a f f e c t  how the element is 
positioned in the plan.  
The  p r e d i c t i o n  composer l o o k s  in t h e  lexicon t o  s e e  what 
grammatical unit will be used t o  realize <is possible, ,  and sees, l e t  us 
say, two possibilities involving di f f eren t  configurations of the adverb 
wn&ybcn and t h e  modal "can be able ton,  with the differences hinging 
on the placement of  the adverb.  Theoretically, a d v e r b s  can be 
p o s i t i o n e d  i n  a nunber o f  places  in a clause, depending on t h e i r  
characteristics. In this instance, the choice is forced because of a 
heuristic written i n t o  the grammar of adverbs and accessible t o  t h e  
composer, that says tha t  when the intent of an adverb is directed t o  the  
audience, i t  should be in t h e  f i r s t  position ( t h e  "frontiogsW s l o t ) .  
This choice implies p u t t i n g  "canw I n  t h e  modal s l o t  d i r e c t l y .  T h e  
alternative with w ~ y b e *  i n  the pre-vb-adv s l o t  would have necessitated 
a different form of the .o8al, yielding " r a y  be able t o n ,  These details 
would have been taken care of by syntactic routines associated with t he  
verb group node. 
A 1 1  the message ererents have been placed and t h e  f i r s t  phase is 
over. The p l a n  is now as below. 
n4e - l  (clause trans1 particle) 
slats fmntfngs "8aybeW 
subject twinston> 
vg node-2 (verb-group par t ic1 el 
slots modal "canw 
pre-vb-adv n i l  
mvb "squeezen 
p r t  " inw 
object1 cperson being talked about )  
post-modifiers n i l  
The second phase controller is a simple dispaching function t h a t  m v e s  
from s l o t  t o  slot. "Fronttngs* contains a word, so t h e  word is printed 
.directly (there is a trap f o r  morphological adjustnents when necessary). 
wSttbjectw contains an in te rna l  object, so the controller should go to 
the lexicon for  its composer and then come back t o  handle whatever t h e  
composer replaced the clement with, 
However, there is always an l h t e r v e n i n g  step t o  check for t h e  
possibility of pronominalizing. This check is made with the elelpent 
s t i l l  in i t s  internal  foro .  T h e  record  o f  t h e  discourse i s  g i v e n  
d i r e c t l y  in t e r m  o f  the i n t e rna l  representation and test f o r  p r i o r  
uccurence can be as simple as identity checks against a reference list, 
svoiding potentially intricate string matching operations w i t h  words. 
In the d i a l o g  tha t  th i s  message came from, there  is clear  reference to 
t w i n 9 t o n > ,  so it can be prononinallzed and "hew is printed.  
Any slot, or any node t y p e  may have procedures associated with i t  
that are executed when the slot or node is reached during t h e  second 
phase. These procedures will handle syntac t ic  processes like agreement, 
rearangelaent o f  s l o t s  t o  rea l i ze  features, add function words, watch 
scope relationships, and in particular, position the particle in verb- 
part ic le  pairs.  
Generally,  p a r t i c l e  position ("squeeze John i n n  vs. n ~ q ~ m e  in 
J o h n w )  is n o t  specifled by the grammar - except when the object i s  a 
pronoun and the particle - must be displaced. This, of course, will not  
be known untlll a f t e r  the verb group has been passed. To deal with 
this, a subroutine in the "when-ent$redn procedure of  t h e  verb group i s  
activated by the "par t i c len  procedure. First, i t  records the particle 
and relaoves  it f r o m  t h e  V G  p l a n  s o  it will not be g e n e r a t e d  
automatically. A "hookw i s  available on any slot for a,procedure which 
can be run after prononinalization is checked and before the composer i s  
called ( i f  i t  is t o  be c a l l e d ) .  The subroutine incorporates the 
part ic le  i n t o  a standard procedure and places i t  on t h a t  hook for t h e  
object1 s l o t .  The procedure will check i f  the  object has been prlnted 
as a pronoun, and i f  so, p r i n t s  o u t  the par t i c l e  (which i s  now I n  the  
proper displaced pori  tion). If  the ob jec t  wasn' t pronominal ized,  then 
it does nothing, nothing has ye t  been printed beyond the verb group, and 
other heuristics will be free t o  a p p l y  t o  choose the proper position. 
Since (person  being t a l k e d  about, is here equal to the student, t h e  
person t h e  prograa is talking with, i t  i s  realized as the pronoun "youw 
and the  particle is dlsplaccd. 
Going irom <31-10-75,9a~-12arn> t o  w t o m ~ r r ~ ~  ~ o r n i n g *  my be little 
more t h a n  table lookup by a wtfme" coBposer that hat been designed to 
know the formats of the time expressions inside the  scheduler .  
This presentation has had t o  be unfor tuna te ly  s h o r t  for the amount  
of new naterial involved. A large n u ~ b e r  of interesting detail s a n d  
questions about t h e  processing have had t o  be oritted. A t  t h e  moaent 
<September, 19751, the data and control structures ~cntioned have been 
fully iep1e~ented and t e s t s  are underway on gedanken data. Hopefully, 
by the end of 1975 the component will have a reasonable g r a m a r  and will 
be working with messages and lexicons form the t w o  programs mentioned 
before. A MI7 A. I. l a b  technical r e p o r t  describing this work i n  d e p t h  
should be ready in the spring o f  n e x t  year. 
David McDonald 
Cambridge, Mass. 
References cited in the text: 
Genesereth, M. (1975) A MACSYMA Advisor. Project MAC, MIT, Cambr ldge ,  
Mass, 
Goldman, N. (1974) "Computer Generation of Natural Language fro. a Deep 
Conceptual Basee. memo AIM-247, Stanford Art l f  l c i a l  I n t e l  l igencc 
Lab., Stanford,  Calif, 
Goldstein, 1. (1975) "Barganing Between Goalsw. i h  the proceedings n f  
IJCAI-4, available from the MIT A I  l a b ,  
McDonald, D. (1975) The Design o f  a Program f o r  Generating p a t ~ . ~ ~  
Language. unpubl ished Master's Thesl s, MIT D e p t .  of El ectlcsl 
Engi neerf ng. 
Simmons, R. (1973) wSeaantic Networks: T h c l r  Computation and Use f o r  
Understanding E n g l i s h  Sentences" .  I n  S c h a n k  a n d  ~ o l b y  eds.  
Computer Models of Thought and Language. 
Winograd, T. (1972) Understanding Natural Language. Academic Press, New 
York, NY. 
American Journal of Computational Linguistics Microfiche 33 : 2 8  
RODGER KNAUS 
Systems  of t w a r e  D i v i s i o n  
S o c i a l  and  E c o n o m i c  S t a t i s t i c s  Administration 
B u r e a u  of the C e n s u s  
W a s h i n g t o n ,  D. C .  20233 
A human who l e a r n s  a language  can b o t h  p a r s e  a n d  g e n e r a t e  
s en t ences  i n  t h e  l a n g u a g e .  I n  c o n t r a s t  m o s t  a r t i f i c i a l  l a n -  
guage p r o c e s s o r s  o p e r a t e  i n  o n e  d i r e c t i o n  on ly  o r  requtre 
s e p a r a t e  grammars  f o r  pa r s ing  and g e n e r a t i o n .  T h i s  paper 
d e s c r i b e s  a model f o r  human language p roces s ing  w h i c h  u s e s  
a s i n g l e  l a n g u a g e  d e s c r i p t i o n  f o r  pa r s ing  and g e n e r a t i o n .  
1 .  Choice o f  P a r s i n g  Strategy 
A number o f  c o n s t r a i n t s  l i m i t  t he  p r o c e s s o r s  s u i t a b l e  a s  
m o d e l s  o f  h u m a n  l a n g u a g e  p r o c e s s i n g .  Because s h o r t  term 
memory i s  l i m i t e d .  t h e  l i s t e n e r  must a b s o r b  i n c o m i n g  w o r d s  
i n t o  l a r g e r  chunks a s  t h e  s e n t e n c e  i s  heard .  A l s o  b e c a u s e  
he  i s  e x p e c t e d  t o  r e p l y  w i t h i n  a c o u p l e  seconds a f t e r  t h e  
s p e a k e r  f i n i s h e s ,  r e g a r d l e s s  o f  l eng th  o f  t h e  s p e a k e r ' s  
u t t e r a n c e ,  t h e  l i s t e n e r  m u s t  do  much o f  t h e  s e m a n t i c  p r o c -  
e s s f n g  o f  a s e n t e n c e  a s  h e  h e a r s  i t .  
1 9  
Bever a n d  H a t t  p o i n t  o u t  t h a t  t h e  d i f f i c u l t y  i n  u n d e r -  
s t a n d i n g  a s e n t e n c e  S i s  n o t  p r e d i c t e d  by t h e  n u m b e r  o f  
t r a n s f o r m a t i o n s  u s e d  t o  g e n e r a t e  S .  F u r t h e r m o r e  t h e  p r o c e s s  
o f  d e t r a n s f o r r n a t i o n  a p p e a r s  t o o  t ime-consuming  ( p e t r i c k )  f o r  
t h e  a p p r o x i m a t e l y  two s e c o n d s  b e f o r e  a l i s t e a e r  i s  e x p e c t e d  
t o  r e p l y .  
A d e p t h  f i r s t  t r a n s i t i o n  ne twork  p a r s e r  (Woods, ~ a p l a n ) ,  
i n  w h i c h  p a r s i n g  d i f f i c u l t y  i s  m e a s u r e d  by t h e  n u m b e r  o f  a r c s  
t r a v e r s e d ,  c o r r e c t l y  p r e d i c t s  t he  r e l a t i v e  d i  f f i c u l  t y  o f  
a c t i v e  a n d  p a s s i v e  s e n t e n c e s  p r o g r e s s i v e  and  a d j e c t i v a l  p r e s e n t  
p a r t i c i p l e  s e n t e n c e s  a n d  t h e  e x t r e m e  d i f f i c u l t y  o f  m u l t i p l e  
center embeddings .  However  a s y n t a c t i c a l l y  d i r e c t e d  d e p t h  
f i r s t  p a r s e r  does  n o t  e x p l a i n  why s y n t a c t i c a l l y  s i m i l a r  
sentences s u c h  a s  
( 5 A )  The  h o r s e  s o l d  a t  t h e  f a i r  e s c a p e d .  
( 5 % )  The horse r aced  p a s t  t h e  barn f e l l .  
v a r y  i n  d i f f i c u l t y ,  n o r  does  i t  e x p l a i n  e x p e r i m e n t s  o n  t h e  
c o m p l e t i o n  a n d  v e r i f t c a t i o n  o f  ambiguous  s e n t e n c e s  (MacKay,  
Olsen and MacKay) w h i c h  s u g g e s t  t h a t  a p r u n e d  b r e a d t h  f i r s t  
s t r a t e g y  i s  used t o  par ce s e n t e n c e s .  S e n t e n c e s  w i t h  t w o  
equal l y  p l a u s i b l e  a1 t e r n a t i v e s  t o o k  l o n g e r  t o  p r o c e s s  t h a n  
s e n t e n c e s  w i t h  o n l y  one  l i k e l y  i n t e r p r e t a t i o n .  T h i s  e x t r a  
p r o c e s s i n g  t i m e  may b e  a t t r i b u t e d  t o  t h e  c o n s t r u c t i o n  o f  t w o  
a l t e r n a t e  i n t e r p r e t a t i o n s  o v e r  a 1 o n g e ~  p o r t i o n  o f  t h e  s e n t e n c e  
when more t h a n  one i n t e r p r e t a t i o n  i s  p l a u s i b l e .  
I n  a d d i t i o n  s u b j e c t s  s o m e t ~ m e s  become c o n f u s e d  by t h e  t w o  
i n t e r p r e t a t i o n s  o f  a n  a m b i g u o u s  s e n t e n c e .  F i n a l l y  i n  e x p e r i -  
m e n t s  i n  which s u b j e c t s  h e a r  a n  a m b i g u o u s  s e n t e n c e  i n  o d e  e a r  
a n d  a d i s f r n b i g u a t i n g  s e n t e n c e  s i m u l t a n e o u s l y  i n  t h e  o t h e r  e a r  
( G a r r e t t )  t h e  i n t e r p r e t a t i o n  a f  t h e  a m b i g u i t y  a c t u a l l y  p e r -  
c e l v e d  by t h e  s u b j e c t  may be s w i t c h e d  b e t w e e n  t h e  p o s s i b i l i t i e s  
by c h a n g i n g  t h e  d i s a m b i g u a t i n g  s e n t e n c e s .  
S t e p  3 ( a ) :  ( S  N P  ( N  mail) ( N  B o x e s ) )  
[ V  l i k e )  (.NP) (PP*)) 
(b): ( S  (NP ( N P  ( N  mall) ( N  B o x e s ) )  
( P P  ( P R E P  l i k e )  NP') (PP*)) 
V ( N P )  f p p * ) )  ( c ) :  ( S  ( N P  ( N  m a i l ) )  ( V  Boxes) 
I P P  ( P R E P  l i k e )  N P )  ( P P * ) )  (d): (S V m ail) (NP ( N  B o x e s ) )  
( P P  ( P R E P  like) N P )  (PP*)) 
( e ) :  ( S  ( V  m a i l )  
( N P  ( N P  ( N  B o x e s ) )  
( P P  ( P R E P  l i k e )  N P )  ( P P * ) )  
( p p *  1) 
A f t e r  completing t h e  sen tence  a f t e r  S t e p  4, t h e  parser 
produces phrase markers from a, c ,  d a n d  e by a d d i n g  t h e  l a s t  
word a n d  de l e t ing  unfilled optional n o d e s .  T h e  phrase marker 
obtained f r o m  48 i s  re jec ted  because i t  c o n t a i n s  an unfilled 
obligatory V n o d e .  
The incremental parser a d d s  e a c h  successive s e n t e n c e  word 
to t h e  partially completed phrase markers b u i l t  from the e a r l i e r  
p a r t  o f  t h e  s e n t e n c e .  The new word i s  added a t  t h e  l e f t m o s t  oblig 
u n f i l l e d  node o f  each partial p h r a s e  marker a n d  a t  all optional 
nodes t o  t h e  l e f t  o f  t h i s  node .  
T h r e e  d i f f e r e n t  operations a r e  used to a d d  a new word to 
a p a r t i a l  parse .  The word m a y  be d i r e c t l y  a d d e d  t o  an  unexpanded 
node ,  as i n  S t e p  3a a b o v e .  A1 ternatively, a new word may be 
a t t a c h e d  t o  a n  u n f i l l e d  n o d e  w i t h  a l e f t  b r a n c h i n g  a c y c l i c  tree  
b u i l t  from the  g r a m m a r  s u c h  a s  (PP P R E P  N P )  or ( S  ( N P  N, IN*)) V 
( N P )  ( P P * ) ) .  A t t a c h i n g  o c c u r s  i n  s t e p s  1 a n d  3c .  
Final ly  a subtrbe o f  a n  e x i s t i n g  p a r t i a l  phrase marker 
may be  4 e f t  embedded i n  a larger structure o f  t h e  same gram- 
m a t j c a l  c a t e g o r y ,  a s  i n  s teps  3b a n d  3e a b o v e .  T h e  e m b e d d i n g  
o p e r a t i o n  u s e s  a t  most t w o  left b r a n c h i n g  trees bui1 t f r o m  the 
gr'ammar: a t ree  TI w i t h  a s i n g l e  cycle on t h e  l e f t  branch i s  
used t o  r e p l a c e  t h e  e x i s t i n g  subtree E b e i n g  embedded.  I n  
s tep 3e ,  f o r  e x a m p l e ,  the  s tructure  ( S  ( V  m a i l )  ( N P  N P  ( P P * ) )  
( P P * ) )  would be o b t a i n e d .  The E i s  u s e d  to expand  t h e  l e f t -  
most u n e x p a n d e d  node o f  TI: for  3 b t h i s  r e s u l t s  i n :  
3 e .  (S ( V  m a i l )  (NP ( N P  ( N  B o x e s )  (N*)) P P * )  ( P P * ) ) .  
Finally t o  t h e  r e s u l t i n g  structure t h e  new sentence word i s  
a d d e d  t h r o u g h  d i r e c t  node e x p a n s i o n  o r  a t t a c h i n g  wi th  an 
acyclic l e f t  b r a n c h i n g  tree ;  i n  t h e  example a b o v e  t h i s  p r o d u c e s  
3e f r o m  3el' 
U s i n g  d i r e c t  e x p a n s t o n  a t t a c h i n g  a n d  e m b e d d i n g ,  t h e  
incremental parser f i n d s  a1  1 t h e  phrase markers o f  s e n t e n c e s  
f n  c o n t e x t  f r e e  o r  r e g u l a r  e x p r e s s i o n  l a n g u a g e ;  a formal 
d e f i n i t i o n  o f  t h e  parser a n d  a p r o o f  o f  i t s  correctness a p p e a r  
in [ l o ] .  
Sometlmes, a s  a t  s t e p s  3b and  3e,  t h e  same s truc ture  ( a  
prepos i t i obna l  phrase i n  s t e p  2) i s  used i n  more t h a n  o n e  p a r t i a l  
parse. Following Earley's Algo'rithm, the  incremental parser  
b u i l d s  a s i n g l e  copy o f  t h e  s h a r e d  substructure Sf!! a n d  m a i n t a i n s  
p o f n t e r s  l f n k i n g  Sb t o  n o d e s  i n  l a r g e r  s t ruc tures  w h i c h  $9 
expands .  
Far a l l  i t s  t r e e  b u i l d i n g  o p e r a t i o n s  the  incremental parser  
uses a flnlte s e t  o f  t r e e s .  e . ,  t h e  t r e e s  w i t h  o n l y  l e f t  sub -  
nodes  expanded and a t  most onelcycle on t h e  l e f t m o s t  b r a n c h .  
These trees may b e  computed djrectly from the grammar and  r e f -  
erenced by root and  leftmost unexpanded  node  d u r i n g  t h e  p a r s e .  
Using t h e s e  p r e c o n s t r u c t e d  t r e e s ,  t h e  incrementa l  parser requires 
o n l y  a f i x e d  number o f  o p e r a t i o n s  t o  a d d  a new word t o  a p a r t i a l  
pa r se :  a r e t r i e v a l  o n  a d o u b l y  indexed s e t ,  copying t h e  l e f t  
b ranching  t r e e ,  and a t  most four s t ruc tu re  c h a n g i n g  o p e r a t i o n s  
+o p a s t e  words a n d  t r e e s  t o g e t h e r .  
L i k e  E a r l e y ' s  Algor i thm,  IP p r o c e s s e s  each word p r o p o r t i o n -  
a l l y  t o  s e n t e n c e  l e n g t h .  However on s e n t e n c e s  s a t i s f y i n g  a depth  
d i f f e r e n c e  bound, t h e  p a r s i n g  time per word i s  c o n s t a n t .  Because  
humans c a n ' t  remember large numbers of  s e n t e n c e  w o r d s  b u t  must, 
process speech a t  an a p p r o x i m a t e l y  c o n s t a n t  r a t e ,  a c o n s t a n t  
p a r s i n g  t ime  per  ward i s  a n e c e s s a r y  p r o p e r t y  o f  a n y  a l g o r i t h m  
model i n g  human language  p r o c e s s i n g .  
Let t h e  depth  o f  c o n s t i t u e n t  C i n  p h r a s e  marker P be 
d e f i n e d  a s  t h e  l e n g t h  o f  t h e  p a t h  from t h e  r o o t  o f  C t o  t h e  r o o t  
of P .  I f  TI and T 2  a r e  tuo a d j a c e n t  t e r m i n a l s  w i t h  T I  preceding 
T 2 .  t h e  depth d i f f e r e n c e  f rom 11 t o  T2  i s  d e f i n e d  as t h e  d i f -  
f e r e n c e  i n  d e p t h  between 1 1  a n d  the  r o o t  ~f t h e  s m a l l e s t  t r e e  
c o n t a i n i n g  TI and T2.  For  e x a r n ~ l e  i n  t h e  phrase marker 
(9) ( S  ( N P  NP ( D E T  t h e )  ( N  t e l e p h o n e ) )  
[ P P  ( P R E P  I N )  (F(P ( D E T  t h e )  ( N  room)) )  
( V  r a n g )  ( A D V  l o u d l y ) )  
t h e  dep th  d i f f e r e n c e  between " t h e "  a n d  " te lephone" '  i s  1 and 
be tween  "roam" and " rang"  i s  3 .  
The  d e p t h  d i f f e r e n c e  be tween  11 and T 2  i s  t h e  number o f  
nodes f r o m  T I  t o  t h e  node expanded when adding T 2  on a p o s t o r d e r  
t r a v e r s a l  from T I  i n  t h e  p a r t i a l  phrase  marker c o n t a i n i n g  T I  b u t  
n o t  T 2 .  The d e p t h  d i f f e r e n c e  between T I  and T2 a l s o  r e p r e s e n t s  
t h e  number of  c o n s t i t u e n t s  o f  which T I  i s  t h e  r i g h t m o s t  w a r d .  
A proof ( requ ir ing  a forma.1 def in i  t i o n  o f  t h e  i ncremental 
parse)  t h a t  p a r s i n g  time per word i s  c o n s t a n t  i n  d e p t h  d i f f e r e n c e  
bounded sentences  appears i n  [ l o ] .  Informally the  depth d i f -  
ference  b o u n d  p l a c e s  a b o u n d  b o t h  o n  t h e  n u m b e r  o f  n e x t  nodes t o  
expand which may follow a g i v e n  terminal a n d  o n  t h e  a m o u n t  o f  
t r e e  traversal  w h i c h  t h e  parser must perform t o  f f n d  e a c h  next 
u n e x p a n d e d  node. Sfnce each m o d i f i c a t i o n  requires  only a fi'xed 
number o f  operati-ons,, e a c h  o f  w h i c h  i s  b o u n d e d  on the  f i n i t e  s e t  
o f  a t  most once c y c l i c  l e f t  branching t r e e s ,  t h e  c o m p u t a t i o n  
a d d i n g  a new word t o  e x i s t i n g  p a r t i a l  p a r s e s  i s  bounded i n d e  
p e n d e n t l y  o f  s e n t e n c e  l e n g t h .  
N a t u r a l  l a n g u a g e  sentences tend t o  h a v e  small d e p t h  d i f -  
f e r e n c e s .  B o t h  r i g h t  branching sentences and l e f t  b r a n c h i n g  
sentences ( f o u n d  i n  Japanese  f o r  e x a m p l e )  h a v e  a n  a v e r a g e  d e p t h  
d i f f e r e n c e  o v e r  e a c h  three or four word s e g m e n t  o f  two or l e s s .  
On t h e  o the r  hand  sentences are d i f f i c u l t  t o  u n d e r s t a n d  when 
they have two  c o n s e c u t i v e  large d e p t h  d i f f e r e n c e s ,  such a s  t h e  
mu1 t i  ple  center e m b e d d i n g  
( 1 0 )  The rat  the  cat t h e  d o g  b i t  chased d i e d b  
or t h e  complex n o u n  p h r a s e  i n  
The p a d  o n  a c l a r f n e t  i n  t h e  l a s t  row whicn 1 
f i x e d  e a r l i e r  far E b  fe7l o u t .  
Furthermore i n  amhlguous sentences such as  
(11)  Joe figured t h a t  it was t i m e  t o  t a k e  t h e  c a t  out. 
Kimball o b s e r v e s  t h a t  s u b j e c t s  pr i f er  t h e  r e a d i n g  w i t h  t h e  
smaller depth  difference. Flnally, Blumenthal found t h a t  s u b j e c t s  
tended t o  understand a m u l t f p l e  c e n t e r  embedded s e n t e n c e  a s  a 
conjunct1 ve sen tence .  The con junc t ive  sentence ~ o n t a i n s  a r e -  
arrangement. w i t h  lower depth differences o f  t h e  c o n s t i t u e n t s  o f  
t h e  c e n t e r  embedded sen tence .  
3 .  Sentence Generation 
The syntactic f o r m  g i v e n  to a sentence  depends on t h e  i n f o r -  
m a t i o n  being communicated i n  a sentence and on t h e  c u l t u r a l  con-  
t e x t  i n  w h i c h  t h e  sentence  appears .  C l a r k  a n d  Haviland show t h a t  
a speaker  uses va r ious  syntactic devices  sentences  t o  p lace  t h e  
" g i v e n "  informatian known t o  t h e  l i s t e n e r  be fore  t h e  informat ion 
"new" t o  t he  l i s t e n e r .  Particular s y n t a c t i c  s t r u c t u r e s  a r e  a l s o  
used t o  emphasize o r  suppress  p a r t i c u l a r  k i n d s  o f  informat ion;  
f o r  example newspaper t r a f f i c  a c c i d e n t  r e p o r t s  u s u a l l y  b e g i n  
w i t h  a pass ive  sentence  such a s  
( 1 2 )  An e l d e r l y  Lakewood man was i n ju red  when.. . , 
presumably t o  e m p h a s i z e  the r e s u l t  o f  the 
accident. 
To c a p t u r e  t h e  dependence o f  syntax on semantic con ten t  a n d  
b o c j a l  c o n t e x t ,  t h e  sentence  gene ra to r  uses f u n c t i o n - l i k e  grammar 
rules o f  t h e  form 
( R u l  erame C a t  Variables Predicate Forms ) . 
Rulename i s  t h e  name o f  t h e  rule  a n d  c a t  i s  t h e  grammatieal 
ca tegory  of t h e  c o n s t i t u e n t  generated by t h e  rul e m  
Variables  i s  a l i s t  o f  formal parameters .  Usually t h e  
v a r i a b l e  l i s t  c o n t a i n s  a v a r f a b l e  b o u n d  d u r i n g  r u l e  execut ion 
t o  a n o d e  i n  a semantic network and ano ther  v a r i a b l e  b o u n d  t o  
a c o n t r o l  a s s o c i a t i o n  l i s t  con ta in ing  i n f o r m a t i o n  about t h e  con- 
t e x t  i n  which  t h e  generated c o n s t i t u e n t  w i l l  a p p e a r  and poss ib ly  
t h e  s y n t a c t i c  form t h e  c o n s t i t u e n t  s h o u l d  h a v e .  
P r e d i c a t e  i s  a B o o l e a n - v a l u e d  f o r m  on the parameters i n  
V a r i a b l e s .  A rule i s  u s e d  only when P r e d i c a t e  i s  true .  
Forms i s  a l i s t  o f  forms d e p e n d i n g  on Variables  w h i c h  
generate terminals or calls t o  t h e  grammar f o r  s u b c o n s t i t u e r i t s  
o f  C A T .  
An example  o f  a g e n e r a t i o n  r u l e  i s  
(SPI SI (X  Y )  ( E q u a l  ( V o i c e  Y )  (Quote P a s s i v e ) )  
( N P  ( O b j e c t  X )  Y )  
t B e v e r b  X )  Pap ( A c t i o n  X ) )  
(M* X Y ) )  
w h i c h  generates simple p a s s i v e  s e n t e n c e s .  The v a r i a b l e  X i s  
bound t o  a node i n  a semant ic  n e t w o r k  and Y t o  a c o n t r o l  
a s s o c i a t i o n  l i s t .  The rule i s  a p p l i e d  only i f  t h e  control 
a l i s t  contains a p a s s f v e  f l a g  and i f  t h e  s e m a n t i c  node h a s  an 
o b j e c t  a n d  a c t i o n ;  i n  general  a r u l e  i s  a p p l i e d  only i f  t h e  
s e m a n t i c  subnodes called i n  t h e  r u l e  body appear in the 
semantic net .  The form ( N P  ( O b j  X )  Y )  generates a f o r m  ( N P  
X I  fl), where X B  i s  the semantic node on the object i n d i c a t o r  
from X .  a n d  Yj3  f s  t h e  v a l u e  o f  Y .  Beverb a n d  P a p  are procedures 
which generate r e s p e c t i v e l y  a form ~f t h e  verb " t o  be" a n d  a 
p a s t  part i c fp le  f o r m  o f  the verb A c t i o n ( X ) .  M *  i s  a procedure 
which generates a l i s t  d e p e n d i n g  on X a n d  Y such a s  ( P P ~ V a l u e  
o f  T l m e ( X ) >  < V a l u e  o f  Y > )  for  generating optional p r e p o s i t i ~ n a l  
phrases or  r e l a t f  v c  c l a u s e s .  
A S  each r u l e  i s  applied,  the l i s t  o f  terminals  a n d  c a l l s  t o  
grammar rules  generated by t h e  rule  i s  a d d e d  t o  a phrase m a r k e r  
representing the s t r u c t u r e  o f  the s e n t e n c e  b e i n g  generated. 
Grammar c a l l s  i n  t h e  phrase marker a r e  expanded t o p  d o w n - a n d  
l e f t  t o  r i g h t ,  i n  a p reo rde r  t r a v e r s a l  of t h e  g r o w i n g  phrase 
marker. As t e rmina l s  a r e  generated t h e y  a r e  p r in ted  o u t .  
As a n  e x a m p l e ,  i l l u s t r a t i n g  t h e  e f f e c t  of semantic and 
s o c i a l  c o n t e s t  on sentence genera t ion ,  an i n i t i a l  sentence O F  
a t r a f f i c  acc iden t  r e p o r t ,  
(13). A  man was k i l l e d  when a ca r  h i t  h i m  i n  I r v i n e .  
was generated from the  semantic nodes 
Al: Agent Afl A 2 :  Agent A @ :  Classman 
O b j e c t  v0 Action h i t  
Action Kil l  Object VJI) 
Place  I r v i n e  Instrument Car 
Cause A Z  
a n d  t h e  con t ro l  a l i s t .  
Purpose: 1n t roduc t ion ;cases :  o b j e c t ,  cause,  p lace 
using a grammar b u i l t  f o r  genera t ing  t r a f f i c  acc iden t  r epor t  
sen tences .  To summarize a t r a c e  of the  genera t ion ,  a c a l l  t o  
t he  sentence r u l e  w i t h  p u r p o s e  = in t roduc t ion  genera tes  a sentence 
c a l l  w i t h  voice  = pass ive .  The passive r u l e  app l i e s  and a  n o u n  
phrase on Afl i s  c a l l e d  for .  Because Purpose In t roduct ion  a 
N P  r u l e  a p p l i e s  which c a l l s  f o r  a NP t o  be  generated on the  
semantic c l a s s  t o  which A 8  belongs. Because CASES conta ins  
T I M E  a n d  C A U S E ,  t h e  passive r u l e  generated c a l l s  f a r  m o d i f y i n g  
s t r u c t u r e s  of t he se  C A S E S .  Because t h e  cause semantic node A 2  
has an a c t i o n ,  t h e  modif ier  r u l e  M = >  Rela t ive  conjunct ion S 
genera tes  the  c a u s e  while t h e  time i s  descr ibed by a preposi-  
t l o n a l  phrase.  The pronoun "him" i s  generated by a noun p h r a s e  
rule.  NP-1 which genera tes  a pronoun when t h e  f i rs t  semantic 
argument  t o  t h e  l e f t  o f  t h e  N P - 1  c a l l  i n  t h e  genera t ion  phrase 
marker w h i c h  i s  d e s c r i b e d  by t h e  same pronoun a s  t h e  s e m a n t i c  
argument A o f  NF-1 i s  i n  f a c t  equa l  t o  A .  
4 .  F i n d i n g  Semantic Preimages 
W h i l e  t h e  generator described in sec t ion  3 produces sentences  
from semantic a n d  contextual  informat ion,  the  incremental pa r se r  
described i n  sec t i on  2 recovers  merely t h e  s y n t a c t i c  s t r u c t u r e  
o f  a sentence.  To obta in  t h e  semantic arguments from which a 
sentence m i g h t  have been generated a procedure t o  I n v e r t  t h e  
generat ion r u l e  forms must be a d d e d  t o  t h e  incremented parser .  
While t h e  incremental pa r se r  begins t h e  cons t ruc t ion  o f  con- 
s t i t u e n t s  top  down, i t  completes them s y n t a c t i c a l l y  i n  a bottom 
up d i r e c t i o n .  In f a c t  IP executes pos torder  t r a v e r s a l s  o n  a l l  
t h e  s y n t a c t i c  parse  t r e e s  i t  b u i l d s ;  o f  course i f  a p a r t i c u l a r  
p a r t i a l  phrase  m a r k e r  can n o t  be f i n i s h e d ,  t h e  t r a v e r s a l  i s  n o t  
completed. However each node n o t  a tree  terminal o f  a s y n t a c t i c  
phrase  marker v i s i t e d  by t h e  incrementa l  p a r s e r  i s  a  s y n t a c t i c a l l y  
complete c o n s t i t u e n t .  
When the parser v i s i t s  a s y n t a c t i c a l l y  complete  c o n s t i t u e n t  
C ,  i t  a p p l i e s  a func t ion  INVERT t o  f i n d  t h e  semantic preimages 
o f  C .  I n  f i n d i n g  t h e  semantic s t r u c t u r e  o f  C ,  INVERT h a s  a v a i l -  
a b l e  n o t  only the s y n t a c t i c  s t r u c t u r e  o f  C ,  b u t  a l s o  t h e  s e m a n t i c  
preimages w h i c h  i t  found f o r  subconstituents o f  C. 'INVERT f i n d s  
t h e  s e t  o f  generat ion rules  w h i c h  might  proruce a c o n s t i t u e n t  
h a v i n g  the same s y n t a c t i c  f o r m  a s  C .  F o r  each such rule R., 
I N V E R T  c o n s t r u c t s  a l l  t h e  p o s s i b l e  par ings  between e a c h  o u t p u t -  
g e n e r a t i n g  form F of R and t h e  c o n s t i t u e n t s  of C which F might 
produce .  For  e x a m p l e  i f  C i s  
( S  ( N P  Man) (Beverb i s )  ( P A P  I n j u r e d ) )  
t h e  p a i r i n g  e s t a b l i s h e d  f o r  t h e  p a s s i v e  s e n t e n c e  r u l e  would  b e  
( N P  ( O b j e c t  X )  Y )  ( N P  t h e  m a n )  
(Beverb X )  (Beverb i s )  
( p a p  (Act ion  X ) )  ( P a p  I n j u r e d )  
( M *  X Y )  N I L  
The p a i r  ( (Equa l  (Voice Y )  PASSIVE) 1) i s  a l s o  c r e a t e d ,  s i n c e  
t h e  r u l e  p r e d i c a t e  i s  t r u e  whenever a r u l e  a p p l i e s .  
Each i n d i c i d u a l  p a i r  P i n  s-uch a p a i r i n g  of a ru le  form and 
r u l e  form o u t p u t s  i s  p r o c e s s e d  by a f u n c t i o n  FIND which r e t u r n s  
an a s s o c i a t i o n  l i s t  c o n t a i n i n g  p o s s i b l e  v a l u e s  o f  t h e  r u l e  
pa rame te r s  ( X  and Y i n  t h e  example a b o v e )  w h i c h  w o u l d  produce 
t h e  o u t p u t  a p p e a r i n g  i n  P .  For  t h e  example above F I N D  would 
p r o d u c e  
( X ( ( O b j e c t  Man) Y NIL)) ( 1  x ( ( r i m e  p a s t )  Y NIL)) 
( (  X N I L )  ( Y  ( (  Cases N i l ) ) ) ) .  
( (  X NIL)  ( Y  ( (  Voice P a s s i v e ) ) ) )  
Using an e x t e n s i o n  t o  a s s o c i a t i o n  l i s t s  o f  t h e  computa t ional  
l o g i c  U n i f i c a t i o n  Algor i thm,  t h e s e  a s s o c i a t i o n  l i s t s  a r e  u n i f i e d  
i n t o  a s i n g l e  a s s o c i a t i o n  l i s t ,  which f o r  t h e  example i s  
( (  X ( ( A g e n t  man) (Time P a s t )  (Act ion  I n j u r e ) )  
( (  Y ( ( C a s e s  N i l )  ( V o i c e  P a s s i v e ) ) ) )  
Finally I N V E R T  creates a grammar r u l e  c a l l ,  
( S  ( (Agen t  man)(Time P a s t ) ( A c t i o n  I n j u r e ) )  
( ( C a s e s  N i l ) ( V o i c e  P a s s i v e ) ) ) )  
f r o m  t h e  a s s o c i a t i o n  l i s t  and  s t o r e s  t h e  r e s u l t  i n  t h e  i n v e r s e  
image o f  C .  
I n  f i n d i n g  a s e m a n t i c  preimaqe, t h e  I N V E R T  f u n c t i o n  must 
know w h i c h  grammar r u l e s  m i g h t  produce a p a r t i  c u l  a r  g r a m m a t i  cal 
c o n s t f  t u e n t .  T h i s  information i s  computed by symbol ical ly e v a l -  
u a t i n g  t h e  grammar r u l e s  t o  produce  t h e  strings o f  r e g u l a r  
e x p r e s s i o n  grammar ncnterminals ( a s  opposed to g r a m m a r  calls) 
representing t h e  p o s s i b l e  o u t p u t  o f  e a c h  rule. T h e  resulting 
r e l a t i o n  from rules t o  s t r i n g s  is i n v e r t e d  into a t a b l e  g i v i n g  
p o s s i b l e  rules g e n e r a t i n g  e a c h  string. 
The h e a r t  of t h i s  s y m b o l i c  e v a l u a t o r  i s  a  f u n c t i o n  E T E R M  on  
t h e  o u t p u t  g e n e r a t i n g  forms o f  a r u l e  w h i c h  r e t u r n s  a l i s t  a l l  
lists o f  regular e x p r e s s i o n  nonterminals representing the out- 
p u t  o f  a f o r m .  E T E R M  t a k e s  a d v a n t a g e  o f  t h e  s i m i l a r  s y n t a x  o f  
most grammar rule forms, a n d  is d e f i n e d  i n  s i m p l i f i e d  f o r m  
( w i t h  comments i n  a n g l e  b r a c k e t s )  a s  
Eterm ( f o r m )  = 
i f  a t o m  (form) t h e n  N I L  
<terminates recurs i o n >  
else i f  car ( f o r m )  i s  a g r a m m a t i c a l  c a t e g o r y  
then l i s t  (Ifst ( c a r  ( f o r m ) ) )  
< t h e s e  f o r m s  generate  a s i n g l e  grammar c a l l >  
e l s a  i f  c a r  ( f o r m )  = F U N C T I O N  ar L A M B D A  
t h e n  E T E R M  ( c a d r  ( f o r m ) )  
e l s e  i f  car  ( f o r m )  = L A M B D A  
then ETERM ( c a d d r  ( f o r m ) )  
else i f  c a r  ( f o r m )  = L l S T  
i f  form i s  n o t  properly contained i n  a L I S T  
e x p r e s s i o n  
then Mapcar((Function Concatenate) 
(Cartesian 
( (Mapcar  (Function E T E R M )  
c d r  ( f o r m ) )  ) ) 
< o u t e r  L I S T S  a r e  used t o  c r e a t e  lists o f  g r a m m a r  c a l l s >  
e l s e  i f  farm I s  i n s i d e  e L I S T  e x p r e s s i o n  
E T E R M  ( c a d r  ( f o r m ) )  
< i n n e r  l i s t s  are u s e d  t o  c r e a t e  g r a m m a t i c a l l y >  
e l s e  if c a r  ( f o r m )  = M A P C O N C  t h e n  m a k e  o p t i o n a l  
a n d  r e p e a t a b l e  a l l  t h e  n o n t e r r n i n a l s  r e t u r n e d  
in E T E R M  ([function a r g u m e n t  of MAPCONC]) 
e l s e  i f  car  ( f o r m )  = COND 
t h e n  MAPCONC((LAMBDA(X) ETERH ( [ l a s t  f o r m  i n  X I )  
( c d r  f o r m )  
< r e t u r n s  a l t e r n a t i v e s  f r o m  each b r a n c h  o f  t h e  COND> 
e l s e  i f  car ( f o r m )  i s  a u s e r - d e f i n e d  f u n c t i o n  
t h e n  ETERM ( [ d e f i n i t i o n  o f  f u n c t i o n ] )  
e l s e  i f  t h e r e  i s  a s t o r e d  v a l u e  f o r  ETERM ( f o r m )  
t h e n  t h a t  v a l u e  
e l s e  a s k  t h e  t h e  u s e r  f o r  h e l p  
The f u n c t i o n  FIND w h i c h  r e t u r n s  p o s s i b l e  b i n d i n g s  f o r  r u l e  
v a r i a b l e s  when g i v e n  a r u l e  f o r m  and  i t s  o u t p u t  i s  d e f i n e d  below. 
The v a r i a b l e  AL1,ST h o l d s  t h e  v a l u e  o f  t h e  a s s o c i a t i o n  l i s t  b e i n g  
h y p o t h e s i z e d  by FIND; t h i s  v a r i a b l e  i s  N I L  when FIND i s  c a l l e d  
f r o m  I N V E R T .  
L i k e  ETERM, t h e  d e f i n i t i o n  o f  F I N D  i s  b a s e d  on  t h e  r u l e s  
f o r  e v a l u a t i n g  r e c u r s i v e  f u n c t i o n s .  
F I N D  ( A l i s t  f o r m  v a l u e ) =  
i f  e v a l  ( f o r m  a1  f s t ) = v a l  ue t h e n  l i s t  (A1  i s t )  
e l s e  i f  r e c u r s i o n  d e p t h  exceeded,  t h e n  N I L  
e l s e  i f  a tom ( f o r m )  t h e n  l i s t  (Merge  ( l i s t  ( c o n s  
( f o r m  V a l u e ) )  A l i s t )  
e l s e  i f  c a r  ( f o r m ) =  COND 
l e t  L = c l a u s e s  w h i c h  m i g h t  b e  e n t e r e d  by 
e v a l u a t i n g  f o r m  
t h e n  Mapconc (FM 1 )  w h e r e  
FM ( c l a u s e )  = l i s t  (Merge  F i n d  ( A l i s t  Car  ( c 1 a u s e ) T )  
F i n d  ( A l i s t  l a s t  ( c l a u s e ) ) )  
e l s e  i f  c a r  ( f o r m )  = Q u o t e  t h e n  i f  c a d r  ( f o r m )  = v a l u e  
t h e n  A l i s t  e l s e  N I L  
e l s e  i f  c a r  ( f o r m )  i s  a d e f i n e d  f u n c t i o n  
t h e n  FIND ( A l i s t  ( S u b s t i t u t e  c d r  ( f o r m )  f o r  
f o r m a l  p a r a m e t e r s  i n  d e f i n i t i o n  
o f  c a r  ( f o r m ) )  
V a l u e )  
e l s e  i f  c a r  ( f o r m )  = MAPCONC ( f n  1 s t )  
t h e n  Me'rge ( F i n d  ( A l i s t  1 s t  v a l u e )  
F o r  each  X i n  1st. M e r g e  ( A l i s t  for X ) )  
< t h i s  c l a u s e  makes t h e  a s s u m p t i o n ,  w h i c h  w o r k s  i n  
p r a c t i c e ,  t h a t  f n  g e n e r a t e s  e i t h e r  o n e - e l e m e n t  
o r  emp ty  l i s t s ,  
e l s e  N I L  
With  a d e f i n i t i o n  o f  F I N D  s i m i l a r  t o  t h e  one a b o v e ,  t h e  
parser f o u n d  t h e  p r e i m a g e  
( 3  ( ( ( p l a c e  ( ( c l a s s  ( p a r k ) ) ) )  ( a g e n t  ([class ( m a n ) ) ) )  
( a c t i o n  ( w a l k e d ]  
[ t h e  e x t r a  p a r e n t h e s e s  d e n 3 t e  l i s t s  o f  a l t e r n a t i v e s ]  f o r  t h e  
s e n t e n c e  
( 1 3 )  T h e  man w a l k e d  i n  t h e  p a r k .  
g e n e r a t e d  b y  t h e  grammar 
[Sp S ( X )  T ( N P  (Agent  X ) )  ( V ( A c t i o n  X ) )  
( O p t i o n a l  ( P P  ( P l a c e  X )  ( ( C a s e  P l a c e ]  
[ N P f l  NP ( X )  T ( D e t  X )  t N ( C l a s s  X I  
[ p p a  PP ( X Y )  T ( P r e p  X Y )  ( N P X ]  
and  t h e  p r e p o s i t i o n  f u n c t i o n  
P r e p  ( X Y )  = S e l e c t q  ( A s s o c  CASE Y )  
( P l a c e  I N )  
(Instrument W I T H )  
( S o u r c e  FROM] 
5.  Imp1  e m e n t a t i o n  
The p r o c e s s o r s  d e s c r i b e d  i n  t h i s  p a p e r  h a v e  been programmed 
i n  U n i v e r s i t y  o f  C a l i f o r n i a ,  I r v i n e ,  L I S P  and r u n  i n  a b o u t  4 5 K  on 
a PDP-10 computer. 
R e f e r e n c e s  
B e v e r ,  Thomas G .  1970.  I n  ? 7 1  a n d  [ 5 ] .  
C l a r k ,  H e r b e r t  H .  and H a v i l a n d ,  Susan E .  1 9 7 5  S o c i a l  S c i e n c e s  
Working P a p e r ,  67.  U.C. I r v i n e .  
- 
C o l b y ,    en jam in W .  1973 .  A m e r i c a n  A n t h r o p o l o g i s t  7 5 ,  6 4 5 - 6 2 .  
F l o r r e s  d ' A r c a i o  and  L e v a l t ,  e d s .  1970  A d v a n c e s  i n  Psycholin- 
g u i s t i c s ,  N o r t h  H o l l a n d ,  Amsterdam.  
G a r r e t t ,  M e r r i l l ,  F .  1970 .  i n  [ 5 ] .  
Haynes,  J o h n  R .  1970 .  C o g n i t i o n  -- a n d  t h e  D e v e l o p m e n t  - o f Lanquage .  
John W f l e y .  
Kap lan ,  ~ o n a l d  M. 1972.  A . I .  3, 77 -100  
Kimball, J o h n  1974.  C o g n f t i o n  2,1,15-47.  
Knaus, Rodge r .  1975 .  Ph.D T h e s i s .  U . C .  I r v i n e .  
MacKay, D o n a l d  G. 1966.  P e r c e p t i o n  a n d  P s y c h o p h y s i c s .  4 2 6 - 3 6 .  
O l s o n ,  James N. and  MacKay ,  D o n a l d  G.  J V L V B  1 3 ,  45770 .  
P e t r i c k ,  S. R. I n  [ 1 4 ] .  
R u s t i n ,  R a n d a l l .  1973 .  N a t u r a l  Lanquage  process in^. 
W a t t ,  Wm. 1970.  I n  [ 7 ]  
woods,  w 1973.  I "  [iil. 
American Journal of Computational Linguistics Microfiche 33 : 33 
D e p a r t m e n t  of Computer S c i e n c e  
U n i v e r s i t y  of H o u s t o n  
Houston, T e x a s  7 7 0 0 4  
ABSTRACT 
A theoretical model for nominal compound formation in English 
is presented in which the rul-es are representations of lexical 
processes. It is argued that such rules can be genera l i zed  to 
account f o r  many nominal compounds with similar structure and 
to enable new compounds to be produced and understood. It is 
shown that nominal compounding depends crucially on the existence 
of a llcharacteristic'' r e l a t i o n s h i p  between a nominal and t h e  
vexb which occurs in a relative clause paraphrase of a compound 
which contains the nominal. A computer implementation of the 
model is presented and the problems of binding and rule selection 
a r e  discussed. 
Linguistic Issues. 
Nominal compounds are sequences of two or more nominals 
which have the semantic effect of noun phrases with attached 
relative clauses. The rightmost nominal is general ly  i he primary 
referent of t h e  compound the other nominals restrict the 
reference of the rightmost nominal i n  much the same fashion t h a t  
a relative clause does. Tbeae are, of course, exceptions in 
which t h e  rightmost nominal i s  figurative or euphemistic 
(e.g. family jewels). Compounds occur frequently in English and 
Germanic languages, but infrequently in the Romance languages 
where their function is largely performed by nominal-preposition- 
nominal sequences (e. g. chemin de fer , agent de change) . 
_ _ C  -
The s y n t a c t  kc s t r u c t u r e  nominal compounds is quite simple 
--the three variants are NAN, N-participle-N, and N-gerund-N. 
In the N-N form, either 0% the two nominals may in fact be yet 
another nominal compound, giving a structure like (N-N)-N or 
N-(N-N); the f irst  of these forms seems to occur much more often 
than the second (examples of each t y p e  are: typewriter  mechanic,  
liquid roach poison). 
I assume that the  process of nominal compounding is syntac- 
tically a process in which a relat ive  clause is reduced by delet- 
ing all elements of the  relative c l a u s e  but one and preposing t h e  
single remaining element i n  front  of the  antecedent nominal. In 
addition, the clause verb may be nominalized 4nd preposed. Other 
linguists have proposed different derivations for nominal 
compounds; Lees [ 3 ] ,  for example, derives nominal compounds from 
nominal-preposition-nominal sequences. There are two reasons why 
I feel that Lees approach i s  wrong: (1) there are English 
compounds for which no reasonable equivalent nominal-prepos it ion-  
nominal paraphrase can be given (e.g.  windmill), and (2) there 
are subtle meaning differences between t h e  nominal compounds and 
their nominal-preposition-nominal counterparts (county clerk vs. 
clerk for the county). I f  nominal compounds and nominal- 
--
preposition-nominal sequences are derived from forms l i k e  
relative clauses, then the differences in meaning can be accounted 
f o r  by deriving each form from a d i s t i n c t  r e l a t i v e  c l a u s e ;  t h e  
relative clauses may, of c o u r s e ,  be quite c l o s e l y  r e l a t e d  t o  
each other. 
I have spoken r a t h e r  l o o s e l y  about  d e r i v i n g  nominal compounds 
from r e l a t i v e  c l a u s e s ;  I am n o t  proposing a d e r i v a t i o n  system 
which operates on s u r f a c e  forms of t h e  language,  and what I 
i n t e n d  t h a t  t h e  reader should  unders tand is that an unde r ly ing  
form f o r  a nominal compound is de r ived  from an  unde r ly ing  form 
f o r  a r e l a t i v e  clause by a language p rocess  which I term a 
l e x i c a l  rule because,  a s  we s h a l l  see, t h e  o p e r a t i o n  of such  
ru les  depends c r u c i a l l y  on the specific lexical items which are 
p r e s e n t  i n  the underlying s t r u c t u r e s .  Linguists have i d e n t i f i e d  
a number of lexical processes in English; some examples of such  
p rocesses  may be found in [I] and [ 2 ] .  
The unde r ly ing  forms a s s o c i a t e d  w i t h  r e l a t i ve  clauves and 
nominal compounds in t h e  model of nominal c om pounding being 
presented here a r e  networks (trees f o r  t h e  most p a r t )  defined 
in terms of a c a s e  grammar which is c l o s e l y  r e l a t e d  t o  t h a t  
used by S imon8 [ 51. The cases which appear  i n  t h i s  system f a l l  
i n t o  two general c a t e g o r i e s :  (1) cases of t h e  c l a u s e  verb,  which 
a r e  the fo l lowing  -- Performer,  Object, Goal, Source,  Locat ion,  
Means, Cause, and Enabler  -- and (2) s t r u c t u r a l  c a s e s ,  which a r e  
R E E L  ( r e l a t i v e  c l a u s e )  and COMP (compound). I w i l l  not  e x p l a i n  
these c a s e s  i n  d e t a i l ,  a s  t h a t  is t h e  s u b j e c t  of a forthcoming 
paper .  But the fo l lowing  o b s e r v a t i o n s  w i l l  i l l u m i n a t e  the case 
system f o r  verb  cases. The c a s e  s y s t e m  d i s t i n g u i s h e s  t h e  
immediate performer of a n  act from a remote cause or  agent of 
the act. The reason for this distinction l i e s  in an i n t i m a t e  
connect ion between verbs and the assumed o r  h a b i t u a l  performer 
of t h e  act  which i s  t h e  reference of the verb. The case system 
also distinguishes an a c t i v e  causative agent of an act  from 
a n  agen t  which mere ly  permi t s  t h k  a c t  t o  o c c u r ;  t h i s  d i s t i n c t i o n  
i n  the case system permi t s  two classes of ve rbs  t o  be distinguished 
accord ing  Po whether t h e  surface subject commonly causes  t h e  ac t  
o r  permits t h e  ac t  to  occur .  
The case s y s t e m  used i n  the present model o f  nominal 
campounding is not a deep case system; on the contrary, it Seems 
that  nominal compounding is a lexical process which occurs 
rather near t h e  surface i n  a d e r i v a t i d n a l  grammar model. An 
example which can be given t o  support t h i s  is t h e  compound 
ignition - key;  t h i s  is a key Vhich turns  a s w i t c h  which enables 
a complex sequence o f  events to  take place t h a t  u l t i m a t e l y  re su l t  
i n  the i g n i t i o n  of a fuel/air mixture i n  an eng ine ,  ar one may 
describe it equ ivaaent ly  a s  a key which causes  i g n i t i o n .  The 
f irst  a e s c r i p t i o n  corresponds to a deep c a s e  l e v e l  of d e s c r i p t i o n  
w h i l e  the  second corresponds to  t h e  l e v e l  a t  which the compound 
i g n i t i o n  key  is formed. I would argue tHat if one takes the 
deep case approach, then one is forced  t o  inc lude  a great d e a l  
of structure i n  the r u l e s  for nominal compounding; i n  particular, 
t h e  rule for  i g n i t i o n  - key must remove all af t h e  l i n k s  i n  t h e  
causal chain l e a d i n g  to  the i g n i t i o n  a c t .  The d e l e t i o n  of this 
in termediate  information mast be done to o b t a i n  the d e s c r i p t i o n  
given in t h e  second case, and t o  inc lude  the d e l e t i o n  procedure  
i n  both a  compounding ru le  and in the rule process which leads 
to  the shorter description means u n n e c e s s a r i l y  duplicating t h e  
procedure. Moreover, i f  one d e r i v e s  compounds from paradigm 
re lat ive  clauses of the second sort ,  e . g .  key which causes an 
a c t i o n  to  occur, then it is possible to  generalize compound 
forming rules so that a siqgle rule may produce several 
compounds. I t  will not  be p o s s i b l e  to  do  this if deep cases are 
used a s  t h e  deep c a s e  structure o f  f i r i n g  key w i l l  be quite 
-
d i f f e r e n t  from that  of i g n i t i o n  key. 
In order  t b  understand t h e  model of compounding whfch is 
being presented here, it is essent ia l  t o  cons ider  the f u n c t i o n  
of wmpounding in language. I n  my v i e w ,  compounding is a p r o c e s s  
which allows a speaker to  systematic8lly deLete i n fo rma t ion  from 
an utterance just when the speaker has reason to expect that the 
hearer can reconstruct that information.  I n  effect ,  I c o n s i d e r  
compounding (and a great many other linguistic procesbes) ro be 
examples of linguistic encoding which are used t o  speed  up 
communication, and t h e  grammar sha red  by t h e  speake r  and h e a r e r  
must i n c l u d e  t h e  encodihg and decoding f u n c t i o n s .  
Consider  t h e  nominal compound steam d i s t i l l a t i o n ,  which 
r e f e r s  t o  t h e  d i s t i l l a t i o n  of  same subs tance  w i t h  s team; t h e  
h e a r e r  o f  t h e  compound steam d i s t i l l a t i o n  knows t h a t  d i s t i l l a t i o n  
is t h e  d e r i v e d  nominal form of  d i s t i l l .  The hearep  a l s o  knows 
what t h e  common o r  c h a r a c t e r i s t i c  c a s e s  of the verb  d i s t i l l  a r e :  
t h e  agen t  is i n v a r i a b l y  a person o r  machine ( t h i s  would be t h e  
occupant of  t h e  Cause case s l o t  i n  my s y s t e m ) ,  t h e  ins t rument  
(or Means) may be an a p p a r a t u s  or  a heated medium such a s  steam 
and t h e  Goal is a l i q u i d  which is miss ing  some of  t h e  c o n s t i t u e n t s  
that it e n t e r e d  t h e  d i s t i l l a t i o n  process  w i t h .  
I t  happens t h a t  i n  Eng l i sh ,  whenever a, de r ived  nominal of a n  
a c t  i s  the r i g h t  element i n  a compound, then  t h e  l e f t  element is 
almbst always an  occupant of  one of  t h e  c a s e  s l o t s  o f  t h e  verb.  
I n  o r d e r  t o  r e c r e a t e  the under ly ing  r e l a t i v e  c l a u s e  s t r u c t u r e ,  i t  
is o n l y  necessa ry  for t h e  h e a r e r  t o  p r o p e r l y  choose t h e  case f o r  
t h e  nominal steam. A g r e a t  d e a l  of l e x i c a l  in format ion  can be 
brought t o  b e a r  on t h i s  q u e s t i o n ;  for  example, steam i s  not  a 
l i q u i d ,  is water  vapor and t h u s  cannot 
subs t ance  o r  t h e  end product  o f  a d i s t i l l a t i o n  process .  Steam 
might b e  t h e  Cause of t h e  a c t  o f  d i s t i l l a t i o n  except  t h a t  there 
do no t  seem t o  be any compounds i n  Engl i sh  which have d i s t i l l a t i o n  
a s  t h e  r i g h t  element and a Cause a s  t h e  l e f t  e lement .  Thus the 
h e a r e r  can a s s i g n  s team t o  t h e  Means c a s e  w i t h  some assurance .  
-
I n  ano the r  example, shrimp b o a t ,  t h e  h e a r e r  can a s c e r t a i n  
by l e x i c a l  r e l a t i o n s  invo lv ing  t h e  word boa t ,  t h a t  boa t s  are 
c h a r a c t e r i s t i c a l l y  used t o  c a t c h  marine l i f e .  One choice  eor t h e  
main verb  i n  a synonymous r e l a t i v e  c l a u s e  is c a t c h ,  which w i l l  
have boa t  a s  an  element of t h e  Means c a s e .  The Cause f o r  c a t c h  
is commonly a person or perhaps a s o p h i s t i c a t e d  machine designed 
t o  o a t c h  t h i n g s  ( i . e .  a t r a p ) .  The O b j e c t - i s  c h a r a c t e r i s t i c a l l y  
a n  animal .  There is a s t r o n g  c h a r a c t e r i s t i c  r e l a t i o n  between 
t h e  animal  being caught and t h e  means used t o  catch i t ,  for example 
mink is t r apped ,  calves are roped,  b i r d s  a r e  n e t t e d ,  and f i s h  a r e  
caught w i t h  a boa t .  Th is  r e l a t i o n  e x i s t s  a s  a r u l e  i n  t h e  lbxfcon 
of both t h e  speaker and the hearer and i t  enables t h e  speaker t o  
produce the  nominal compound and the  hearer t o  understand i t .  
Furthermore, shrimp - boat is one member of a c l a s s  of 
c lose ly  r e l a t e d  nominal compounds whioh includes l o b s t e r  - boat,
whale boat tuna boat and many others .  I t  would be most 
- -' 
in teres t ing  i f  a s i n g l e  rule  could be formulated which would 
generate a l l  of these  cqpounds .  A l o b s t e r  boat is a boat 
which is used t o  catch l o b s t e r ,  a tuna boat is a  boat which is 
used t o  catch tuna, and so forth. A l l  of these  examples a r e  
i d e n t i c a l  except f o r  t h e  p a r t i c u l a r  marine animal being caught. 
The l o g i c a l  next s t e p  is the  c r ea t i on  of a r u l e  which generalizes 
the  individual marine anfmals t o  the cbmmon category of m a r i n e  
animal. Th is  r u l e  f i l l  state that a marine animal boat is a boat 
which is used t o  ca tch  marine animals, 
I n  making t h i s  genera l iza t ion ,  I have given t h e  rule the  
power t o  help i n t e r p r e t  novel compounds and t o  generate them. 
With t h i s  power comes a d i f f i c u l t y ,  Which is const ra in ing the  
rule so  t h a t  it does not generate bad compounds o r  produce 
incorrect i n t e rp r e t a t i ons .  The k e y  t o  t h i s  constra'int l i es  
i n  what I w i l l  term t h e  c h a r a c t e r i s t i c  o r  hab i tua l  aspect of 
nominal compomds. I n  the case of the boat compounds, a  boat 
will only be a shrimp boat i f  it is c h a r a c t e r i s t i c a l l y ,  usua l ly ,  
hab i tua l ly  o r  invarfably used t o  ca tch  shrimp. So the operat ion 
of a compounding rule is enabled only i f  a  c h a r a c t e r i s t i c  aspect 
is associa ted  with t he  verb; i n  English,  this is usua l ly  indicated 
b y  a n  adverb o r  an adverbial phrase. If the speaker is wi l l ing  
t o  a s s e r t  that a  boat is c h a r a c t e r i s t i c a l l y  used t o  catch t u r t l e s ,  
then the nominal compound t u r t l e  boat may be used. The hearer 
sill use the general r u l e  t o  place t u r t l e  and boat i n  the proper 
case slots, and because a compound was used b y  the  speaker, the 
hearer w i l l  i n f e r  Qhat the boat is one which  is c h a r a c t e r i s t i c a l l y  
used to catch t u r t l e s ,  
There are other  problems which arise with the genera l iza t ion  
of rules; for  example, compounding never produces a compound i n  
which the l e r t  element is a proper noun, unless the proper noun 
ie t h e  name of a process (e.g. Harkov process) or  is a Source, 
Performer, o r  Goal of an a c t  of g iv ing.  It a l s o  seems t o  be t r u e  
t h a t  compounds are not genera l ly  formed when a l e x i c a l  i t e m  is 
several levels  below t h e  general term which appears i n  the r u l e  
(e.g. r e p a i m i d g e t )  o r  when a c r o s s - c l a s s i f i c a t o r y  term is used 
(e.g. automobile Indian  as an Indian who r e p a i r s  automobiles). 
With all of the preceding discussion in mind, I would now like t o  
t u r n  t o  the model of nominal compounding which I have p resen t ly  
implemented and running. 
The Computer Model 
The computer model of compounding accepts  r e l a t i v e  c lause  
s t r u c t u r e s  as input  and produces nominal compound s t r u c t u r e s  a s  
output when t h e  input  is appropr ia te .  It is w r i t t e n  i n  a language 
with many parentheses t h e  language was chosen f o r  its program 
development f a c i l i t i e s ,  i . e .  b u i l t - i n  e d i t o r ,  r a the r  than for its 
i n t e r p r e t i v e  c a p a b i l i t i e s .  The program which produces nominal 
compounds is a p a t t e r n  matching i n t e r p r e t e r ;  it appl ies  a r u l e  
of compound formation by matching one side of t h e  r u l e  w i t h  t h e  
input s t r u c t u r e ,  and i f  c e r t a i n  c r i t e r i a  are s a t i s f i e d  by t h e  
match, i t e m s  from the input  s t r u c t u r e  a r e  bound i n t o  t h e  r u l e ,  
t r ans fe r red  t o  t h e  o the r  side of the r u l e ,  and a copy is then 
maae a f  the o the r  s ide  of the r u l e .  The r e s u l t  is a nominal 
compound s t r u c t u r e .  
The model has two components: a r u l e  interpreter and a 
lexicon of r u l e s  for compounding. There is nothing t r i c k y  
about r u l e  app l i ca t ion .  Consider t h e  nominal compound flower 
market and i t s  associa ted  r e l a t i v e  c lause  paraphrase - market 
where f lowers - are c h a r a c t e r i s t i c a l l y  sold.  These phrases have 
i n  my system t h e  underlying structures shown i n  Figure 1. 
The no ta t ion  i n  square braces means t h a t  the verb se l l  has the 
characteristic aspect  i n  this instance. 
market I RELCL 
sell [+char]  
m / \J- 
market flowers Figure 1. 
market 
flower 
These two s t r u c t u r e s  can be made i n t o  a rule by l i n k i n g  them 
t o g e t h e r .  Whenever a r e l a t i v e  c l a u s e  s t r u c t u r e  i d e n t i c a l  t o  
t h a t  i n  F igu re  1 is r e c e i v e d ,  t h e  r u l e  a p p l i e s  and a copy is 
c r e a t e d  of t h e  nominal compound f lower  - market .  The matching 
procedure  is a r e l a t i v e l y  s t r a i g h t f o r w a r d ,  t o p  down, r e c u r s i v e  
p r o c e s s  which has  b a c k t r a c k i n g  c a p a b i l i t y  i n  t h e  even t  t h a t  
a s t r u c t u r e  o r  c a s e  o c c u r s  more than  once a t  any g i v e n  l e v e l  of  
the  s t r u c t u r e .  There a r e  two problems which arise; however: 
i f  e r u l e  is g e n e r a l i z e d  t o  account f o r  compounds o t h e r  t h a n  
flower market, then t h e  l e x i c a l  i tems i n  t h e  r u l e  w i l l  behave a s  
v a r i a b l e s  and some p r o v i s i o n s  must be made for binding of values  
t o  these v a r i a b l e s ;  a l s o ,  t h e  r u l e  i n t e r p r e t e r  must  have some 
h e u r i s t i c s  f o r  s e l e c t i n g  a p p r o p r i a t e  r u l e s  i f  t h e  time requ i red  
t o  produce a compound is not  t o  i n c r e a s e  exponentially w i t h  t h e  
size of the l e x i c o n .  
The p r e s e n t  version o f  t h e  model only p a r t l y  so lves  the 
binding problem. Consider the r u l e  given i n  Figure 2 w h i c h  is  a 
g e n e r a l i z a t i o n  of  that given  in Figure  1. 
market 
I 
s e l l  [+cha r ]  
LOC 
market goods 
market I C O W  
goods 
Figure 2.  
If this rule is t o  app ly  t o  the  r e l a t i v e  clause structure glven i n  
Figure 1 and g e n e r a t e  the compound flower m a r k e t ,  t h e n  t h e  r u l e  
i n t e r p r e t e r  must recognize t h a t  t h e  r e l a t i v e  c l a u s e  i n  Figure 1 
is an  i n s t a n c e  of t h a t  g i v e n  i n  F igure  2.  The matching procedure 
does  this by de te rmin ing  t h a t  t h e  reference se t  of the nomina l  
flowers is a subset of the r e f e r e n c e  set  of the nominal goods. 
I n  a d d i t i o n ,  t h e  nominal flowers must  be c a r r i e d  across t o  
the o t h e r  side of the  rule and substituted there for goods before 
t h e  other s i d e  of t h e  r u l e  is cop ied .  Thus  market and goods must 
be bound across the r u l e  s o  t h a t  whatever  l e x i c a l  i t e m  matches 
either of t h e s e  nominals becomes t h e  v a l u e  a s s o c i a t e d  w i t h  these 
nominals on t h e  o t h e r  s i d e  o f  t h e  r u l e .  
I n  t h e  i n i t i a l  v e r s i o n  of t h e  model, t h i s  b ind ing  was 
e s t a b l i s h e d  e x p l i c i t l y  when t h e  r u l e  was e n t e r e d  i n t o  the l e x i c o n ,  
bu t  t h i s  seemed u n s a t i s f a c t o r i l y  ad hoc. I n  a  subsequent v e r s i o n ,  
-- 
t h e  i d e n t i t y  of t h e  l e x i c a l  i t e m s  on bo th  s i d e s  of t h e  r u l e  was 
t h e  relation used t o  e s t a b l i s h  b ind ing  r e l a t i o n s h i p s .  Consider ,  
however, t h e  s t r u c t u r e  shown i n  F:Lgure 3. 
person I RELCL 
s t e a l  [+char ] 
PERF/ \ OBJ 
person  v a l u a b l e s  
F igure  3 
t h i e f  
Here person  should be bound t o  t h i e f  but  t h e  p rev ious  technique 
is not  a b l e  t o  e s t a b l i s h  t h i s  b ind ing .  The reason t h a t  w e  know 
t h a t  person  and t h i e f  should  be bound is because w e  know t h a t  a 
t h i e f  is a  person who s t e a l s  c h a r a c t e r i s t i c a l l y .  I n  t h e  most 
r e c e n t  v e r s i o n  pf t h e  model, t h i s  in format ion  is used t o  f i n d  t h e  
b ind ing  r e l a t i o n s h i p s  when t h e  r u l e  of i d e n t i t y  doe$ not  work. 
The l e x i c o n  is searched  for  a  r u l e  which can be used t o  e s t a b l i s h  
t h i s  b ind iag .  The r u l e  which is used i n  t h e  example shown i n  
F igure  3 is d i sp layed  below i n  Figure 4. 
person I RELCL t h i e f  
s t e a l  [+char  ] I PERF 
person 
Figure  4 
From the s t r u c t u r e s  g iven i n  F igure  4 ,  one c a n  see t h a t  person 
shduld  be bound t o  t h i e f  because t h e  r u l e  s t a t e s  t h a t  t h e  r e f e r e n c e  
se t  o f  t h i e f  is t h e  same as  the r e f e r e n c e  set of  person a s  
r e s t r i c t e d  by t h e  r e l a t i v e  c l a u s e .  
The technique o f  u s i n g  l e x i c a l  r u l e s  t o  e s t a b l i s h  b ind ings  
works i n  v i r t u a l l y  e v e r y  i n s t a n c e ,  but  it has t h e  d e f e c t  of  
r e q u i r i n g  t h a t  t h e  informat ion t h a t  a t h i e f  is a person who s t e a l s  
t h i n g s  be represen ted  i n  t h e  l ex icon  twice a t  l e a s t .  A new model 
is under c o n s t r u c t i o n  which a t t empts  t o  reduce t h i s  redundancy 
by a l lowing  t h e  r u l e s  t o  have m u l t i p l e  l e f t  and r i g h t  p a r t s .  
The problem of s e l e c t i n g  a p p r ~ p r i a t e  r u l e s  is r a t h e r  e a s i e r  
t o  so lve .  I n  most compounds i n  Engl i sh ,  there is a c h a r a c t e r i s t i c  
association between t h e  r i g h t  element of the nominal compound and 
t h e  main verb of the as soc i a t ed  r e l a t i v e  c l a u s e  paraphrase .  These 
two elements which occur on  opposite sides of the compounding r u l e  
supply a g r e a t  d e a l  o f  in format ion  about t h e  p o s s i b i l i t i e s  f o r  
a p p l i c a t i o n  of t h e  ru le .  So, i n  t h e  model ,  each ru le  i n  t h e  
l ex i con  is indexed by t h e  main verb  of  the r e l a t i v e  c l a u s e  and 
by the r i gh t  element of t he  nominal compaund. T h i s  index actually 
con ta in s  some environmental informat ion as  w e l l ;  for t h e  c l a u s e  
verb ,  t h i s  environmental informat ion is t h e  ca se  frame of t h e  ve rb  
and the f a c t  that  it is the main verb of the r e l a t i v e  c l ause  -- 
for t h e  compound nominal, t h e  environmental in format ion  is j u s t  
the fact that the nominal is t h e  r ightmost  one i n  a nominal 
compound. 
The basic model has been tested w i t h  a se t  of  s e v e r a l  
hundred nominal compounds and is very s u c c e s s f u l  i n  coping w i t h  
a wide v q r i e t y  of compound types .  The p r o d u c t i v i t y  of t h e  rules 
varies g r e a t l y ;  some rules  may produce hundreds of compounds w h i l e  
other rules may on ly  result i n  one or two compounds. Frozen forms 
such a s  k e e l  boat are handled by a rule which gene ra t e s  only  
one compound; there is a r u l e  for each f rozen  form. The r u l e  
s t r u c t u r e s  c o n t a i n  exc lus ion  lists a s s o c i a t e d  w i t h  each lexical 
i t e m  i n  the rule, and these exclusion lists prevent  t h e  r u l e  from 
ope ra t i ng  whenever a l e x i c a l  i t e m  matches one Of t h e  items on an 
exc lhs ion  list i f  t he  i t e m s  occur a t  corresponding l o c a t i o n s  i n  
the s t r u c t u r e s .  
The model is quite quick i n  o p e r a t i o n ;  on a h igh  speed 
dibplay  conso le ,  i t  w i l l  generally produce compounds much faster, 
than a person s i t t i n g  a t  t h e  console  can conven ien t ly  read them. 
v i ~  is mainly due t o  t h e  r u l e  s e l e c t i o n  h e u r i s t i c ,  b u t  t h e  match 
procedure has been c a r e f u l l y  optimized as  w e l l .  
Conclusions 
The model program is an  e x c e l l e n t  demonstrat ion of t h e  
appropr ia teness  of  t h e  b a s i c  t heo ry ;  moreover, t h e  r u l e s  
themselves can be genera l i zed  t o  d e a l  wi th  s y n t a c t i c  p rocesses ,  
s o  there is no d i s c o n t i n u i t y  i n  t h e  grammar model between t h e  
lexical  processes  and t h e  s y n t a c t i c  processes .  I t  seems clear 
t h a t  t h e  r u l e s  could a l s o  be used t o  r ep re sen t  o t h e r  l e x i c a l  
processes  i n  language and t h i s  is c u r r e n t l y  being pursugd. 
There is no reason why t h e  r u l e s  could not  be used f o r  
r ecogn i t i on  as well a s  for t h e  product ion of  nominal compounds. 
The bindings  a r e  not  one-way, and t h e  matching procedure w i l l  
work e q u a l l y  well for compound s t r u c t u r e s .  The reasons  why t h e  
computer model is a product ion model a r e :  (1) tha t  t h e  computer 
model assumes t h e  semantic c o r r e c t n e s s  of t h e  inpu t  r e l a t i v e  
c l a u s e  s t r u c t u r e s ,  and (2) t h a t  compounds a r e  o f t e n  ambiguous 
and may be paraphrased by two o r  more r e l a t i v e  c l ause s ,  w h i l e  t h e  
converse of this is almost never t r u e .  A recogn i t ion  model would 
have t o  genera te  under lying r e l a t i v e  c l ause  s t r u c t u r e s  f o r  each 
ambiguity and a semantic component would have t o ~ s c r e e n  t h e  
r e l a t i v e  c l a u s e s  f o r  semantic e r r o r s .  
I hope t h a t  the reader  has not iced  t h e  avoidance of r u l e  
procedures i n  t h i s  model. When I began working on t h e  design of 
t h e  computer programs, I had i n  mind t h e  c r e a t i o n  of a model which 
once implemented i n  LISP could be extended merely by adding new 
~ u l e s  wi thout  having t o  cons t ruc t  any a d d i t i o n a l  LISP programs. 
I u l t i m a t e l y  wanted t o  have a model which could l l l ea rn t l  new r u l e s  
by systematic g e n e r a l i z a t i o n  and r e s t r i c t i o n  of existing r u l e s .  
I feel t h a t  t h i s  would be r e l a t i v e l y  easy  w i t h  r u l e  s t r u c t u r e s  and 
extremely d i f f i c u l t  w i t h  r u l e  procedures w r i t t e n  i n  a programming 
language. Furthermore, I subsc r ibe  t o  Karl  Popper 's  icfeas of 
s c i e n t i f i c  endeavour, and r u l e  s t r u c t u r e s  appealed because i t  
would be more difficult t o  bury f laws or ill understood a s p e c t s  
of compounding and r u l e  processes  i n  s t r u c t u r e s  than  i n  procedures 
where t h e  computat ional  power of  t h e  programming language permits  
and even encourages -- ad hoc s o l u t i o n s  t o  be found t o  problems. 
Acknowledgements 
I would like to here acknowledge t h e  suggestions made by 
Robert F. Simmons, Carlota Smith,  Mary Boss T. Rhyne, U u r e n t  
S i k l o s s y ,  and Stanley Peters which have helped tsprbve my 
understanding of nominal compounding. 
1. Chomsky, N. "Remarks on Naninalizatlon, '' i n  Readings - in 
EngXish Transformational G-r, Jacobs, R. and Rosenbaum, 
P. eds. Ginn, Waltham, Xassachusetts, 1970. 
2 .  Gruber, J. vvStudies in Lexical Eklat ions. " Ph. D . thesis, 
HIT, 1965. 
3, Lees, R, - The Grammar - of English NosninalTzations, Mouton, 
The Rague, 1968. 
4. Rhyne, J. "Lexical Rules and Structures in a Computer %lode1 
of Nominal Compounding in English." Ph. D. t h e s i s ,  The 
University of Texas at Austin, 1975. 
5 ,  Simmons, R. "Semantic N e t w o r k s  : Their Camputat ion and U s e  
for Understanding E n g l i s h  Sentences,  '' i n  Computer Models - of 
Thought and Language, Schank, R. and Colby,  K. eds. W. H. 
-
Freeman, San Francisco, 1973. 
American Journal of Computational Linguistics Microfiche 33 : 45 
Computer Science Depar tment  
I n d i a n a  U n i v e r s i t y  
Bloon l ing ton  4 7 4 0 1  
ABSTRACT 
Generation of English s u r f a c e  s t r i n g s  from a semant ic  network 
is viewed a s  t h e  c r e a t i o n  o f  a l i n e a r  surface s t r i n g  t h a t  d e s c r i b e s  
a node of  t h e  semant ic  network. The form o f  t h e  s u r f a c e  s t r i n g  i s  
c o n t r o l l e d  by a r e c u r s i v e  augmented t r a n s i t i o n  network grammar, 
which i s  capab le  of examining t h e  form and c o n t e n t  o f  t h e  semant ic  
network connected  to t h e  semant ic  node b e i n g  d e s c r i b e d .  A s i n g l e  
node o f  the grammar network may r e s u l t  i n  d i f f e r e n t  forms o f  sur- 
f a c e  strings depending on t h e  semant ic  node i t  i s  g i v e n ,  and a 
single semantic node may be d e s c r i b e d  by d i f f e r e n t  s u r f a c e  s t r i n g s  
depending on t h e  grammar node i t  is g iven  t o .  S i n c e  g e n e r a t i o n  
from a semantPc network r a t h e r  t h a n  from d i sconnec t ed  p h r a s e  markers , ,  
t h e  s u r f a c e  s t r i n g  may be g e n e r a t e d  d i r e c t l y ,  l e f t  t o  r i g h t .  
I n t r o d u c t i o n  
I n  t h i s  p a p e r ,  w e  d i s c u s s  t h e  approach b e i n g  taken i n  t h e  E n g l l s h  
g e n e r a t i o n  subsystem of  a n a t u r a l  language understanding system 
presently under  development a t  I n d i a n a  U n i v e r s i t y .  The co re  of  
t h e  unde r s t ande r  i s  a semant ic  network p r o c e s s i n g  sys tem,  SNePS 
(Shapi ro ,  1975), which i s  a descendant  of t h e  MENTAL semant io  sub- 
system (Shap i ro ,  1971a, 1971b) o f  the M I N D  sys tem (Kay, 1973). 
The r o l e  of t h e  g e n e r a t o r  13 t o  describe, i n  E n g l i s h ,  any oP t h e  
nodes i n  the sernantjc network, a l l  o f  which r e p r e s e n t  concepts o f  
the understanding aystem. 
4 6  
and other computations are ~ e q u i r e d  in the process of pasting these 
t r e e s  t o g  the r  i n  a p p r o p r i a t e  places u n t i l  a ' s i n g l e  phrase marker 
I s  a t t a i n e d  which  w i l l  l e a d  t o  t h e  s u r f a c e  string. S i n c e  we are 
g e n e r a t i n g  from a semant ic  network, aL1 the  p a s t i n g  t o g e t h e r  i s  
a l r e a d y  done. Grabbing the n e t w o r k  by the node of i n t e r e s t  and 
l e t t i n g  the network dangl-e from it  gives a s t r u c t u r e  m i c h  may be 
searched apppogr i a t e ly  i n  o r d e r  t o  g e n e r a t e  t h e  s u r f a c e  s t r f n g  
directly i n  l e f t  t o  r i g h t  f a s h i o n .  
Our system b e a r s  a s u p e r f i c i a l  r e s e m b l a n c e  t o  that d e s c r i b e d  
fn Simmons and Slocum, 1972 and i n  Simmons, 1973. T h a t  sys tem,  
h o w e v e r ,  s t o r e s  s u r f a c e  i n fo rma t ion  such  as t e n s e  and vo ice  i n  its 
semant ic  rietwork and its ATN t a k e s  as i n p u t  a l i n e a r  list con ta in -  
ing the semantic node and a generation p a t t e r n  consisting o f  a 
" s e r i e s  of c o n s t r a i n t s  on t h e  moclalltyfl (Simmons e t  a l . ,  1973, p .  9 2  
The g e n e r a t o r  d.escribed i n  Schank e t  a l . ,  1973, t r a n s l a t e s  from 
a "conceptua l  s t r u c t u r e f 1  i n t o  a network of  t h e  form o f  Simmons ' 
network w h i c h  is t hen  g iven  t o  a v e r s i o n  of  Simmons g e n e r a t i o n  
program. The two s t a g e s  use d i f f e r e n t  mechanisms. Our system 
amounts t o  a u n i f i c a t i o  of  these two s t a g e s .  
The g e n e r a t o r ,  as d e s c r i b e d  i n  this page r ,  as w e l l  as SNePS, 
a parser and an in fe rence  mechanism have been written i n  LISP 1 . 6  
and are runn ing  I n t e r a c t i v e l y  on a DEC system-10 on t h e  I n d i a n a  
University Computing Network. 
Representation i n  t h e  Semantic_Network 
Conceptual in fo rmat ion  derived from parsed sen t ences  o r  deduced 
from other in fo rmat ion  ( o r  i n p u t  d i r e c t l y  v i a  t h e  SNePS user's l an -  
guage) i s  stored i n  a semant ic  network. The nodes i n  the network 
represent concepts  which may be d i s c u s s e d  and reasoned abaat. The 
edges represent semantic b u t  non-conceptual  b i n a r x  relations 
between nodes. There are a l s o  a u x i l i a r y  nodes which SNePS can 
use or which the user can use as SNePS v a r i a b l e s .  (For a more 
complete diecussion of SNePS and the network n e e  Z h a p i r o ,  1975.) 
The semantic network representation be ing  used does no t  i n -  47 
olude information considered .t.6 be f e a t u r e s  of' t h e  s u r f a c e  s t r i n g  
such as t e n s e ,  vo ice  o r  main v s .  r e l a t i v e  c l a u s e .  I h s t e a d  of t e n s e ,  
temporal  in fo rmat ion  i s  s t o r e d  P e I a t i v e  t o  a growing t i m e  l i n e  
i n  a manner s i m i l a r  t o  tha t  of Bruce,  1 9 7 2 .  From t h i s  informat ion  
a t e n s e  can be gene ra t ed  f o r  an ou tpu t  s e n t e n c e ,  bu t  i t  may be a 
d i f f e r e n t  t e n s e  t h a n  that of t h e  o r i g i n a l  i n p u t  sen tence  i f  t ime 
has progressed  i r i  %he 5nter im.  The vo ice  o f  a genera ted  sen tence  
i s  u s u a l l y  determined by t h e  top l e v e l  c a l l  t o  the gene ra to r  func- 
t i o n .  However, sometimes i t  i s  determined by t h e  g e n e r a t o r  gram- 
m a r .  For  example, when g e n e r a t i n g  a r e l a t i v e  c l a u s e ,  vo ice  i s  
determined by whether t h e  nodn be ing  m o d i f i e d - i s  t h e  agen t  o r  ob- 
ject of t h e  a c t i o n  de sc r ibed  by the r e l a t i v e  clause. The Main 
c l a w e  of a gene ra t ed  sentence  depends on which semant ic  node i s  
g iven  t o  t h e  g e n e r a t o r  in t h e  t o p  l e v e l  c a l l .  Other  nodes con- 
nec t ed  t o  it may r e s u l t  i n  r e l a t i v e  c l ause s  be ing  genera ted .  These 
r o l e s  may be r e v e r s e d  i n  o t h e r  t o p  l e v e l  c a l l s  t o  t h e  g e n e r a t o r .  
The g e n e r a t o r  i s  d r i v e n  by  two s e t s  of data: t h e  semant ic  ne t -  
work and a grammar i n  t h e  form of a r e c u r s i v e  augmented t r a n s i t i o n  
network (ATN) similar t o  tha t  of  Woods, 1973. The edges on 
our  ATN a r e  somewhat d i f f e r e n t  from those  of Woods s i n c e  our  view 
i s  that  t h e  g e n e r a t o r  i s  a t r a n d u c e r  from a network i n t o  a l i n e a r  
s t r i n g ,  whereas a p a r s e r  I s  a  t r a n s d u c e r  f r o m  a l i n e a r  string i n t o  
a t r e e  o r  network. The changes t h i s  e n t a i l s  a r e  d i s cus sed  below. 
During any p o i n t  i n  gene ra t i on ,  t h e  gene ra to r  i s  working on some 
p a r t i c u l a r  semant ic  node. Funct ions  on t h e  edges of t h e  ATN can 
examine the network connecteb t o  t h i s  node and fail o r  succeed 
accord ing ly .  I n  t h i s  way, nodes of  t h e  ATN can "decide" what sur- 
face form i s  most a p p r o p r i a t e  f o r  d e s c r i b i n g  a semantic node, while 
d i f f e r e n t  ATN nodes may gene ra t e  different surface foI?ms t o  des- 
cribe the  same semantic node. 
A common assumption among l i n g u i s t s  i s  that gene ra t i on  beg in3  
w i t h  a set of disconnected  deep phrase markers. T r n n u f  o ~ - m a t l o n ~  
LEX 
Fizure 1: Semantic Network RepresentatLon for "Charlie believes 
that a dog kissed sweet young Lucy," "Charlie i s  a person," and 
"Lucy i s  a person. 
,.Af=rmation considered t o  be features o f  surface strings are n o t  
stored in the semantic network, but a r e  used by the p a r s e r  in con- 
s t r u c t i n g  the network rrom t h e  i n p u t  sen tence  and by t h e  g e n e r a t o r  
f o r  generating a s u r f a c e  s t r i n g  from t h e  network. For example,  
tense i s  mapped into and from temporal  r e l a t i o n s  between a node 
r e p r e s e n t i n g  that some a c t i o n  has, is, or will occur and a growing 
t i m e  l i n e .  Restrictive relative clauses are used by the  parser  
to Identify a node being d i scussed ,  while n o n - r e s t r i c t i v e  r e l a t i v e  
clauses may result i n  new i n f o r m a t i o n  b e i n g  added t o  t he  network. 
The example used i n  t h i s  paper  i s  designed t o  i l l u s t r a t e  t h e  
generation issues being discussed. Although i t  also i l l u s t r a t e s  
our general approach t o  representational issues, some details w i l l  
*(SNEG MOOLb) 
(CHARLIE IS BELIEVING THAT A DOG KISSED SWEET YOUNG L U C Y ) ,  
* (SNEG M0023) 
( A  DOG KISSED SWEET YOUNG LUCY) 
*(SNEG M0007) 
(CHARLIE WHO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY) 
"(SNEG i4OOd;j 
(CHARLIE IS A PERSON WXO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY) 
* (SNEG M0006) ( C H R R L I E ~ W H O  IS BELIEVING THAT A DOG KISSED SWEET YOUNG L U C Y  I S  A PERSON) 
(SNEG M0008) 
(THE BELJEVING THAT A DOG KISSED SWEET YOUNG LUCY BY CHARLIE) 
* (SNEG M0011) 
(A DOG WHICH KISSED SWEET YOUNG LUCY) 
*(SNEG ~ 0 O l O j  
(THAT WHICH KISSED SWEET YOYNG LUCY IS A DOG) 
* (SNEG M0012) 
(THE KISSING OF SWEET Y O U N G  LUCY BY k DOG) 
@(SNEG M0020) 
(SWEET YOUNG LUCY WHO WAS KISSED BY A D O G )  
*(SNEG M0014) 
(LUCY IS A SWEET YOUNG PERSON WHO NAS KISSED BY A DOG) 
*(SWG M0015) 
(SWEET YOUNG LUCY HH3 WAS KISSED BY A DOG IS A PERSON) 
*(SNEG M0017) 
(SWEET LUCY WHO WAS KLSSED BY A DOG IS YOUNG) 
*(SNEG M0019) 
(YOUNG LUCY WHO WAS KISSED BY A DOG IS SWEET) 
F i g u r e  2 :  R e s u l t s  of  calls t o  t h e  g e n e r a t o r  with nodes f rom 
Figure  I* User i n p u t  i s  on l i n e s  beginning with *. 
c e r t a i n l y  change as work p r o g r e s s e s .  F i g u r e  1 shows t h e  semant ic  
network r e p r e s e n t a t i o n  for the i n f o r m a t i o n  i n  the sefitencesb, "Charlie 
b e l i e v e s  that a dog k i s s e d  sweet young Lucy,"  " C h a r l i e  is a person ,"  
and "Lucy i s  a p e r s o n . "  Converse edges a r e  n o t  shown, b u t  
i n  a l l  cases t h e  label of  a converse  edge i s  t h e  l a b e l  o f  the  fo r -  
ward edge with ' * '  appended exoept  f o r  BEFORE, whose converse  edge 
is l a b e l l e d  AFTER. LEX p o i n t e r s  p o i n t  t o  nodes c o n t a i n i n g  ; lexica l  
e n t r i e s .  STIME p o i n t s  t o  the s t a r t i n g  t ime of  an  a c t i o n  and ETIME 
t o  i t s  ending  time. Nodes r e p r e s e n t i n g  i n s t a n t s  of t ime a r e  re- 
l a t e d  t o  each o t h e r  by t h e  BEFORE/AFTER e d g e s .  The auxiliary node 
NOW has a :VAL p o i n t e r  to t h e  c u r r e n t  i n s t a n t  of  t i m e .  
F i g u r e  2 shows t h e  g e n e r a t o r ' s  o u t p u t  f o r  many o f  t h e  nadcs  o f  
F igure  1. Figure 3 shows t he  Lcxicon uncd i n  the example .  
(BELIEVE((CTGY.V)(I~BELIEVE) 
(PRES.BELIEVES)(PAST.BELIEVED)(PASTP.BELIEVED)(PRESP.BELIE~JING))) 
(CHARLIE ( (CTGY . NPR) (PI . CHARLIE) 1') 
(DO~'((CTQY.N)(SING.DOG)(PLUR.DOGS))) 
(K~SS((CTGY .v) CINF.KISS) 
~PRES.KISSES)~PP.ST.KISSED~~PASTP.KISSED)(PRESP.KISSING~~) 
(LUCY-((CTGY.NPR)(PI.LUCY))) 
(PERSON((CTGY.N!(sING.PERSON)(PLUR.PEOPLE)~~ 
(SWEET(~CTGY.ADJ)(PI.SUEET) 1 )  
(YO~NG((CTGY.ADJ)(PI.YOUNG))) 
Figure 3: The l ex icon  used i n  the example of Figures 1 and 2. 
Generation as P a r s i n g  
Normal p a ~ s i n g  involves t a k i n g  i n p u t  from a linear s t r i n g  and 
producing a tree o r  network structure as o u t p u t .  Viewing this 
in terns of an ATN grammar as described i n  Woods, 1973, t he r e  i s  a 
well-defined next  input f u n c t i o n  which simply p laces  success ive  
word6 into t h e * *  r e g i s t e r .  The outpu t  f u n c t i o n ,  however, i s  more 
complicated, uslng BUILDQ t o  build pieces  of  t r e e s ,  o r ,  as i n  our  
parser, a BUILD function t o  build p i e c e s  of  network. 
If we now consider g e n e r a t i n g  i n  these terms,  we see  that  t h e r e  
i s  no simple next  i n p u t  f u n c t i o n .  The g e n e r a t o r  will focus on 
some semantic  node f o r  a whi le ,  recurs ive ly  s h i f t i n g  its a t t e n t i o n  
to adjacent nodes and back. Since  there are several  ad jacen t  nodes,  
connected by variously l a b e l l e d  edges ,  the  grammar a u t h o r  must 
specify which edge t o  fo l low when t he  gene ra to r  i s  to move t o  ano the r  
semantic node. For t h e s e  reasons ,  t h e  same focal semantic node 
is used when traversing edges of the grammar network and a new se- 
mantic node is- specified by gl,ving a p a t h  from t h e  c u r r e n t  semantic  
node when pushing t o  a new grammar node. The reg i s t e r  SNODE is 
u s e d t o  hold the current semantic node. 
The output func t ion  of gene ra t ion  i s  s t r a i g h t f o r w a r d ,  s i m p l y  
being concatenation onto  a growing s t r i n g .  Since t h e  ou tpu t  s t r i n g  
is analogous t o  the parser's Inpu t  s t r i n g ,  w e  store i t  in the reg- 
garc : := (TEST test [action]* (TO gnode) ) 
(JUMP [action]*(TO gnode)) (mM wform (wqrd*) test [action]*(TO gnode))  
(NOTMEM wform (word#) test [ a c t i o n ] * ( T ~  gnode)) 
(TRANSR ([regname] regname regname) test [ac t ion]*  (TO gnode) ) 
(GEN gnode sform [action]*regnarne [action]*(TO gnode))  
sform ::= w f o r m  
SNODE 
wform : := (CONCAT f ~ ~ m  form*) 
(GETF sarc [aform]) 
( GETR re gname ) 
(LEXLOOK l f  e a t  [ sf orm] ) 
sexp 
form -: := w f o r m  
sform 
ac t  ion : := (SETR regname f o m  
(ADDTO regname form* ) 
(ADDON regname f o m *  ) 
sexp 
test : :  (MEMS form form) 
(PAT23 sform sarc* sform) 
form 
sexp 
gnode : := <any LISP atom which r e p r e s e n t s  a grammar node> 
word : := <any LISP atom> 
regname ::= <any non-numeric LISP atom used as a r e g i s t e r  name> 
sarc ::= <any LISP atom used as a semantic a r c  label> 
l f ea t  : := <any LISP atom used as a l e x i c a l  feature> 
sexp : := <any LISP s-expression> 
Figure 4: Syntax of  edged of gene ra to r  ATN grammars 
i s t e r  *. When a pop occurs ,  i t  i s  always t h e  cu r r en t  va lue  of * 
tha t  is r e t u ~ n e d .  
Figure 4 shows the syntax  of t h e  gene ra to r  ATN grammar. Object 
language symbols  are ) , (, and elements i n  c a p i t a l  l e t t e r s .  Meta- 
language symbols are i n  lower case ,  Square brackets  e n c l o s e  op- 
t i o n a l  elements. Elements followed by * may be repeated one o r  more 
t j m e s .  Angle b r a c k e t s  enc lose  informal  Eng l i sh  d e s c r ~ p t i o n s .  
Semantics of Eage Functions 
In this section, the semantics of t h e  grammar arcs, forms and 
t e s t s  ape preaehted and compared to those of Woods1 ATNs.? The 
--- 
t A l l  comparlsona arc with Woodo, 1973. 
NCL ') 
JUMP(SETR * @(/ / / /  NO GRAMMAR NODE F O U N D ) )  M E N D  ) 
Figure 5 :  The default en t ry  i n t o  the grammar n e t w o ~ k .  
essential differences are those required by the differences between 
generating and parsfng as discussed in the previous s e c t i o n .  
(TEST t e s t  [action]*(TO gnode)) 
If the test i s  successful ( e v a l u a t e s  t o  non-NIL), t h e  a c t i o n s  
are performed and gene ra t i on  con t inues  at gnode. I f  t h e  test 
f a i l s ,  this edge i s  not  t aken .  TEST- is the same as WoodsT TST, 
w h i l e  TEST(GETF s a r c )  i s  analogous t o  Woods' CAT.  
(JUMP  action]*(^^ gnode)) 
Equivalent to (TEST T [actlon]*(TO gnode)). JUMP is simllar 
In use to Woods JUMP, b u t  the d i f f e r e n c e  from TEST T disappears 
s ince  no edge r'consumesl' any th ing .  
(MEM wform (word*) tes t  [action]* (TO gnode) ) 
If the value of wform has a non-null  intersection w i t h  t h e  
list of words, the test is performed. If t h e  test is also success- 
f u l  the actions are performed and gene ra t i on  continues a t  gnode. 
if either the Intersection is null or the t e s t  f a i l s ,  the edge 
MEM(GETR VC)(PASS)T G-EN NCLNP(~ETF OBJECT) 
(ADDTO DONE SNODEI* 
( SREG PRED) 
OEN NCLNP(GETF AGENT)(ADDTO DONE SNODE)* 
Figure 6: Generation of subject of sub ject-verb-ob ject sentence. 
is not taken. This is similar in form to Woods1 MEM, but mainly  
used for testing r e g i s t e r s .  
(NOTMEM wform (word*) test [action]*(TO gnode)) 
This is e x a c t l y  l i k e  MEM except the intersection must be n u l l .  
(TRANSR ([regnamel] regname2 regname3) t e s t  [ac t ion]*  gnode) ) 
If regnamel i s  present, the  contents  o f  regname2 are added 
on the end of regnamelo If regname is empty, t he  edge is not  3 
taken. Otherwise, t h e  f i rs t  element i n  regname is removed and 3 
placed in regname2 arid the  t e s t  i s  performed. If the  t e s t  f a i l s ,  
the edge is not  taken, b u t  if i t  succeeds, the ac t ions  are performed 
and generat ion continues at gnode. TRANSR i s  used t o  iterate th rough  
several nodes all in t h e  same semantic r e l a t i o n  w i t h  the  main se- 
mant ic  node. 
(GEN gnodel s form [action]*regname [ac t ion]*(TO gnode*)) 
The f i r s t  s e t  of a c t i o n s  are performed and t h e  generation i s  
c a l l e d  recursively with the semantic node that is the value  of sform 
and a t  the  grammar node gnodel. If this genera t ion  is successful 
( r e t u rn s  non-NIL), the result i s  placed i n  the  r e g i s t e r  regname, 
the  second se t  of  a c t i o n s  are performed and g e n e r a t i o n  con t inues  
at gnode*. If the generation fails, the edge i s  not t aken .  This 
I s  the same as Woods1 PUSH but requires a semantic node t o  be npeci- 
f i e d  and allows any register to be used t o  hold t h e  result. In- 
stead o f  having a POP edge, a r e t u r n  automatically occurs when 
(ADDON * @WILL @HAVE) 
(ADDON * QWQULD) 
UI@(ADDON * @(/ / /CANNOT COMPUTE TENSE)) 
TEST( MENS (GETR REF) ( *  @NOW) ) (ADDON PIS') \ a  
MEM(GETR VC) (PASS)T(ADDON * @BEEN) CVPF 
MEM(GETR VC)(PASS)T(ADDON * @BE) ( tp~ JUMP 
@FAST~ J U M P ( A D D 0 N  * (LExLOOK PASTP(GETF VERB))) 
JuMP(ADDON * (LEXLOOK INF(GETF V E R B ) ) )  CTIINF ) - 
Figure 7: Tense genera t ion  network. 
transfer is made to the node END. At tha t  point, the con ten t s  o f  
the register named * are r e tu rned .  
(CONCAT form form*) 
The forms are evaluated and concatenated i n  the order given.  
Performs a r o l e  analogous to tha t  of Woodst BUILDQ. 
(GETF sarc [sform]) 
Returns a list of a l l  semantic nodes at the end of the seman- 
t i c  arcs label led sarc from the  aemantic node whl ch i s  t h e  value 
Figure 8: The tenses of "breakn which t h e  network o f  F igure  7 
can generate. 
of  sfomn. If sform i s  missing, SNODE is assumed. Returns N I L  if 
I 
t h e r e  a r e  no such semant ic  nodes. It is similar in the semantic 
Tense 
past 
f u t i l ~ e  
present prog~essive 
pas t  progressive 
future progr6ssive 
past In future 
future fq p a s t  
Active Passive 
domain t o  Woods' GETF i n  t h e  l e x i c a l  domatn. 
broke 
will break 
is break-lng 
was breaking 
w i l l  be break ing '  
w i l l  have broken 
would break 
(GETR regname) 
Returns the contents of  register regname. It i s  essentially 
the same as Woodst GETR. 
was broken 
w i l l  be broken 
i s  being broken 
was being broken 
will be being broken 
w i l l  have been broken 
, wquld be broken . 
(LEXLOOK l f e a t  [sform]) 
Returns the value of  the lexical feature, l f e a t ,  of the l e x i c a l  
en t ry  associated w i t h  the semantic node which i s  t h e  value of sform. 
If sform is missing, SNODE i s  assumed. If no lexical entry i s  asso- 
c i a t e d  with t h e  semantic node, NIL i s  r e tu rned .  LEXLOOK i s  sirnilar 
to Woods1 GETR and as a l s o  i n  the l e x i c a l  domain. 
(SETR regnarne form) 
The va lue  of form is placed in the r e g i s t e r  regname. It is 
the same as Woods1 SETR. 
(ADDTO Pegname form*) 
Equivalent  t o  (SETR regname (CONCAT (GETR regname) form*)). 
Equivalent to (SETR regname (CONCAT form* (GETR regname))). 
(MEW f o r m  form) 
Returns T If t h e  values of the t w o  forms have a non-null intersec- 
tion, NIL otherwise. 
TEST( GETF OBJECT 
~ P R E D O B J )  
UMP 
cpmDAm GEN KLNP (GETF AGENT) REG (ADDON * (GETR 'REG) ) 
CpRGDOB3 GEN NCLNP (GETF OBJECT) REG (ADDON * (GETR REG ) ) I 
Figure 9: Generating the s u r f a c e  o b j e c t .  
(PATH s f o m l  sarc* sformp) 
Returns T i f  a p a t h  descr3bedl By t h e  sequence o f  semantic  a r c s  
exists between t h e  value of  sfoml and sformp. If %he sequence 
i s  sarcl s a r c 2  ... sarc,, the p a t h  desc r ibed  i s  t h e  same as t h a t  
i n d i c a t e d  by sarc l*  sarc2* ... sarcni. If no such p a t h  exists, 
NIL i s  r e tu rned .  (Remember, * means r epea t  one o r  more t imes .  ) 
Discussion o f  an Example Orammar Network, 
The top level genera tor  f u n c t i o n ,  SNEG, Ls given as arguments 
a semantic node and, o p t i o n a l l y ,  a grammar node. If t h e  grammar 
node is  not g iven ,  gene ra t i on  begins a t  t h e  node G 1  which should 
be a small d iscc i rn ina t ion  n e t  t o  choose t h e  p r e f e r r e d  d e s c r i p t i o n  
for t h e  given semantic  node, Th i s  p a r t  of the  example grammar is 
shown i n  Figure 5. Jn it w e  see that  t h e  preferred d e s c r i p t i o n  
f o r  any semantic  node i s  a sen tence .  If no sentence  can b e  formed 
a noun phrase w i l l  be t r i ed .  Those a r e  t h e  only p r e s e n t l y  avail- 
able options. 
Semadtic nodes wi th  an  outgoing VERB edge can be desc r ibed  by 
a normal SUBJECT-VERB-OBJECT sen tence .  (For  this example, we 
have n o t  used a d d i t i o n a l  c a s e s . )  F i r s t  t h e  s u b j e c t  i s  genera ted ,  
Figure  1 0 :  Generating t h e  t h r e e  "non-regular" s e n t e n c e s .  
which depends on whether t h e  sen tence  i s  t o  b e  i n  a c t i v e  o r  p a s s i v e  
voice.  A l t e r n a t i v e l y ,  t h e  choice  could be expressed  i n  terms of  
whether t h e  agent  o r  o b j e c t  is t o  be t h e  t o p i c  as sugges ted  by Kay, 
1975. Figure 6 shows Lhe network that generates t he  s u b j e c t .  The 
r e g i s t e r  DONE h a l d s  semant ic  noaes f o r  which sen tences  are being  
g e n e r a t e d  for l a t e r  checking too prevent i n f i n i t e  r e c u r s i o n .  WPthout 
i t ,  node MOO23 of  F i g u r e  I would be desc r ibed  as,  "A dog which k i s s e d  
young sweet Lucy who was k i s s e d  b y  a dog which  k i s s e d .  . ."  
The i n i t l a 1  pa r t  of t h e  PRED network i s  concerned with generat-  
ing t h e  tense. This  depends on t h e  BEFORE/AFTER pa th  between t h e  
s t a r t i n g  and/or endinb time of the  a c t i o n  and t h e  c u r r e n t  va lue  of  
NOW, w h i c h , i s  given by t h e  form ( #  @ N O W ) .  Figure 7 shows t h e  t e n s e  
g e n e r a t i o n  network. Figure 8 shows t h e  t e n s e s  t h i s  network i s  a b l e  
t o  generate. 
A f t e r  the verb group is generated,  the surface o b j e c t  is gener- 
a t e d  by desc r ib ing  e i t h e r  t h e  s e m m t i c  agent  o r  object. Figure  9 
skuws this part of t he  network 
The o t h e r  th ree  kinds of s e n t e n c e s  a r e  lor descr ib ing  nodes 
r e p r e s e n t i n g :  (1) t h a t  something has  a p a r t i c u l a r  adjective a t t r i b u -  
able t o  it, ( 2 )  that something has a name, ( 3 )  that something i s  a 
member of some c l a s s .  The networks  f o r  t h e s e  a r e  shpwn i n  F igure  
10 .  Again, t h e  DONE r e g i s t e r  i s  used t o  prevent  such sen tences  as 
"Sweet young Lucy I s  sweet," "Charlie i s  Charlie." and "A dog is a dog." 
GEN 3 (GETF OBJECT(GETF VERB*))REG(ADDON * @THAT(GETR R E G ) )  
cICL>GEN SREG SNODE *(ADDTO * @THAT) 
Figure 11: Generating norninalized verbs and sentences. 
Pugure 5 showed three b a s i c  kinds of noun phrases t h a t  can be 
generated: the noun clause or nominalized sentence, such as " t h a t  
a d o f ~  kissed sweet young Lucyt'; the nominalized verb, such as "the 
kisslng of sweet young Lucy by a dogn; the r egu l a r  noun phrase. 
The first two of these are generated by the network shown in Figure 
11. Bere DONE is ased t o  prevent, f o r  example, " t h e  kissing of  sweet 
young Lucy who was kiesed by a dog by a dog." 
The regular noun phrase network begins w l t h  another descrimina- 
t i o n  net which has the following p r i o r i t i e s :  use a name of the o b j e c t ;  
use a class the obJect belongs to; use something e l se  known about 
*he obJect. A lower prior i ty  description will be used if all h i g h e r  
priority descriptions are a lready  in DONE. Figure 12 shows the be- 
glnnlrrg of the noun phrase network. Adject ives  are added before t h e  
mame or before tkre  class name and a relative clause is added after. 
GEN ADJS SNODE *(ADDTO * @A) 
Cm&uMp (sETR * B A )  N E M ~  
(LEXLOOK SING(GETE CLASS(GETF MEMBER*))))  
Figure 12: The beginning of the noun phrase network. 
F igure  13 shows the a d j e c t i v e  s t r i n g  genera to r  and Figure  1 4  shows 
t h e  r e l a t i v e  c lause  g e n e r a t o r .  Notice the  use o f  t h e  TRANSR edges 
f o r  i t e r a t i n g .  A t  t h i s  time, we have no theory  f o r  determining t h e  
number o r  which adjec t ives  and r e l a t i v e  c l auses  t o  generate ,  s o  
a rb i t ra r i ly  we generate a l l  a d j e c t i v e s  not  a l r e a d y  on DONE but only  
one relative c lause .  We have n o t  y e t  implemented any o rde r ing  of  
adjectives.  It i s  merely f o r t u i t o u s  t h a t  "sweet young Lucyt is 
eenerated rather than "young sweet Lucyft. The network i s  w r i t t e n  
so  t h a t  a r e l a t i v e  clause f o r  which t h e  noun i s  t h e  deep agent  is 
preferred over one i n  which t h e  noun i s  the  deep o b j e c t .  Notice 
that  t h i s  choice determines t h e  voice  of t h e  embedded clause.  The 
fomn (STRIP(FIND MEMBER (1. SNODE) CLASS (FIND LEX P E R S O N ) ) )  is a 
call t o  a SNePS f u n c t i o n  t h a t  determines  i f  t he  o b j e c t  i s  known t o  
be a person, i n  ~ h i c h  case  "WHO" i s  used r a t h e r  than "'WHICHft.  This 
determination i s  made by r e f e r r i n g  t o  t h e  semant ic  network r a t h e r  
than  by i nc lud ing  a HUMAN f e a t u r e  on t h e  l e x i c a l  e n t r i e s  f o r  LUCY 
and CHARLIE.  
nDJs7JUMP(SETR ADJS(GETF W E I C H * ) )  
Figure 13,: The network f o r  g e n e r a t i n g  a s t r i n g  o f  a d j e c t i v e s .  
Notice that any in format ion  abou t  t he  object being described 
by a noun phrase may be used to construct a relatfve clause even 
i f  that Lnfomnation derived from some main clause. Also,  while 
the gene ra to r  i s  examining a semantic node all t h e  in format ion  about 
that node i s  reachable from it  and may be used d i r e c t l y .  There 
i s  no need t o  examine disjoint deep phrase markers t o  d i scove r  where 
they can be attached t o  each o t h e r  s o  that a complex sentence can be 
derived. 
Future Work 
Additional work needs ts be done in developing t h e  s t y l e  of 
gene ra t ion  desc r ibed  i n  this paper.  Experience with larger and 
richer networks will lead to the fo l lowing  i s s u e s :  d e s c r i b i n g  a node 
by a pronoun when that node has been described e a r l i e r  i n  the string; 
regu la t ing  verbosi ty  and complexity, p o s s i b l y  by the use  of resource 
bound8 simulating the limitations of s h o r t  term memory* keeping sub- 
, 
ordinate clauses and descriptions to t h e  point of t h e  conversa t ion  
p o s s l b l y  by the use of a TO-DO register holding thenodes  t h a t  are 
t o  be included in the  string. 
In thla paper, only i n d e f i n i t e  descriptions were genera ted .  We 
are working on a routine that  w l l l  I d e n t i f y  the proper  subnet o f  t h e  
semantic network t o  j u s t i f y  a d e f i n i t e  descr ip t ion .  This  must be  
such that it uniquely i d e n t i f l e e  t h e  node being d e s c r i b e d .  
(SETR VC @ A C T )  
JUMP 
\JUMP F JUMP 
TEST(STRI? !*I!JD :.lEMEEFl(f SI\l; DE)CLASS (YT?ID E X  PERSON) ) ) 
Figure 14: The r e l a t i v e  clause generator .  
Acknowledgements 
The a u t h o r  i s  indebted t o  John  Lowrance, who lfiplemnted t h e  
generator, Stan Kwasny, who implemented the p a r s e r ,  Bob Bechtel, 
who worked b u t  t h e  t empora l  r e p r e s e n t a t i o n ,  Nich V i t u l l i  and N i c k  
Eastridge, who implemented versions of SNePS, and Jim McKew for 
general software ? u p p o r t .  Computer service was prov ided  by t h e  
I U P U I  Computing F a c i l i t i e s .  T y p i n g  and graphics were d ~ n s  by 
Christopher Charles. 
Bruce, B.C. 2 9 7 2 ,  A model  f o r  temporal references and its a p p l i -  
ca t ion  in a question answering program, A r t i f i c i a l  Intelli- 
gence 3 ,  1, 1-25. 
Ray,  M. 1973. The MIND system. N a t u r a l  hanguage, Probesstng, R e  
Rustin (EB. ) , AlgorithmScs Press, Mew Ysrk,  155-188. ' 
Kay, M. 1975. Syntactic processing and functional sen tence  p e r -  
s p e c t i v e .  Theoretical Issues in N a t u r a l  Language Processfng 
R, Sch& and B,L, maah-Webber ( E d s , ) ,  B o l t  Beranek,& Newman, 
fnc . ,  Ombrfdge, Massachusetts. 
Schan~ ,  R.C.; @oldman, ; Rteger, C , 111; and Riesbeck,  C .  1973. 
NARGlE: memory, analysis ,  responae generat ion,  and inference 
on English, Proc, Third xntematf onal, J o i n t  Conference on A r t i .  
f i c i q l ,  ,Intelligence, Stan fo rd  University, August 20-23, 255-26T. 
Shapiro, S,C.  1971a. The W I N 3  system: a data s t r u c t u r e  f o r  seman- 
tic Infornation processlrig. R-837-PR. The Rand Corp . , S a n t a  
Monica, Cal%forn la .  
Shapirs. S.C. l g r l b .  A n e t  structure f o r  semantic i n f o r m a t i o n  
- storage, deduetlon and retrieval.  2nd International J o i n t -  Con- - .- 
Shapiro, S. C. 1975 * bAn 2 ntroduction t o  SNePS . Technical Report 
No. 31, CumpuLer Science Department, Ind iana  U n i v e r s i t y ,  Bloom- 
f ngt on, 
SS@@ons, R,F.  1973, Semantic networks: their cornputatSon and use 
for understanding English sentences.  computer Models of Thohght 
R.C* Schank and K.M. Colby (Eds.), W.B. Freeman 
Francisco, 63-113. 
Sirnone, R.B., and Slocurn, 3 .  1972. Generating English discourse 
from rralnantic net6 + Corn,. ACM 15, 10, 891-905. 
Woods, W.A+ 1973. A n  exgerlmental parsing system for transition 
ne %work gramars . , R .  Rustin ( E d . ) ,  
Algsrf t m i o a  Press, 
American Journal of Computational Linguistics ~ ic ro f i che  33 : 63 
Artificial Intelligence Center 
Stanford Research Institute 
Men10 Park, California 94025 
ABSTRACT 
8atur.l languag8 output  can b* generatrd fram remantic nets 
by ptoc*rsing ternplats8 asroeiated with concept# in the n e t r  A 
# q t  a t  verb teaplater i s  belng derived from a Study of t h e  
surfrc9 syntax o f  ran@ 3000 Englirh Verb88 fhe actlve forms of 
the  verb$ have been t Z ~ r r i f l s d  rtcorb&n$ t o  subjectr objeetCm1~ 
and compl~aent(r1) there Syntactic Patterns, augmented with  case 
nams,  ara used as a grammat t o  Cantrol th4 generation O t  t e x t ,  
Thlr text in turn i s  pasrad through a speech syntheri8 program 
and output by 4 VOTRAX speech rynth4o&zax, ThLr analyrar rhould 
ultimately benefit systems a t t s a p t l n g  t o  understand E r l ~ l i ~ h  i n p u t  
by praviding surface etructurs  t o  deep  c u l  i t rue turd  maps using 
the rare trmpirter r r  emp1Qytd by the generator. 
T h f r  reararch w4r rupportrd by t h e  Detenra Advaneed Reuearch 
Proleeta Agancy a f  th* Dcprrtmmnt @t D ~ f e n r e  and manit6rrd by the 
U, 8 .  &rmY Rs#~rrch Offica under Cantract No, DAHC04~75-C-0006. 
TNTRQDUCTXON 
It computer6 r t r  t o  canmonicrtr e f t r e t l v c l y  with p e o p l e ,  
they nust spark, or a t  irart  w r i t e ,  the  urcr*r  nrtur61 Language, 
The b u l k  o t  the work in co~pytatlonrl Llnguilticr has been 
drvot rd  t o  computer undcrstandlnq o f  n a t u t a l  language i n p u t #  b u t  
r e l a t i v e l y  l i t t i e  rtfo<rt  ha8 been e%pend@d in d e v e l o p i n $  natural 
Language output .  M o r t  Enplirh output systems hrve  been along t h e  
l i n e  of  n f i l l  In the  blanku with Perhap& soma semantic 
cenrtrrint6 imporad!  thera have bean few attempts a t  language 
generation from what one could crLl wsamrntic netR structures  
[8g@aon8 and 8locua, 1972; Sloeuar 1973; Goldman, 19741 ,  
PeFh&p@ generation i s  canr ldered  a much aas i s r  problem,  The 
ruccrrr o f  understanding ef forts  i r  generally bclisvtd to drprnd 
on rome warkrble theory o f  Rdlrcaurrr 6rganlzatlonc which would 
rccbunt gar affect8 of  context and would ahow how i n i p h o r i c  
~ ~ p r e n 8 l ~ n s  (pronoun# and noun phrases) are resolved and how 
#rnt*nCeS r r o  order84 t n  the  b U t P U t r  A s  t t  hrppdnot there 
m@chanlr@r are p r ~ L # * l Y  those t h a t  r wrr8ponre g ~ n e r r t o r ~  must 
Incorporate i t  i t  1 s  t o  appear Lntrlligent. Tha lrtudy o f  
qrnrtrtion r i l l  p l a y  an important r o t s  in r o l v i n g  t h e  problem of 
undrrttandino i f  i t  ern draonrtrrte & mapping t ~ o m  derp ramantic 
rtrUctura6 t o  ru t face  r t r t n g r ,  
bet  ua b r i e f l y  outlina gome relevant preccrrrs in the #peach 
understanding system bring d r Y c L 0 ~ 1 d  by 8RI and SDC (Walker a t  
a1.t 1 9 1 5 ~  and Rite., 1915). The urar inltlatrs rrrrton by 
r r t r b l i r h t n g  conmunLc~tion with the ryrtrmf a l l  subarqurnt d i a l o g  
( i n p u t  and o u t p u t )  is manlter@d by a Wdircaurae m a d u l a 8  (Dautacb,  
11975) to maintain rn accurate ca~ntrerskition41 context ,  An 
e x e e u t t v c  eserdinata# v a r i a u r  Knarladge sauxcos 4 c W r t i ~ r  
p r o s o d i c ,  syntactic, r~mrntie, pzagmrtlc, and d i ~ e e u r r c  t o  
Bunderotrnbw c u c c e r s i v t  utt@rane@rr 
The analyzed UttaFlnge i Q  then Pas8rB l a  ZRa "resPandarw PBItll 
another eamponrnt o f  the dileaurtc module. The responder may 
c a l l  the pucrtlonransrcrrr i t  t h e  lnput i r  a ques t ion !  i t  may 
c a l l  4 data  bead u p d a t e  Program I t  ths i n p u t  i s  r otatcmant o f  
fact1 or i t  may d r c l d r  an romc other  rppropriatc r e p l y .  Tha 
content ab t h e  r@DpDnD@ I s  prrora  to t h e  gsnaratar~ perhapa # i $ h  
Some tndicrtian of hsa i t  is t o  be tarmulat@ds TRa r e p l y  may bs 
a rtsrcatypsd rsrpsnss ( w y @ 8 B p  "noM, "1 @e@C)I noun p h r a r s  
(nodel, r o@nt+nes ( v e r b  node ) r  O r r  e ~ ~ n t u 1 1 1 y ~  a paragraph, 
The q e n ~ P a Q ~ r  o u t p u t s  stettotyped raspanreg Pmmed$atslyt if! 
the  rcrpanrr i r  nor@ complicated [ a  "nounB nab@, * v e r b R  nads, ar 
rvcnturlly r nrtwork) ,  r mbrr detallcd proptam i r  ragulrcd. T h i s  
program nbLl dctrrmina exactly how the responge i s  t s  bs 
bormulrtad m a  &g NBI 61 OH teqUIRCQ 8 f  St! i t  may bb ~ d ~ ~ l r 6 d  
t o  Chooag Verb@ and noun@ with which t o  @ X g s @ @ @  t h e  d e e p  C l S c  nae 
c tructurrr ,  r r  wall r8 a ryntaetlc from. f o r  the genaration. The 
g~narator P ~ O ~ U C I I  tha rrrponrr in wfrxtw form1 t h i r  in turn i r  
p & g s a d  t o  a B ~ O I C ~  tynthrllr program t a r  trrnrtarmatlon and  
cutput  by r comn@rCial VOTRAX r p r a c h  rynthe~izar. C u r r ~ n t l y  no 
IsntQner intenstion sr r t r ~ a s  con%sWing i~ being p @ r t ~ r m e d ,  
8tnea t h e  major Bntmsost a t  this papsr  i t  in " t e x t H  ganaratlane 
fur ther  reference t o  t h e  synfhcrlg r t r p  r i l l  be m e d e n  
CQNSTRAXNTS Or? RESPONDING 
There a r e  several  censLdcr8tianr i n v o l v e d  in responding 
appropriateby t o  an utterance. First, t h e r c  are  *conver:ctlanal 
P o ~ t U l & t e # "  (Gordon and  Lakoff, 1 9 7 5 1  8 h a r s d  b y  t h e  u6ers a ?  e 
Lanuurprt there  p o t t u 2 a t e r  serve  t o  canstrain t h e  c o n t e n t  and 
form o f  c a ~ ~ u n i c a t i o n r  from the  speaker t o  the heerare For 
instance,  t h e  rperker  should not t a l l  t h e  hearer  r e ~ s t h i n g  the 
hearer all@&dy knows, l c r t  he  be  bore61 y e t  t h e  speaker cannot 
t e l l  t h e  h c a r e r  samething the  h e a r e r  knows a b ~ o l u t e l y  nathlnq 
about, or t h e  hearer r l l l  n o t  comprehend. The ggenkee c h o u l d  
r e l a t e  k n t  ncwa in h i s  marsaga to t h e  p r t o r  knowledgs o f  t h e  
hearer;  t h i s  requires t h e  r p e r k c r  t e  have ti model of! the  h a a r c f  
There heuristic6 mur t  operate in canjunctbon w ~ t h  c w ~ ~ c ~ ~ n c ~  
producerw t o  constrain what may be o u t p u t  by  a q ~ e n t c n c e n  
generatore We are  only beg inn ing  t o  understanG h o w  to 
lncorparrtt  there  partuiater in a languagc g r o c e 6 ~ b n g  k y g t c m ,  
Then t h e r e  Is the  matter o f  con8tructlng the b a t i c  sentence  
Normal English ryntax r c q u i r r r  a t  l t a a t  ant v e r b  In t h e  s a n t c n c a f  
choor ing  a mrln verb  constrains the r u r f d c t  Rt ruc tu r e ,  For 
inltrncer in thr  rblcncr of campounds any v e r b s  o t h e r  than t h e  
main v w b  will have t o  appear  i n  another Fornr nominal, 
i n f i n i t i v e ,  gerundr p ~ r t L c I p L @ ~  or subordinate C f a u c e ,  How d a e c  
t h e  relevant fnfarmatlon centaintd In & gementic n e t  Indicate t h a  
rpproprlate farm? The traditlondl answer Is "by meann of t h t  
l a x i C 0 n r U  We w i l l  Q X p l o r Q  t h e  relationship be tween  net @ r ~ d  
lexicon and rdvsnce a methodology f a r  raprelcntlng a map tram 
deep  case structura t a  surface s tructure ,  
Thlr prgrr ~ O C U L I I  an a philosophy o t  sLnglam6cnfencr 
farmattinqr cmeaaing a main vatbr choosing t n a  grass  structure s t  
t h e  o u t p u t  scntencer and deciding how t o  generate spgropriata 
noun p h r a r a s ,  Qur exarnpl~a will anB1oY limPlifia4 semantic n e t  
rtrueturrr,  remcrhat like t h o s e  in t h e  actual  5RI ~ a a r t i t i a n a d  
BlarntP~ neta 8ystam lHandrlxr 19751,  MMes In t h e  net may 
raprerant phylicrl objects, rcllttonshipr, evantr, s b t r ,  r u l a s ,  
a r  uttsrencesr a0 in the  Qxempla balaw, Directad lab@Pled areg 
conncct nsdaa and rsprasant c e r t a i n  w p r i m i % i r a n  tlmc-invariant 
r a l a t  t s n r h t p a ,  
In t h e  n @ t  L r r q m ~ n t  above, t h e  U.8. an4 t h r  U , K .  r r a  elcmrntl ( a )  
of t h e  g a t  o f  C Q M W ~ ~ ~ @ @ ,  as  EXP@tisnt@rr t hey  b a e h  participate 
in OWNLng rlfurtionl lnvolvlnp as OBJlctr p a r t i c u l a r  rubmariner) 
reeh rubmarlnt 11 an rlcmsnt o f  same c l a s s  o t  subm&r1ntsr rnd 
t e ~ p l a f e s  f a t  Engllah rtntcner8, Bc c h o a ~ e  a simple verb f o r  
dernmstrrtfin a= OWN, W a  not@ t h a t  our v e r b  h $ @ v & t & 1  
VynanymrRr WAVE, POSSESS, and BELONG C10L S l m c  c l f h  of thcsc  
verb8 (including OWN1 ha8 other  Ssnsr meanings, re  D a r l t  a node  
tense they have in Comment this node w i l l  be &ha m ~ r o t o t y p Z c r l E  
OWHI in t h s t  It w112 incarpareta the u m s r n i n ~ R  of the altuatlsn 
and Ln that all inaerncrs a f  owning rituatians will b4 r e r a t ~ d  P Q  
POSSESSt HIVEI BELONG] and trmplatrr, Wsts that  one t e m p l a t e  
r i l l  hat  r u f f t e a  Ear a l l  dour verbs;  For inatanesr the subject 0 %  
t h e  subject i r  t h e  FXPeriencQsr 
EXP own& OBJ 1 0BJ i s  owned by EXP 
EXP p o r o a s s ~ a  OBJ OBJ 1s  Pabl@lldd by EXB 
EXP h r r  aBJ OBJ Gdronv t o  EXP 
tOWK (EXP V&ct OBJ) (OBJ Vprr B Y  EXD] )  
[PO3SES8 (EX$ Yact OBJ) (063 Ypar B Y  EXPI] 
fHAVE (EXP Vact OBJ)] IBEbON6 (084 Vact  TO EXP)] 
New# i n  Order t b  rpcilc about  a p a r t i c u l a r  Owning s l t u a t b o n r  nt 
t % d W r  BELONG) and an a g ~ o e 1 a t e d  template (OBJ VaeE TO EXPI, and 
But we have 4 problem! t h e r e  i s  no indication o f  how tho EXP 
and OBd Qrgumcntt &re t o  be generated, NP will not always 
r o f t i c r r  note for  inrtanec t h a t  t h e  predicate argument o f  
in %?shn hapad to go homen must ba an Infinltlva PhP48e (rather  
than the QetUfid p h r r e e  t h a t  NP might producal, Even a cursory 
8tUdY o f  a few hundred verbs in t h @  language shawl that they have 
very defintts Cand regular1 C o n s t t a i n t &  on the syntactic form 0 %  
tnrrr canststucntr, Thaas cons tra int8  appear ts bc matters % o r  
the lexicon rr thar  than the grammar, we assoc ia te  
net) rather than imwemsnt them v i a  QP4MmBF TUI~II and wg 
cxpllcltly incorporate t h s  conrtltutnt t y p e s  in t h e  tamplatcst 
COWM ((NP EXP) V a ~ t  (NP OBJ)) (CNP OBJ) Ypar BY (NP EXP))I 
(POSSES6 ((NP EXP) Vact (NP OBJ)) ((NP OBJ) Vpe8 BY (NP EXP))] 
[HAVE ((HP EXPI Vact (NP OBJ))] 
[BELONG ((NP OBJ] Yaet TO (NP EXP))I 
A a c t  of  patterns  liLe t h t r a  i s  a s s o c i a t e d  * I t h  r v s r y  
" P I O ~ ~ Y P .  verbn nods in the knswZ~dg@ b r a @ *  $t would seam that 
m l l  r a  need i s  an P n t n r g s e b r  t k a b  g i v ~ n  any w ~ e ~ b  instanceR 
node fn the  knowb@dg@ b ~ g e r  l 0 b k o  up t h e  psttbrns P Q T  t h a t  t y p e  
of! n o d h  C ~ O Q G Q ~  Q V Q t b r  1 eOrraapdnding tsmglate for  the v e r b @  
and then Proeaedr t s  * e v r l u a t a n  fha p a t t e r n o  
v e r b  [ O W N ,  S - 3 8 , D W N I  sms b Q l ~ n $  
tamp [(MP OBJ) Vact TQ (NP EXpll 
(NP Odd) 913 t h e  S ~ a w o L f  
Y I C ~  -13 Bclonqs 
T O  --3 t o  
(NP G X P )  t h e  u,s, 
B u t  us t t l i l  r u n  i n t o  trouble  with o u r  r i m p l c  cchema, 
Consldsr the  rent@ncc, *John burned the taarf b l a c k , "  
\ ACT \ ~ B J  colorl 
By uging t h e  simple p a t t e r n  U N P  AGT) Vact (HP OBJI) we could 
e a s i l y  generate the *Lncorrrctw sentence, rJahn burned t h e  b l a c k  
tmr;trW since (NP QBJ) might include the color o f  t h e  t e 8 l t t 8  Me 
need a pattern more llke ((NP AG,T) Vact [NP O W )  (nod  R ~ S I I I  Zn 
which t h e  RESult of t h e  a c t i o n  wflk bc directly r e l a t e d  t o  t h e  
verb. Ha*rvcrr t h l r  1% n o t  q u i t e  enough a= rt l a a r t ,  n o t  Wtthout 
a very c0mpfic.tad Lntcrpretcr -* because the in terpre ter  must 
RnoW t h a t  (NF OBJ) cannot i n e l u d e  h a  v r a b P s  RE8 ergurnawl 
[ b l a c k ) .  Thus# by convention, nay indicate an e x t r a  argument 
t o  bs Passed t o  r eon6tttuant q a n s r d o r  (such as the Ounetisn NP) 
t e  denote the item(@) not t e  appear in the resultant canrtiturnta 
( I N P  ACT) Vact (HP OBJ RES) (Nod RES)) 
*he pattern (NP OBJ RES) mrrnr Vgrnaratr an NP using t h e  OBJsct  
of t h e  VQrbr but do n ~ t  ine lude  t h a  RESult of ths v e r b  in the 
p a t t a r n o  ( L e e r  a pattern  copy far  every p o r r / b l r  *mmlrrLngfl 
constituent), This level  o f  detail w o u l d  be unrdasonable i d  f @ w  
other verbs cou ld  we t h i s  template; however, there are  rnt?t@ khan 
rstrtlvaly few tern~lrtarr baCh s h w ~ d  by several tang BB hundred@ 
o f  verbs ,  t h e  urt of templates proves t o  ba q u i t *  hefpfull 
There? rrr other roureqr o t  potantla1 pat tern  p r o l t f a r a t i ~ n ~  
an impattant one being t h e  cambindtorial arrangamants o f  CQea 
arguments o f  t ime,  manner, and athar  such ~ B ~ W b i ~ l l r  &it well aa 
other ( p o t 8 i b l Y  non*advrrbiall ease arguments such as sourer,  
$041, inttrumrnt, etc .  Some a t  $ha@@ a r g u m a ~ t d  are rath@r 
censtralnsd I n  t h e i r  paaitiona in t h e  rantencar but others  may 
"esterday t h e  s h i p  satled f rom t h e  lighthouse to t h e  d o c k , "  
"The # h i p  s a i l r d  from ths lighthau8a t o  t h e  dock yesterday." 
wYast@rday t h e  s h i p  r a i l e d  t o  the  dock from t h e  l l g h t h o u r ~ . ~  
g t  i s  a f  cauara unrsrranabl@ t a  try t o  maintain a l l  the ~ a s 8 i b X e  
pr f t r rnr !  Lnefcad r s  leave Lnrsrtlon o f  fhrte  rdvcrb ia f  rrguncntr 
t o  r ring11 heuristic routine ( d c r e r i b c d  below), There are 
rrvcral jurtitlcations for t h j l ,  amanp them8 t i )  the particular 
farm 09 the verb cannot be grneobatsd until t h e  subject bbject(a5) 
@ r ~ r t @ L  p o s s i b l e  P L & C I ~ ~  and ( 3 1  t h e t a  r t a  some heuristic 
one may question whether passive tenplatao ahou ld  be atore41  
c@tt@inlyr they c o u l d  be d e r i v e d r  On t h e  other  hand, neglecting 
t~ rtare thorn woWd farce ur t o  Ind%bat@ wAth each Verb (84n03)~ 
whether Lt can (or,  ronrtimar, m u s t )  be p a r r i v i z c d ,  I n d i c a t i n g  
" t r . n ~ l t l v @ V i r  naf enough since there are tranritlvc vrrbr 
( i . a , ,  vcrbr t h a t  taka an object) t h a t  cannot bc p s s s l v i z a d .  
8incs we hava t o  r t o r a  t h e  information anywayp we Can r a v e  dame 
cads and Coaput$np t i a r  by storing thr  parslvr ternplat@. 
There arr rtvsrrl rraronr f o r  gcnrrafinq the verb  a f t e r  t h e  
mafor @rgumentr. F t r ~ t  t h e  lubjre t  auat be panerrfad ro t h a t  t h e  
verb can b r  mrdc t o  aprrr  in nuabnr. Second,  c e r t a i n  rare t r n r r r  
8tr true of  vrrb-prrticlr conblnitionc rkiir n o t  cL t h e  i c o l a t r d  
verb,  Btncr, in addition, prrticl@c must appear r f t t r  o b j e c t 8  
that  F Short  (like pranownrl b u t  b s f ~ r s  a b j a e t e  t h a t  are  long 
(like noun phraras), t h e  particle nurt b e  positionad a f t e r  t h e  
o b j e c t  j S  grncrrtcd. F f n a L 1 ~ 1  inocrtian a f  soma advarbirbr 
t r . ~ ,  annot" rrqulrrr an ruxllirry v e r b  I- thug  v e r b  grnaratlon 
aurt fotlor rdvrrbirl grncratlon, 
VERB PATTERNS 
T h i s  #tudy started with t h e  25 V e r b  pattcrnr" p r c r c n t c d  by 
Hornby (1954) .  T h e ~ e  Ln t u r n  crwr f r o m  a d l c t g o n a r y  by Hornby ct 
el., ( 1948 ) .  V c t M  in t h e  dict$onary &re cZ&irltird & c ~ o r d i n g  t a  
t h e i r  gross  syntactic p r t t r r n ~  a f  lubjrctp abjrct(s1, end 
c o m ~ ~ r a e n t C s ) ~  most o t  t h e  ~ a f t q r n r  r r a  rub-dlvgdade Thc rutkorr 
cl@La t h a t  there p a t f r r n r  WXXNnt f o r  a l l  conttruetlanr involving 
&I& t h e  verbs I n  theLr 4ietianary dndr by N t t n e f o n ,  In t h e  
IangUagr, I tl&SrifiertLon i s  not Zmmcdi&telY useful t o  
C ~ t h p U t d h t i ~ n a l  lingulrtr r l n c a  i t  doas not a d d r a g s  underlying 
~ e m a a t i c s ~  H a v a t k h e l e ~ ~ ~  i t  $r c l a r r  t h a t  i t  can ssrve ae t h s  
brrlr for  r &artvatIan o l  Und@rlYlng c a r r  r t r u c t u h a r  
prrtlculatly, &r a bar16 f o r  Vplnrrrtion tcngl&tro,* 
There pattern8 &re b@lng canvar tad  i n t a  t a m p l e t @ @  much llkt 
tho#* der ived arr l fe tr  t h a  tnrlyris i s  Baing perfarmed with 
ralD*Ct t 4  300b V6tb l  drawn f r ~ ~  the dtctionary ( S ~ O C U W ~  to 
appear) ,  There templatea s e r v e  ro t h o  major portion o f  a modular 
*gan@ratLon grammarr* with t h e  r@aarlnder in t h r  farm of  h s u t i a ; t i c  
tunctianr t o r  constructing syntactic constituentr, 
N O U N  PHRASES 
What t o  IncluBb Ln a noun phrase should be another mrttar 
f a r  the d i r c a u r t e  module t o  judge,  There are no w ~ 1 l ~ E a r m ~ l a C a d  
f u l r l  eccountlng far  anaphorl In EngliShj i n d e a d ,  there arc  trw 
wsflee8trbliehad parameters a t h e r  than t h a t  %ha hearer must  ba 
a b l e  t o  r ~ a a l v a  t h o  (pto)nouns t o  t h e i r  reforants, The &D@ak@a?p 
S h o u l d  tmploy anaphoxa In order to avo la  t@petitlonr b u t  o n l y  P t  
h i s  B0deX of! t h e  hearer i n d i c r t o ~  t h a t  t h e  ~ ~ Q P C P  can t d s o l v d  the 
ambiguity, Thcrc arc same lawcpowrr ptaneminalization ru l e r  t h a t  
could be directly incarp0ra t sd  in a generator rafg@x$v%zalPanr 
for  s ~ 1 1 p 1 0 .  N c V ~ P ~ ~ B ~ ~ S S ~  f t  IS i m p a s t a n t  L O  P ~ B Z I Z B  that When 
r generator i r  unaware of  t h e  eanvcrtafl~nal context, it l h a u l d  
not indepsndantLy decide haw to ganaratr noun phpa1481 I t  CQR 
only decide when t o  d6 r o e  This r b t u a t l o n  har not been 
univ+roalLy r@caqnf iedr  b u t  I t  1s becoming hnercarlngZY c l ea r  
t h r t  a Q Z ~ c s u r t e  m s d u h  must be canrubtsd during t h e  ~snarrtlan 
phrrs .  The direourre modal. will not know ahead of timr what NPI 
are %O be  p r ~ d u e @ d  u n ~ @ s g  $t p4rforrn\@ many o f  ths g e m @  ~ P o r a t i a n a  
t h a t  t h e  paneratar would do anyr4y. Y a t  the cantcxt-8cnritivo 
d e c i r i o n  s t r r t ~ g ~  may h.ve  t o  resorb ts rush m a a r u t b r  a r  
dlaewb$quating the proporrb o u t p u t  uoLwg khs model of &he hrsrer 
in order t a  d ~ t e r m b n r  what rnaphdra if4 teseavabla ,  t %  I r  
unr@rsanrble t s  ancarporrte t h l g  s t r r t ~ g y  in ths gancr a t s r ~  r i n c a  
for  rany rrrsonr i t  nurt be p a r t  o f  t h e  d l r c o u r r r  modulc, 
Therefate t h r  genrrrtor S h o u l d  p a 6 S  any R n c u n U c o n s t i t u c n t  
t o  t h @  dJscourre module ( p l r h s p t  r i t h  i t s  rrcommcndation a b o u t  
how to PIgdUce the c o n s t i t u e n t , ;  t h ~  n o d u l e  m u s t  d c t c r m i n r  i f  a 
pronoun or b&ga noun i t  ambiguour t o  t h e  h e a r e r ,  a n d ,  i f  s o ,  what 
to add to t h e  noun ln order to makt the d e s i r e d  r e f e r e n t  e l e a r ,  
Ln the current SRI system, noun  prt t crnr  [Slocum, t a  r p P c a r )  a r a  
U S I ~  t o  control noun phrase grnrrrtian, Much like verb patterns, 
noun prttcrnr order t h e  ~ o n ~ t l f u @ n t 8  in t h e  p h r a r r  and indicate 
how each eon8tLturnf Is t o  b e  generated by naming a functicn t o  
be Called with the nQtwerK ~anstftuentf 
((DET] [Ad3 QUA&) ( A d j  SIZE) ( A d j  SHRFE) (Ad1 COLOR) (N)] 
Batttrhr like t h i r  era  dirtributrd a b o u t  the network h i @ r @ r e h y j  
in t h e  f u t u r e @  t h @  Q L ~ c ~ u r r c  aadulc r i l l  dccLde t o r  each p q t t r r n  
constituent whather f t  i 8  to appear i n  t h e  p h r r c s ,  
MEURZSTXC RULES 
R ~ r n b y  d+rcrlb@r three b s r l c  porltlanr f a r  a d v c r b r  in the 
clrussr "rentff pa#b$tionp R ~ t d n  pssltlonr and @ a n d u  ~ e r i t l o n ~  
Front poritgen rdvrrbr occur b a t a r e  the s u b j r c t t  w V e r t a ~ d a y  h@ 
want hornat from these ha took  a t a x i , *  The i n t o r r o q l t i w a  r d v a r b r  
(a,g, now, when? rrr typically c o n s t r d k n ~ d  t o  front Pooitionl 
other8 miy r p p r r t  thrrr  t a t  p u r p o r r r  o f  rmpharla cr e a n t r a l t .  
M i d  p e r l e i o n  rdvarba  occur v i r h  t h e  v e r b  (atringlt Sf there 
ar* medal s r  ru#ilLrrv v a r h r s  t h e  dbvrrls occurs a f t o r  t h e  first 
one, Oth@twi8r the r d ~ ~ r b  w ~ L L  appear b t k ~ r @  t h e  Verbl  cxcapt 
fbr *un11tre8#aQ~ f h l t e ~  o f  bar  a n d  4 0 1  ' ~ 4  O ~ ~ Q R  $36 
thararl @oh@ if8 t y p i ~ l l l y  buw8] *he I t  1t11I waiting,@ 
End position adverbs occur r t trr  t h e  verb  and a f t e r  any 
d b t e e t  or indirect object pteacnt, While t a l a t i v ~ l y  fen clrurss 
have mare t h r h  one adVQrb in tront parttian or mara t h r n  sns In 
@ i d  porltianr i t  i r  common t a t  r r v c r r l  .dV@rbS to appear in and 
~ a r l t l o n  in t h a  rams c lausal  *thaV p l a y  t h e  P iana  PeerlY 
tagcthrrw, 
hdvarblrlr o f  time (rnrrrring t h e  4uartiont wrh@n?w) usually 
deeut  in and p o a l t i o n ,  but may appear In grsnt position f a r  
aaphrrtr or contrast. kdverbialr o f  frequency (anrwsrlng t k a  
quettbon, wRaw ~ f t a n ? ~ l  can be split i n Q  t w o  groups, The f i r s t  
group is comgo@@d ~f ringla-nerd adverbs t h a t  tyalcally seeui fn 
& i d  porition b u t  a I r o  may br  in i n d  patLtianj th@ sacand i r  
eosparsd a$ m u l t i p l s = w o r d  phrrrrr that  dgp&ar Pn end p a r i t i o n  e r ~  
&err Lrr9UrntlYr in t r e n t  Position. Adverbs of duration [ V l f ~ r l  
hew lonqtw) u d u ~ l l y  have end parltlan, wbth %song p6sBtPon fbr  
empha8fs or csntxartr Adverb8 o f  place and diraetlen narrnall~ 
hivQ and porition. Advcrbr o f  4 rgrca  and manner have mid or  and 
~ O S I ~ L Q R I  depbnding  on t h r  advarb ,  
Along W i t h  ruah  ruler c o n ~ ~ r n l n g  t h e  BarLtionr O L  Vsriout 
types  o f  advrrbr,  there  murt b r  a mcchanirm t o  0rd.f t h e  rdvcrbr 
t h a t  arr L a  s ~ c u r  In t h a  "maQn petitLon, Thrrr r r a  eome 
h @ u a l r t i c l ~  among rdverbi.11 o f  time Car p l a ~ 1 1  t h e  smallat unit 
81 ururlly pL4ccb t l r l t ,  unlrrl i t  t r  44604 48  &R sftarthauphtl 
@ t h e  army a t taeksd  thr village in farce  an a h o t  Augut t  
@ftrrnoon, j u s t  a t t a r  r i e r t a H ,  Adv@rbialr of p l a c a  end diroetton 
usually precede t h o r e  of frequency, which in t u r n  praeode t h o o ~  
a t  time, 
There ru le8  r e  iaplrmontsd  in th@ raRr r a u t L n ~  M a t  
produce@ t h e  verb1 when @ template i s  f i r a t  f n e a r p r c k e d  =- N W h  
eo B 8equencc of  function e r l l r  t h e  R V a ~ t w  or "Vpao kaya  arc 
lonored. once t h e  l U b j C C t ,  ~ b j C C t ( S 1  and compltmcnt(a) l n d i c r t r d  
by t h e  t cnplr tr  rrr Oanrrrfrdr t h i s  *clean upm routine $ 6  c a l l e d .  
Et employg the h a u x i t t i e k  d ~ r c r f b e d  abava La a d d  the adverb ia l  
C ~ r t & t f t U @ n t &  and VhFbr then concatsnatss the canstbtutnts t a  
produce r complete @IruseI 
DXSCUSSTON 
fn theory, t h e  s e t  o f  porsiblc EnpLlrh rantcncrs i a 
i n f  fnZtsr Tha obv laor  q u s a t l b n  man ~ t @ @ @ r  O l f  sne t r i e s  to 
account ror them with tarnp l i t rrr  won t t h e r e  bc an i n f i n i t e  
number eL t a a p l a t t ~ ? ~  The simple antxcr i r r  "Nor t o r  romc of the 
Sam@ r e l l ~ n l  that  allow a finite grammar t o  gcnrrata  an intlnite 
number of itr2ngr.R One can p r e d u c a  rantrncer o f  arbitrary Length 
by ( 1 )  ~ T ' b l t t ' a t ~  anb@ddlngr and ( 2 1  a r b i t r a r y  conjuncttan@ Caw@ 
B o t o  not do s o  by includdng a r b i t r a r y  n u m b e r s  sf distinct car@ 
erpuacntl. Evrn r a  t h e  numbcr o t  basic p a t t e r n s  c o u l d  be 
t n l ~ a m e l Y  I a f  gc , E v i d r n c a ,  horevrrr i l  t c  the con t r a ry !  t h e  
l V e n t U I I  nUnbqr o f  t@Bpl.t@# would appear t o  b r  r e v e r a l  time8 t h e  
number OI p l t t e r n r ~  awing to thr  SUbltitUtion o f  parttcular 
p r a ~ a r i t l o n e  Ear n p r ~ p w  In t h e  r ~ ~ t i c t l c   attaro or, and  t h a  
arrlgnaent o t  dltfetent c r l e  nancr t o  a p a r t i c u l a r  canstitusnt 
depending on t h e  p r r t i c u l a r  vrgb u r @ d .  
Dcotsch, Barbara G, Establishing Context in Task-Oriented 
b l a l d g ~ .  Prrrcnted a t  t h e  Thirteenth Annual Meeting o t  t h e  
Atsooiatian f a t  Computational Llngutrflcr, Barton, M a ~ r a c h u ~ d t t ~ ,  
S O  October * 1 Navarnber 1975,  
OoLdmrnr Neil H e  Computcr G ~ n e r a t i o n  o f  Natural L@nguaga 
tram a D I I ~  Conceptual I r r e .  A 1  Memo 2 4 7 ,  A r t i t i ~ i a l  
I n t e l l i g e n ~ ~  Laboratory, 8trnford Univcr8ityt Str rnf  ord, 
C q i f  o r n i b  1974, 
Gordon DIvidt and Lakaff, George. Convearettonal 
Portulater. Syntax snd Senanticst Volume 3 1  Speech  A c t s ,  Edited 
by Peter Cole and Jerry L. Morganr Acadrmia  P r s a ~ ,  New Ygrkr 
1975 rn 
H@ndtixt Gary G. Expanding thr Utility of  Bemantie Nafworkr 
f hrough Pact i t  toning, Advance Pav@r r of  t h e  Fourth Internationcl 
J o h t  Contcrrncs on Artificial Zntblllgenee, Tbiiiolr C s o r ~ i a ,  
U6SRl 3.8 Geptambcr 1975,  I I S a I Z l r  
Hornby, 8 t r  Gatrcby, Vetand W~lK@flb@Xdr H Q  The 
Advmced Laatnet@@ Dictionary of  C u r r a n t  Engllrh. Oxford P r @ r r ~  
London@ 1948,  
Rita.# H, Barry, Autoastic Speech Underrfandin~ SYrtamr. 
Proessdlngr, Eleventh Annual IEEE Camputst S a e l e t y  Contcranea, 
Harhlngton, D. C e r  9 - i  1 S ~ p t r m b e r  1975,  
Siamanrr Robtrt & I  and S ~ O C U ~ ~  Jonathan. Gaa@rartinq 
English Dlrcourcr from Senrntlc N I E W O ~ K C .  CommUnicstlonr ~t the 
ACH, 1 9 9 2 ,  1 s t  8911909n 
S J o c u l ,  Jonathan.  Quartion Anarrring v i a  Csnanlcrl Verb8 
and Bsrnrnt l c  Madcllat t C~nsra t ing  %ngllrh trow the W O ~ Q ~ ,  
Technical Report H t = i 3 t  Department a&  Csapartrr bcbtawcar r 
Univeoritp a t  T a ~ a r ~  Austin@ Ttx.8, January 1913.  
$locum, Jonathan, Verb Patterns and Noun Pat tarns  In 
E n g l i ~ h t  A Cl&r  Anrlyrir. A r t l f i ~ L a l  Lntrlliprncs Center, SRX4 
Man10 Parkt Californirr (in preparatlsn), 
American Journal of Computational Linguistic8 Microfiche 33 : 78 
Y a l e  U n i v e r s i t y  
New Haven, C o n n e c t i u c t  0 6 5 1 1  
ABSTRACT 
TALE-SPIN is s program which makes up stories by using planning 
structures as part of its world knowledge. Planning structures 
represent goals and the methods of achieving those goals. 
Requirements for  aparticular method depend on static and dynamic 
facts about the world. TALE-SPIN changes the state of the world 
by creating new characters and presenting obstacles to goals. 
The reader / listener makes certain p l o t  decisions during the 
telling of the story. The story is generated using the notation 
of Conceptual Dependency and is fed to another program which 
translates it into English. 
INTRODUCTION TALE-SPIN is a computer program which makes up 
stories about characters who plan how to solve certain problems 
This work was supported in part by the Adudnced Research 
Projects Agency of the Department of Defense and monitored by 
the Office of Naval Research under contract N00014-75-C-1111. 
and t h e n  carry o u t  their p l a n s .  The planning procedures i n t e r a c t  
with a d a t a  base of knowledge about other characters and o b j e c t s  
in the world,  memory, and t h e  personal  r e l a t i o n s h i p s  which e x i s t  
between characters. The stories are  r e p r e s e n t e d  i n  Conceptual 
Dependency and are  passed t o  a program which expresses them i n  
E n g l i s h .  The r e a d e r  is asked t o  make c e r t a i n  decisions about the 
story d u r i n g  t h e  process of generation. Here is an example. 
J O E  BEAR WAS FAMISHED, HE DECIDED HE WOULD BE FULL IF HE 
ATE SOME HONEY, HE WANTED TO F I N D  OUT WHERE THE HONEY WAS, 
HE THOUGHT TRAT IRVING BIRD WOULD TELL H I M  WHERE THE HONEY 
WAS. 
J O E  BEAR WALKED TO THE TREE WHERE I R V I N G  BIRD WAS. HE 
ASKED IRVING BIRD I F  HE WOULD TELL HIM WHERE T H E  HONEY WAS. 
>> DECIDE: DOES *IRVINGBIRD* AGREE? *NO 
IRVING B I R D  REFUSED TO TELL JOE BEAR WHERE T H E  HONEY WAS. 
J O E  BEAR DECIDED IRVING B I R D  WOULD LIKE HIM TO GIVE THE WORM 
TO HIM. J O E  BEAR A S K E D  I R V I N G  B I R D  I F  HE WOULD TELL HIM WHERE 
THE HONEY WAS IF HE GAVE THE WORM TO H I M .  
>>  DECIDE: DOES *IRVINGBIRD* AGREE? *YES 
HE THOUGHT THAT HE WOULD LIKE JOE BEAR TO GIVE I T  TO HIM,  
HE WANTED TO FIND OUT WHERE THE WORM WAS, HE THOUGHT THAT 
I R V I N G  B I R D  WOULD TELL HIM WHERE THE WORM WAS, J O E  BEAR A S K E D  
I R V I N G  BIRD I F  HE WOULD TELL HIM WHERE THE WORM WAS. 
>.> D E C I D E :  DOES *IRVINGBIRD* AGREE? *YES 
IRVING BIRD DECIDED HE WOULD TELL JOE BEAR WHERE T H E  WORM 
WAS- I R V I N G  B I R D  TOLD H I M  I T  WAS A T  A PATCH OF GROUND, 
HE WALKED TO THE PATCH OF GROUND WHERE WORM WAS, HE TOOK 
THE WORM HE WALKED TO THE TREE WHERE IRVING BIRD WAS. H E  
GAVE THE WORM TO I R V I N G  B I R D .  
> >  DECIDE: DOES * I R V I N G % I R D k  K E E P  H I S  PROMISE? *NO 
HE REFUSED TO TELL JOB BEAR WHERE -THE HONEY WAS. JOE 
BEAR TOLD IRVING B I R D  HE XS GOING TO STRIKE H I M  IF HE DOES NOT 
TELL HIM WHERE T H E  HONEY WAS. 
> >  D E C I D E :  DOE$ *IRVINGBIRD* IGNORE THE THREAT? *NO 
IRVING BIRD DECIDED HE WOULD TELL JOE BEAR WHERE THE 
HONEY WAS, I R V I N G  B I R D  TOLD HIM IT WAS AT THE BEEHIVE. 
80 
JOE BEAR THOUGHT THAT HENRY BEE WOULD GIVE THE HONEY TO 
W I M .  JOE BEAR WALKED TO THE BEEHIVE WHERE HENRY BEE WAS. HE 
ASKED HENRY BEE IF HE WOULD GIVE THE HOMEY TO HIM. 
>> DECIDE: DOES "HENRYBEE* AGREE? *YES 
HENRY BEE DECIDED HE WOULD GIVE I T  TO JOE BEAR. HENRY 
BEE GAVE IT TO JOE BEAR. BE ATE IT. HE WAS FULL. THE END. 
Here is a s t o r y  which TALE-SPIN generates which  t h e  
translator  is no t  y e t  capable of producing i n  ~ n g l i s h :  
JOE BEAR W4S HUNGRY. HE THOUGHT TEWJ! I R V I N G  BIRD WUQLD 
TELL HIM WHERE SOME HONEY WAS, HE WALKED TO TlWE TREE WHERE 
IRVING BIRD WAS. HE ASKED IRVING B I R D  TO TELL H I M  WHERE THE 
HONEY WAS. IRVING BIRD TOLD HIM THE HONEY WAS I N  A [ ce r t a in ]  
BEEHIVE 
JOE BEAR WALKED TO THE BEEHIVE WHERE THE HONEY WAS. HE 
ASKED HENRY BEE TQ GIVE HIM THE HONEY. HENRY BEE REFUSED. 
JOE BEAR TOLD HIM WHERE SOME FLOWERS WERE. HENRY BEE FLEW 
FROM THE BEEHIVE TO THE FLOWERBED WHERE THE- FLOWERS WERE. JOE 
BEAR ATE THE HONEY, 
HE WAS VERY TIRED. HE WALKED TO HIS CAVE. HE SLEPT. 
THE END. 
TALE-SPIN starts with a small s e t  of characters and var ious  
facts about them, I t  also  has a set of problem-solving 
procedures which generate t h e  events  i n  t h e  s t o r y .  Many 
decisions have to be made as the story is being t o l d .  Some are 
made at random (names of characters,  fo r  example) ; o t h e r s  deperld 
on the re la t ionships  between characters (whom one asks fo r  
information, fox example); others  are  made by the reader 
(whether a character keeps a promise, f o r  example) . 
TALE-SPIN generates  sentences using the representation 
system of Conceptual Dependency (Schank 1975). Some of the 
Conceptual Dependency (CD) s t r u c t u r e s  are passed on to a program 
which expresses them in E n g l i s h .  (The o r i g i n a l  v e r s i o n  of that 
program was writ ten  by Neil Goldman fo r  the MARGIE system. The 
present vers ion has been modified by Walter Stutzman and Gerald 
8 1 
D e  Jong .) The s e n t e n c e s  which a r e  not passed t o  t h e  t r a n s l a t o r  
a re  t h o s e  which r e p r e s e n t  e a s i l y  i n f e r r e d  i d e a s .  N e i t h e r  program 
y e t  worries  about  khe s t y l e  of e x p r e s s i o n ;  t h a t  is,  we worry  
about whether t o  say a newly g e n e r a t e d  piece of t h e  s t o r y ,  b u t  
n o t  much a b o u t  how t o  say it. 
A TALE-SPIN s t o r y  involves  a single main character who 
solves some problem. To make t h e  p r o c e s s  i n t e r e s t i n g ,  obstacles 
a re  i n t r o d u c e d ,  some by t h e  r e a d e r  i f  he c h o o s e s ,  and some a t  
random. For i n s t a n c e ,  t h e  r e a d e r ' s  d e c i s i o n  Chat I r v i n g  B i r d  is 
n o t  go ing  t o  t e l l  J o e  Bear what he wants t o  know p roduces  an  
obstacle t o  Joe  ear's p l a n  t o  f i n d  something o u t .  Some 
obstacles are c ~ a a t e d  when c e r t a i n  s c e n e s  a r e  included i n  the 
s t o r y .  For i n s t a n c e ,  t h e  i n i t i a l  world s t a t e  has no bees i n  it, 
but when it comes time i n  the s t o r y  t o  conjure up  some actual  
honey, w e  do so by c r e a t i n g  a whole s c e n e  which i n c l u d e s  some 
honey in a b e e h i v e  i n  a tree and a bee who owns t h a t  honey. The 
bee may o r  may n o t  be a t  home. I f  he  is, J o e  Bear is go ing  t o  
have another obstacle i n  h i s  p l a n  when he g e t s  t o  the beeh ive .  
The story is  t h e  n a r r a t i o n  of some of t h e  e v e n t s  which occur 
during the s o l u t i o n  (o r  n o n - s o l u t i o n )  of t h e  problem. ( T h a t  is, 
more things happen i n  t h e  s o l u t i o n  o f  a problem t h a n  a 
storyteller says or n e e d s  to  say.) TALE-SPIN d i f f e r s  from other 
problem-solving systems i n  several  ways : (1) the problems it 
solves a r e  t h o s e  r e q u i r i n g  i n t e r a c t i o n  w i t h  o t h e r ,  u n p r e d i c t a b l e  
c h a r a c t e r s  ra ther  t h a n  with a d a t a  base o f  theorems or b l o c k s  o r  
c i r c u i t s ;  ( 2 )  t h e  world  i n s i d e  TALE-SPIN grows: new c h a r a c t e r s  
are created with  u n p r e d i c t a b l e  e f fec t s  on t h e  story; ( 3 )  
obstacles are d e l i b e r a t e l y  introduced; ( 4 )  a n   unsuccessful" 
story, one i n  which t h e  problem i s  not solved,  can be just a s  
i n t e r e s t i n g  as a U s u c c e s s f u l ~  one. 
PLANNING STRUCTURES Planning s t r u c t u r e s  a r e  what we use t o  
organize knowledge about planf ul a c t i v i t y ,  which is  represented 
i n  CD by a  chain of causes and effects. The planning s t r u c t u r e s  
include d e l t a - a c t s ,  planboxes, packages, s c r i p t s ,  s igma-states ,  
r h o - s t a t e s ,  and p i - s t a t e s .  
A d e l t a - a c t  is used t o  achieve a p a r t i c u l a r  g o a l s t a t e .  
Delta-prox ( w r i t t e n  here a s  dPROXl i s  t h e  procedure fo r  becoming 
proximate t o  some loca t ion .  A de l t a -ac t  i s  defined as a goa l ,  a 
se t  of planboxes, and a dec i s ion  algorithm fo r  choosing between 
planboxes. 
A planbox is a p a r t i c u l a r  method for  achieving a g o a l s t a t e .  
A l l  t h e  planboxes under a  de l t a -ac t  achieve t h e  same g o a l s t a t e .  
Each planbox has a set of precondit ions (some of which may be 
de l t a -ac t s )  , and a set  of a c t i o n s  t o  perform. "UnconsciousN 
preconditions a r e  at tached t o  planboxes which would never occur 
t o  you t o  use. If you're t ry ing  t o  become proximate t o  X ,  you 
don ' t  even think about persuading X t o  come t o  you when X is an 
inanimate ob jec t .  " ~ n c o n t r o l l a b ~ e "  precondi t ions  cannot be made 
true i f  they ' re  not  a l ready true.  (The assumption is t h a t  they 
are sometimes t rue.)  " ~ l a n t i m e '  precondi t ions  a r e  t h e  t h i n g s  you 
worry about when you're making up t h e  p lan .  You don' t  worry 
about "runtimen preconditions u n t i l  you're executing the plan.  
("Planning" is a mental a c t i v i t y .  PLAN is, i n  f a c t ,  one of the  
p r i m i t i v e  ACTS of CD. "Executing a plan" i s  performing a 
l o g i c a l l y  s t r u c t u r e d  sequence  of  a c t i o n s  t o  achieve the g o a l  o f  
t h e  p l a n . )  I f  1 ' m  p l a n n i n g  t o  g e t  a Coke o u t  of t h e  machine 
u p s t a i r s ,  I wor ry  a b o u t  having  enough money, b u t  I d o n ' t  wor ry  
a b o u t  walking up  the s t a i r s  until 1 ' m  a t  the  s t a i r s .  That the 
machine a c t u a l l y  has some Coke is an  u n c o n t r o l l a b l e  r u n t i m e  
pr econd it i o n  : I d o n ' t  worry  a b o u t  i t  u n t i l  I g e t  t h e r e ,  and 
t h e r e ' s  n o t h i n g  I c a n  do  i f  it is empty when I g e t  t h e r e .  
A package is a set of p l a n b o x e s  which lead t o  a g o a l  ac t  
I' a t h e r  t h a n  state.  The PERSUADE package ,  f o r  i n s t a n c e ,  c o n t a i n s  
p l a n b o x e s  f o r  X t o  p e r s u a d e  Y t o  d o  some a c t  2 .  The p l a n b o x e s  
include a s k i n g ,  g i v i n g  l e g i t i m a t e  r e a s o n s ,  o f f e r i n g  f a v o r s  i n  
r e t u r n ,  t h r e a t e n i n g ,  and so on.  
Goalstates come i n  v a r i o u s  f l a v o r s .  T h e r e  a r e  t h e  goals 
which are  a s s o c i a t e d  w i t h  t h e  delta-acts:  t h e  g o a l  of dPROX is  
t o  be somewhere, t h e  goal of dKNOW is t o  f i n d  o u t  t h e  answer t o  
some q u e s t i o n ,  t h e  g o a l  of dCONTROL i s  t o  p o s s e s s  something.  B u t  
there are also g o a l s  of s a t i a t i o n ,  called s i g m a - s t a t e s .  For 
example, sHUNGER o r g a n i z e s  t h e  knowledge abou t  s a t i s f y i n g  hunger 
( i n v o k i n g  dCONTROL of some food ,  e a t i n g ) .  TALE-SPIN a l s o  u s e s  
sigma-state knowledge i n  t h e  b a r g a i n i n g  process; o f f e r i n g  
someone some food i n  r e t u r n  for a f a v o r  i s  l e g i t i m a t e  s i n c e  it 
w i l l  satisfy a p r e c o n d i t i o n  f o r  sHUNGER.  There  are a l s o  goals of 
p r e s e r v a t i o n ,  c a l l e d  pi-states,  which a re  most i n t e r e s t i n g  when 
t h e y  are  i n  danger  o f  be ing  v io l a t ed .  The l o g i c  o f  t h e  THREATEN 
p l anbox  i n  t h e  PERSUADE package, f o r  example,  d e r i v e s  from t h e  
f a c t  t h a t  p h y s i c a l  v i o l e n c e  c o n f l i c t s  w i t h  pHEALTN. 
A SAMPLE DELTA-ACT: dPROX 
- 
TALE-SPIN d o e s  no t  i n c l u d e  a l l  n i n e  
delta-acts descr ibed  by Abelson ( 1 9 7 5 ) .  I t  conta ins  t h e  three  
which closely correspond to pr im i t i v e  acts:  dPROX (PTRANS) , 
dCONTROL (ATRANS) , dKNOW (MTRANS). 
Here is an outline of dPROXt 
~ P R O X ( X , Y )  -- X wishes  to be near Y 
Planbox 0: if x is already near Y, succeed. 
Planbox 1: X qoes t o  Y 
uncontro l lab le  precondition: can X move himself?  
plantime precondition: P KNOW ( locat ion  o f  Y )  
runtime precondition: dLINK (location of Y) 
action: PTRANS t o  location of Y 
runtime precondit ion: i s  Y really there? (We may have 
g o t t e n  false information dur ing the  KNOW. ) 
Planbox 2: Y comes to X 
unconscidus precondit ion:  i s  Y animate? 
uncontrollable precondition: is Y rno~  able? 
action: PERSUADE Y to PTRANS himself  to X (PERSUADE package) 
Planbox 3: Agent A br ings  X to  Y 
uncontrollable precondition: i s  X movable? 
action: X gets AGENT to bring X to Y (AGENCY package) 
Planbox 4: Agent A brings Y t o  X 
unconscious precondition: i s  Y animate? 
uncontrol lable  precondit ion: i s  Y movable? 
action: X gets AGENT t o  bring Y to X (AGENCY package ) 
Planbox 5: X and Y meet a t  l o c a t i o n  Z 
unconscious precondition: is Y animate? 
uneontrollabls precondition: is Y movable? 
a c t i o n s :  PERSUADE Y t o  PTRANS h i m s e l f  t o  Z and dPROX(X,Z) 
THE DATA BASE Planning s t r u c t u r e s  a r e  e s s e n t i a l l y  p r o c e d u r a l .  
-- --
The non-procedural  d a t a  base  used by the planning s t r u c t u r e s  i s  
d i v i d e d  i n t o  f i v e  classes. 
1. Data about i n d i v i d u a l  PPs ( P i c t u r e  P roduce r s ,  nouns) 
where a p p l i c a b l e  : h e i g h t ;  weigh t ;  where t h e i r  home is; who 
t h e i r  a c q u a i n t a n c e s  are. 
2. Data common t o  classes of PPs (e .g. ,  d a t a  common t o  a l l  
birds) where a p p l i c a b l e :  what t h e y  ea t ;  what t h e i r  g o a l s  
(sigma-states) a r e ;  whether  t h e y  are  animate ( capab le  o f  
MBUILDing) , movable, self -movable ; how t h e y  move around. 
3 Sigma-state  knowledge i n d i c a t i n g  how t o  ach ieve  a 
s igma-s ta te  and what t h e  p l a n t i m e  p r e c o n d i t i o n s  a r e  t h a t  someone 
o t h e r  than  t h e  planner can ach ieve .  T h i s  is used i n  t h e  
bargaining process .  J o e  Bear o f f e r s  t o  b r i n g  I r v i n g  Bird a worm 
because dCONTROL (FOOD) i s  a p lan t ime  precond it ion for sHUNGER 
which J o e  Bear can  a c h i e v e  f o r  I r v i n g  Bird. There are no 
plantime p r e c o n d i t i b n s  f o r  sREST t h a t  he can ach ieve  f o r  I r v i n g  
Bi rd  ( excep t  maybe t o  l e a v e  him a lone )  . 
4. Memory: what everybody knows ( t h i n k s ,  believes) ; w h a t  
Joe Bear knows; what J o e  Bear t h i n k s  I r v i n g  B i ~ d  knows; e t c .  
Planbox 0 of BKNOW, f o r  example, a c c e s s e s  Memory t o  test  whether 
J o e  Bear a l r e a d y  knows t h e  answer t o  t h e  q u e s t i o n  be ing  asked, o r  
whether it i s  pub l i c  knowledge. Since both t h e  q u e s t i o n  and t h e  
facts i n  Memory are r e p r e s e n t e d  i n  CD, t h e  p a t t e r n  match is  v e r y  
simple, taking advantage of CD's c a n o n i c a l  r e p r e s e n t a t i o n  of 
meaning. 
5. Personal  r e l a t i o n s h i p s .  T h e  r e l a t i o n s h i p  of one 
character to another is d e s c i b e d  by a p o i n t  o n  each of t h r e e  
scales:  COMPETITION, DOMINANCE, and FAMILIARITY.  S c a l e  v a l u e s  
range from -10 to +I@. The relation " i s  a f r i e n d  o f "  i s  
represented by a certain r a n g e  on each of t h e  three scales. The 
r e l a t i o n  "would act  a s  an agen t  f o r "  is  r e p r e s e n t e d  by a 
different range.  The s e n t e n c e  " J o e  Bear t hough t  that I r v i n g  B i r d  
would t e l l  him where t h e  honey was" comes from the " A s k  a F r i e n d "  
planbox of dRNOW. There is a procedure w h i c h  goes t h r o u g h  a l i s t  
of Joe Bear's acquaintances and produces a l i s t  of  those who 
q u a l i f y  as " f r i e n d s " ,  i.e., those who fit somewhere within the 
" f r i e n d n  range. 
Relations are n o t  symmetric: Joe Bear may t h i n k  of  Irving 
B i r d  a s  h i s  f r i e n d ,  so h e  might ask him where t h e  honey is, b u t  
Irving Bird may n o t  th ink  of Joe Bear a s  h i s  f r i e n d  a t  a l l ,  i n  
which case he might r e f u s e  to  answer Joe Bear.  
Relationships can change. If Gee Bear becomes s u f f i c i e n t l y  
aggravated a t  h i s  " f r i e n d "  I r v i n g  B i r d  and has to t h r e a t e n  t o  
bash him i n  the beak i n  order t o  g e t  him to t e l l  him where t h e  
honey is, t h e n  the relationship between them d e t e r  i o r a t e  s .  
We plan t o  extend t h i s  feature t o  d e s c r i b e  a c h a r a c t e r ' s  
"default" r e l a t i o n s h i p :  how he relates t o  t o t a l  s t r a n g e r s .  T h i s  
would n o t  necessarily be t h e  p o i n t  (0,8,0) b u t  r a t h e r  some p o i n t  
which would be used to give  a rough i n d i c a t i o n  of  t h e  character's 
"persoaal i tyn .  Big bad Joe Bear might rate a t  ( + 6  ,+9,+4)  , where 
small meek B i l l  Worm m i g h t  r a t e  a t  (-6 ,-la , - 4 )  . 
Changing a r e l a t i o n s h i p  i s  a type of g o a l  we haven't y e t  
c o n s i d e r e d  i n  much d e t a i l ,  a 1  t h o u g h  g o a l s  of r e l a t i o n s h i p s  
( r h o - s t a t e s )  c l e a r l y  ex i s t .  The p r o c e d u r e  for g e t t i n g  someone t o  
l i k e  you ( r L I K E )  might c o n t a i n  p l anboxes  f o r  ATRANSing g i f t s ,  
MTRANSing sweet n o t h i n g s ,  e t c . ,  i n  a d d i t i o n  t o  changing your own 
f e e l i n g s  toward that p e r s o n  so t h a t  i f  he  (she) asks you t o  do 
someth ing ,  you d o n ' t  refuse. 
I n f o r m a t i o n  g e t s  into t h e  da ta  base i n  several ways. Memory 
da ta  gets  produced d i r e c t l y  by t h e  p l a n n i n g  s t r u c t u r e s .  Changes 
i n  relations are s i d e - e f f e c t s  of  t h e  present se t  of p l a n n i n g  
s t r u c t u r e s .  B u t  t h i n g s  have f o  s t a r t  somewhere. There is  a 
f u n c t i o n  CREATE ( X )  which i n v e n t s  a new item of type X ( e . g . ,  
bear,  f l o w e r ,  b e r r y ) .  Associated w i t h  each type of item is a 
small procedure called a picture which i n v e n t s  t h e  d e s i r e d  i t e m  
and o t h e r s  as r e q u i r e d .  For example,  when we c r e a t e  some honey,  
we also create a beehive, a t r ee ,  and a bee. The honey is 
"owned" by t h e  bee  and i s  i n s i d e  t h e  b e e h i v e  which i s  i n  t h e  
tree. The bee may o r  n o t  be a t  home. Randomly chosen  names, 
heights, w e i g h t s ,  etc., are  a t t a c h e d .  A l l  t h i s  d a t a  is  t h e n  
added t o  Memory. 
The CREATE f u n c t i o n  is called when needed; remembet t h a t  
TALE-SPIN models t h e  p r o c e s s  of making - ue a s t o r y  a s  you go 
a long .  We will now f o l l o w ,  i n  d e t a i l ,  t h e  p r o d u c t i o n  of the 
second sample story. 
CREATE a bear, which i n v o k e s  a p i c t u r e  p r o c e d u r e  which 
invents a beat.  Assume the bear is named J o e ;  although since t h e  
name is  chosen a t  random from a list of f i r s t  names, it i s  just 
a s  o i t e n  I r v i n g .  A c a v e  is also i n v e n t e d ,  and has J o e  i n  i f .  
~ o e ' s  l o c a t i o n  becomes p u b l i c  knowledge. 
CREATE a b i r d ,  named I r v i n g ,  and a tree which is  h i s  home. 
~ r v i n g ' s  loca t ion  is a l s o  now p u b l i c  knowledge. 
Assert  t h a t  Joe i s  hungry. T h i s  fact enters ~oe's Memory. 
We also "say" this: that is, we pass i t  to t h e  E n g l i s h  
translator which t h e n  produces  t h e  sentence "JOE BEAR WAS 
HUNGRY N .  
Invoke sHUNGER. 
Choose at random a food that bears e a t :  honey. A s s e r t  that 
Joe i s  now p lanning  t o  achieve t h e  goal (sigma-state) of 
s a t i s f y i n g  his hunger. Assert that he has d e c i d e d  that eating 
t h e  food can l e a d  to  t h e  achievement of h i s  goal. 
sHUNGER calls dCONTROL (honey)  . T h i s  forms a new goal, 
namely, t h a t  Joe have some honey.   CONTROL'S "Planbox 0" asks 
Memory i f  t h e  goal is a l s e a d y  true: does Joe a l r e a d y  have some 
honey? The answer comes back: n o .  A plantime p r e c o n d i t i o n  is 
t o  know t h e  location of some honey, so dCONTROL c a l l s  dKNOW(where 
i s  honey?). (The question is r e p r e s e n t e d  in C D ,  not English.) 
dKNOW forms the  new g o a l .   KNOW'S "Planbox 0" asks Memory 
whether Joe knows the  location of any honey.  Memory says no.  
Planbox 1 tests whether the  question can be answered by 
consu l t ing  a standard reference (e .g . ,  "What time is it?") . T h a t  
f a i l s .  Planbox 2 tests whether  t h e  question r e q u i r e s  expertise: 
no. Planbox 3 t e s t s  whether t h i s  i s  a "general in format ion"  
q u e s t i o n .  I t  i s ,  so w e  a s s e r t  t h a t  Joe i s  p lanning  to answer 
t h i s  q u e s t i o n  u s i n g  Planbox 3 ("Ask a Friend"). 
Planbox 3 starts. Choose a f r i e n d :  I r v i n g .  dKNOW calls 
the PERSUADE package t o  t r y  t o  g e t  I r v i n g  t o  answer ~ o e ' s  
q u e s t i o n .  
PERSUADE a s k s  Memory whether  Joe t h i n k s -  that I r v i n g  c a n n o t  
answer  t h e  question. ~ n s w e r :  no. I r v i n g  is  a " f r i e n d " ,  so w e  
t r y  t h e  ASK p lanbox .  A s s e r t  t h a t  Joe t h i n k s  t h a t  Irviag will 
t e l l  him where t h e  honey is. PERSUADE c a l l s  dPROX(,Irving),  s i n c e  
J o e  needs  t o  speak t o  I r v i n g .  
dPROX asks Memory whether  Joe i s  a l r e a d y  n e a r  I r v i n g .  
Memory says no. Planbox 1: i s  Joe se l f -movable?  Yes. A s s e r t  
t h a t  Joe i s  planning t o  be nea r  I r v i n g  by go ing  there himself. 
dPROX c a l l s  dKNOW (where i s  I r v i n g ? )  . 
~KNOW'S "Planbox 0"  asks Memory whether Joe a l r e a d y  knows 
where I r v i n g  is. The answer comes back: y e s ,  I r v i n g  is i n  a 
c e r t a i n  t r e e .  dKNOW r e t u r n s  t h i s  to ~ P R O X .  (We w i l l  omit  future 
references t o  "Planbox O n .  ) 
dPROX a s s e r t s  that Joe walks t o  t h e  t r e e  where I r v i n g  is .  
We a s k  Memory whether  I r v i n g  is  a c t u a l l y  there. H e  i s ,  so dPROX 
h a s  achieved its desired g o a l ;  his change  i n  l o c a t i o n  is added 
t o  Memory. dPROX r e t u r n s  t o  PERSUADE. 
30e a s k s  Irving where some honey i s .  The reader now g e t s  t o  
decide whether  I r v i n g  a g r e e s  t o  do  39. Assume t h e  r e a d e r  says 
y e s .  We ask Memory whether Irving a c t u a l l y  knows where any honey 
is .  I f  h e  d i d ,  w e  would have I r v i n g  tell h im,  but he doesn't, so  
we CREATE some honey: a s t o r y t e l l e r  can c r e a t e  s 6 l u t i o n s  t o  
p rob lems  as well a s  o b s t a c l e s !  Some honey is  i n v e n t e d ,  along 
w i t h  a beeh ive ,  a tree, and a bee (Henry)  who is  a t  home. I r v i n g  
t e l l s  Joe that t h e  honey is i n  t h e  beeh ive .  ASK s u c c e e d s ,  so  
90 
PERSUADE succeeds, so dKNOW succeeds: Joe knows where some honey 
is .  
Back i n  dCONTROL, we ask Memory whether [Joe t h i n k s  t h a t ]  
anyone owns the honey. Memory says t h a t  Henry does ,  so  
  CONTROL'S Planbox 1 ("Free f o r  t h e  taking") fails. Planbox 2 i s  
t o  PERSUADE Henry t o  give t h e  honey to Joe. 
Given no re la t ion  between Joe and Henry ( t h e y  d o n ' t  know 
each other) , the on ly  planboxes i n  PERSUADE which can be used are 
ASK and INFORM REASON. 
We try ASK f i r s t .  This calls dPROX<Henry) which succeeds 
s i r f c e  Joe knows where Henry is;  we omit the d e t a i l s  h e r e .  Joe 
asks Henry to g i v e  him the honey,  and t h e  reader decides that 
Henry re fuses .  
We try INFORM REASON next. We c h o o s e  a goal of ~enry's and 
b u i l d  a causal chain backwards from t h e  goal,. For example, one 
of  Henry s goals i s  t o  "eat" f lowers .  (TALE-SP'IN t h i n k s  that 
what beesa d o  t o  f l o w e r s  i s  e q u i v a l e n t  to e a t i n g . )  I n  order t o  
e a t  a f l o w e r ,  you have to  "control" a flower, which r e s u l t s  from 
someone (possibly you yourself) ATRANSing the flower to you. We 
test  whether what Joe i s  t r y i n g  to PERSUADE Henry to d o  matches  
ATRANSing a f l o w e r .  I t  doesn't, (Joe i s  trying to PERSUADE 
Henry to  A-TFWNS t h e  honey t o  him.) We t h e n  consider t h a t  i n  
o r d e r  to ATRANS a flower, you. have to be near t h e  flowes, which 
r e s u l t s  from someone PTRANSing you t o  t h e  f lower.  Does this 
match? No . We r e p e a t  this process  a few times, t r y i n g  to 
construct a short i n f e r e n c e  c h a i n  which -connects= what Joe i s  
trying to  persuade Henry to do with one of Henry's g o a l s .  INFORM 
REASON f a i l s ,  and we r e t u r n  t o  dCONTROL. 
The n e x t  P l a n b o x  i s  ca l l ed  "Steal". We ask Memory ~ h e t h e r  
Henry is home: i f  he  w e r e n ' t ,  J o e  would simply t a k e  t h e  honey.  
But Memory t e l l s  u s  t h a t  Henry  is  home, so STEAL c a l l s  PERSUADE 
t o  get Henry  t o  l eave  home; that is,  Joe is now going t o  t r y  t o  
p e r s u a d e  Henry  t o  PTRANS h i m s e l f  f rom t h e  h i v e .  
I n  t h e  c o n t e x t  o f  STEAL,  t h e  A S K  p l a n b o x  i s  n o t  u s e d .  Joe 
tries INFORM REASON again and succeeds i n  producing the f o l l o w i n g  
chain: we g e t  t o  t h e  idea of someone PTRANSing h i m s e l f  t o  a 
f l o w e r  again a s  we d i d  before, b u t  w e  n o t i c e  t h a t  t h i s  does m a t c h  
what  we are t r y i n g  to persuade Henry  to do:  the c o n n e c t i o n  i s  
4 t h a t  Henry will PTRANS h i m s e l f  from the b e e h i v e  to t h e  f l o w t x .  
Joe now c o n s i d e r s  the p r e c o n d i t i o n  for ~ e n r y  's PTRANSing himself 
to the f lower ,  namely, t h a t  Henry  h a s  t o  know where  the flower 
is. Memory does n o t  i n d i c a t e  t h a t  J o e  t h i n k s  t h a t  Henry knows 
where a flower is ,  n o r  does Joe know where a f l o w e r  is ,  but 
r a t h e r  than invoke dKNOW(where i s  a flower?), w e  CREATE a f l o w e r :  
t h i s  i s  l e g i t i m a t e  i n  a plan to s t e a l  s o m e t h i n g .  Joe now tells 
Henry t h a t  there i s  a  flower i n  a c e r t a i n  f l o w e r b e d ,  and then 
asks Hengy i f  he  would like t o  fly to  t h a t  f l o w e r .  Henry aqrees  
and flies away. PERSUADE s u c c e e d s ,  and r e t u r n s  t o  dCONTROL. 
Joe now takes the honey f rom the h i v e ,  s o  dCONTROL succeeds  
and r e t u r n s  t o  sHUNGER.  Memory is m o d i f i e d  t o  i n d i c a t e  t h a t  Joe 
knows t h a t  he h a s  t h e  honey ,  b u t  t h a t  Henry d o e s  not. 
Joe  now oats t h e  h o n e y ,  and h a s  ach ieved  t h e  sigma-state of 
n o t  b e i n g  h u n g r y .  But, when bears e a t ,  t h e y  become t i r e d ,  so  
sREST i s  invoked.  
sREST i s  v e r y  s h o r t .  I t  r e q u i r e s  a dPROX ( c a v e )  , which  i s  
e a s i l y  a c h i e v e d ,  and t h e n  Joe goes t o  s leep .  
Since t h e  main goal has been a c h i e v e d ,  and the g o a l  p roduced  
as  a c o n s e q u e n c e  of  that g o a l  has a l s o  been a c h i e v e d ,  t h e  s t o r y  
ends. 
What d i s t i n g u i s h e s  s t o r i e s  from s i m p l e  s e q u e n c e s  of  e v e n t s ?  
Coherency  i s  i m p o r t a n t :  t h e r e  has t o  be a l o g i c a l  flow f rom one 
e v e n t  t o  t h e  next. T h i s  i s  r e p r e s e n t e d  i n  CD a s  a c h a i n  of a c t s  
which r e , s u l t  i n  s t a t e s  which e n a b l e  f u r t h e r  a c t s  and s o  on.  
I n t e r e s t  is  i m p o r t a n t :  s o m e t h i n g  i n t e r e s t i n g  o r  u n u s u a l  h a s  t o  
happen o r  else t h e  r e a d e r  w i l l  begin t o  wonder what  the p o i n t  of  
t h e  s t o r y  is. TALE-SPIN c r e a t e s  impediments  t o  g o a l s ,  o n  t h e  
a s s u m p t i o n  t h a t  t h e  overcoming  of o b s t a c l e s  can make an 
i n t e r e s t i n g  s k o r y .  "One d a y  Joe Bear w a s  hungry .  T h e r e  was a 
jar  o f  honey r i g h t  n e x t  t o  him. He a t e  it. The end" i s  n o t  a 
s t o r y .  It s h o u l d n ' t  be t h a t  e a s y .  
On t h e  o t h e r  hand ,  it s h o u l d n ' t  be t o o  h a r d  e i t h e r .  I n  
t h e o r y  a t  least, t h e r e  i s  a c o s t - e f f e c t i v e n e s s  ca l cu lus  which 
people employ when d e c i d i n g  how much e n e r g y  t o  expend on a 
s u b g o a l ,  based a n  how much t h e  g o a l  is w o r t h  t o  them. T h i s  
p r o c e s s  p r e v e n t s  t h e  p l a n s  f rom b e i n g  t o o  complicated. 
A s  t h e  story i s  g e n e r a t e d ,  v a r i o u s  p l o t  d e c i s i o n s  have t o  be  
made. Some d e c i s i o n s  are made a t  random, o t h e r s  a re  made by t h e  
r e a d e r .  When J o e  Bear t h r e a t e n s  I r v i n g  Bird because I r v i n g  B i r d  
won't t e l l  him where t h e  honey  is ,  t h e  r e a d e r  g e t s  t o  decide 
whether I r v i n g  B i r d  is  g o i n g  t o  i g n o r e  t h e  threat. 
We use  p l a n n i n g  s t r u c t u r e s  b e c a u s e  any program which r e a d s  
o r  w r i t e s  a s t o r y ,  whether of the f o l k t a l e  v a r i e t y  or the New 
York  Times v a r i e t y ,  m u s t  have a  model of the l o g i c  of human 
a c t i v i t y .  I t  might be e a s i e r  t o  simulate t h e  genera t ion  of a 
h igh ly  s t y l i z e d  form of s t o r y ,  a s  Klein ( 1 9 7 4 )  has done using 
~ r o p p ' s  a n a l y s i s  of a  c l a s s  of Russian f a i r y  tales, but  the re  is 
l i t t l e  g e n e r a l i t y  there .  One could use any of t h e  wel.1-known 
problem-solving systems l i k e  MICRO-PLANNER, b u t  t h e  s t o r y  is t h e  
proof procedure, and the procedure used the re  does not  correspond 
t o  my conception of how people solve  problems.   hat's not a 
c r i t i c i s m  of MICRO-PLANNER a s  a  problem-solver, b u t  only a s  a 
model human problem-solving . 
user i n t e r a c t i o n  was included for  two reasons. F i r s t ,  the  
i n t e r a c t i v e  f e a t u r e  now serves  a s  a h e u r i s t i c  for placing bounds 
on the  complexity of the s to ry .  Beyond, some number of obs t ac l e s  
t o  the g o a l ,  a  s t o r y  becomes a k i n d  of joke. Second and more 
important ,  ex tens ions  t o  TALE-SPIN w i l l  include more 
soph i s t i ca t ed  responses than t h e  present yes/no var i e ty .  
THE FUTURE OF TALE-SPIN. 
-- - There a r e  a  l o t  of th ings  t h a t  
TALE-SPIN doesn ' t  do ye t  t h a t  would improve it a s  a s t o r y t e l l e r .  
Here a r e  some of the  t h e o r e t i c a l  problems we w i l l  be working on  
i n  the  immediate f u t u r e .  (1) Bargaining, a s  it e x i s t s  now i n  
TALE-SPIN, i s  a p r e t t y  one-sided a f f a i r ,  w i t h  the main character  
making a l l  t h e  proposals.  I rv ing Bird i s  j u s t  a s  l i k e l y  t o  
suggest  t h a t  Joe Bear go g e t  him a  worm as Joe is  t o  o f f e r  to  do 
SO Counter-proposals a r e  c e r t a i n l y  common enough. ( 2 )  Future 
s t o r i e s  should include planning on t h e  p a r t  of more than one 
cha rac te r .  The presen t  s t o r i e s  a r e  a l l  "about" the bear ,  and 
o n l y  i n c i d e n t a l l y  involve the b i r d  and o t h e r  c h a r a c t e r s .  The 
stories a re  more concerned  w i t h  r e a c t i o n  t h a n  i n t e r a c t i o n .  ( 3 )  
For every p l a n ,  there may be a c o u n t e r - p l a n ,  a plan t o  block t h e  
achievement of a goal: a p lan  for  keeping away from somethinq or 
someone; a plan not t o  f i n d  o u t  something, o r  to be c ~ n v i n c e d  
that it isn't t rue ;  a plan t o  g e t  r i d  of something you own. ( 4 )  
How much of a plan do people consider i n  advance? We have made 
some efforts i n  t h i s  area  by making t h e  d i s t i n c t i o n s  between 
kinds of p r e c o n d i t i o n s .  C e r t a i n l y  t h e  most important  improvement 
here will be t h e  c o s t - e f f e c t i v e n e s s  r e a s o n i n g .  ( 5 )  The theory of 
t e l l i n g  s t o r i e s  (what t o  say) now implemented i n  TALE-SPIN i s  to 
express v i o l a t i o n s  o f  s i g m a - s t a t e s  ("Joe Bear was h u n g r y n )  , 
p h y s i c a l  acts ,  and those mental ac t s  which provide m o t i v a t i o n  o r  
j u s t i f i c a t i o n  for l a t e r  events. The r e a d e r  is assumed t o  be able 
t o  infer t h e  rest. T h i s  seems t o  work r e a s o n a b l y  we11 for t h e  
present simple s t o r i e s ,  but may have  t o  be modif ied  to s u i t  
l o n g e r ,  more complicated storie s. 
REFERENCES 
Abe l son ,  Re P. (1975) .  Concep t s  fo r  representing mundane reality 
i n  p l a n s .  I n  D, Bobrow and A. Collins, eds. Representation 
and understanding: Studies i n  c o g n i t i v e  science. Academic ' 
- 7 P r e s s ,  New York. 
R l e i n ,  S. e t  a1 ( 1 9 7 4 ) .  Model l ing  Propp and L e v i - S t r a u s s  i n  a 
rneta-symbolic s i m u l a t i o n  system. T e c h n i c a l  Report 2 2 6 ,  
University of. Wisconsin a t  Madison. 
Schank,  Ro C. (1975) .  Concep tua l  I n f o r m a t i o n  P r o c e s s i n  . 
American E l s e v i e r ,  New YZ *~bis includes -___r% contri u t i o n s  by 
N e i l  M. Goldman, C h a r l e s  J. ~ i e g e c  111, and Chris topher  K. 
Riesbec k ,  
Schank, R. C. and Abelson, R. P. ( 1975 ) .  Scripts, plans and 
knowledge, In Proceedings of t h e  4 t h  I n t e r n a t i o n a l  Joint 
Conference  on Artificial I n t e l l i g e n c e .  

