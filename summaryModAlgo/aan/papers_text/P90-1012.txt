NORMAL STATE IMPL ICATURE 
Nancy L. Green 
Department of Computer and Information Sciences 
University of Delaware 
Newark, Delaware 19716, USA 
Abstract 
In the right situation, a speaker can use an unqual- 
ified indefinite description without being misun- 
derstood. This use of language, normal slate im- 
plicature, is a kind of conversational implicature, 
i.e. a non-truth-functional context-dependent i - 
ference based upon language users' awareness of 
principles of cooperative conversation. I present 
a convention for identifying normal state implica- 
tures which is based upon mutual beliefs of the 
speaker and hearer about certain properties of the 
speaker's plan. A key property is the precondition 
that an entity playing a role in the plan must be 
in a normal state with respect o the plan. 
1 In t roduct ion  
In the right situation, a speaker can use 
an unqualified indefinite description without being 
misunderstood. For example, a typical customer 
in a typical pet shop who said (la) in response to 
the clerk's question in (1) would expect o be un- 
derstood as meaning (lb). The goal of this paper 
is to formally describe such uses of language. 1 
1A similar use of language is noted in \[McC87\]. Mc- 
Carthy (pp. 29-30) discusses the problem of b r id~ng the 
gap between a "rather direct \[translation\] into first order 
logic" of a s tatement  of the Missionaries and  Cannibals puz- 
zle, and a representat ion suitable for devising a solution to 
the puzzle. For example, if the puzzle s ta tement  mentions 
that  '% rowboat that  seats two is available" and  doesn't  say 
that  anyth ing is wrong with the boat,  the problem-solver 
may assume that the boat doesn't leak, has oars, etc. Mc- 
Carthy proposes a general-purpose method for formalizing 
common sense reasoning, "circumscription", to solve the 
problem. 
Also, a similar use of language is described in \[GriT5\] (p. 
51): "A is standing by an obviously immobilized car and is 
approached by B; the following exchange takes place: 
A: I am out of petrol. 
B: There is a garage round the corner. 
... \[B\] implicates that the garage is, or at least may be 
open, \[has petrol to sell\], etc." That tiffs use of language 
89 
1. (Clerk A:) May I help you? 
a. (Customer B:) I'd like to see a parrot. 
b. I \[the speaker\] would like to see a live parrot. 
c. 3 p:PARROT REQUEST(B,A,SIIOW(A,B,p)) 
d. 3 q:\[A p:PARROT LIVE(p)\] REQUEST(B,A, 
SHOW(A,B,q) 
One problem is that (la) (i.e. its putative 
representation in (lc)) does not entail (lb) (i.e. its 
putative representation in (ld)). 2 
Another problem 
is the context-dependence, both spatio-temporal 
and linguistic, of the relationship of (lb) to (la). 
In a different spatic~temporal context, such as in 
a china shop, a speaker might use (la) to convey 
(2) rather than (lb). 
2. I \[the speaker\] would like to see a porcelain 
parrot. 
In a different linguistic context, such as if the cus- 
tomer had said (3a) following (la), she would not 
involves the use of language I have i l lustrated in (1) can 
be seen by considering a s i tuat ion identical to the above 
except that  the dialogue consists of just  A 's  saying "I need 
a garage." In other words, Grice's example is of a situation 
where B has ant ic ipated a request from A which is the same 
kind of request as (la). 
2The customer's use of (la) is an indirect speech act, 
namely, a request to be shown a parrot; other possible re- 
alizations of this request include "Show me a parrot" and 
"Can you show me a parrot?". (The derivation of represen- 
tations of indirect speech acts has been treated elsewhere 
\[PAS0\] and is not a concern of this paper.) (Ic) is intended 
to represent that request by means of a first order language 
extended with hlgher-order operators such as REQUEST.  
Also, indefinite descriptions are represented as in \[Web83\]. 
The status of the existence of the parrot in the real world 
or discourse context (and the related question as to the 
proper scope of the existential quantifier), is not relevazlt 
to the concerns of this paper. My  point is that the usual 
treatments employing a one-to-one translation from surface 
structure to logical form without consideration of other in- 
formation will not he able to explain the relationship of 
( lb) to (1@ 
normally expect he clerk to think she had meant 
(lb). A related question is why it would be ap- 
propriate (non-redundant) for the customer to say 
(3b) following (la) if the customer believed that 
the clerk might mistakenly believe that the cus- 
tomer wanted to see a dead parrot. 
2 Scalar Impl icature 
tIirschberg proposes the following set of six 
necessary and sufficient conditions for identifying 
conversational implicatures (p. 38). 3 A speaker 
S conversationally implicates Q to a hearer tI by 
saying U (where U is a realization of a proposition 
P) in a context C iff: 
3.a . . . .  a dead one 
b . . . .  a l ive  one 
A third problem is that in order to derive 
(lb) from (la) it is necessary to consider the beliefs 
of speaker (S) and hearer (H): e.g. S's and H's 
beliefs about why each said what they did, and 
about the appropriate state of the parrot. 
Grice \[Gri75\] described conversational im- 
plicature, a kind of non-truth-functional context- 
dependent inference based upon a speaker's and 
hearer's awareness ofprinciples of cooperative con- 
versation. In this paper, I claim that a speaker's 
use of (la) may conversationally implicate (lb). 
In order to formally describe this kind of conver- 
sational implicature, which I have termed 'nor- 
mal state implicature', I adopt the methodology 
used by Hirschberg \[Hir85\] for the identification of 
another kind of conversational implicature, scalar 
implicature. 
In section 2, I present a brief description 
of scalar implicatures and Hirschberg's methodol- 
ogy for identifying them. In section 3, I present 
a convention for identifying normal state implica- 
tures. Informally speaking, the convention is that 
if speaker S makes a request hat hearer H per- 
form an action A on an entity E, and if S and tt 
mutually believe that S has a plan whose success 
depends on the E being in a certain state N (which 
is the normal state for an E with respect o that 
plan) and that S's request is a step of that plan, 
then S is implicating a request for S to do A on an 
E in state N. 
In section 4, I clarify the notion of nor- 
mal state with respect to a plan by distinguish- 
ing it from the notions of stereotype and plan- 
independent normal state. Next, in section 5, I 
show how states can be represented in the lexicon. 
In section 6, I compare scalar and normal state im- 
plicature; in section 7, survey related work; and, 
in section 8, present my conclusions. 
1. S intends to convey Q to H via U; and 
2. S believes that S and H mutually believe that 
S is being cooperative; and 
. 
. 
. 
. 
S and H mutually believe that S's saying U in 
C, given S's cooperativity, licenses Q; and 
Q is cancelable; i.e., it is possible to deny Q 
without denying P; and 
Q is nondetachable; i.e., the choice of a real- 
ization U of P does not affect S's implicating 
Q (except in certain situations where Q is li- 
censed via Grice's Maxim of Manner); and 
Q is reinforceable; i.e., it is possible to affirm 
Q without seeming redundant. 
Instead of using these conditions to identify 
particular scalar implicatures, Hirschberg argues 
that it is sufficient o provide a means of iden- 
tifying instances of a class of conversational im- 
plicature, such as scalar implicatures. Then, she 
provides a convention for identifying instances of 
scalar implicat ure. 
Informally speaking, scalar implicature is 
based on the convention that (pp. 1 - 2)"cooper- 
ative speakers will say as much as they truthfully 
can that is relevant o a conversational exchange"; 
and distinguished from other conversational impli- 
catures by "being dependent upon the identifica- 
tion of some salient relation that orders a concept 
referred to in an utterance with other concepts"; 
e.g. by saying (4a), B has scalar implicated (4b). 4 
(4) A: How was the party last night? 
a. B: Some people left early. 
b. Not all people left early. 
90 
The convention for identifying scalar impli- 
cature proposed by Hirschberg is of the form: if 
3Her condit ions are ~ revision of Grice's. Also, I have 
changed the names  of her variables to be consistent with 
usage in the rest of my paper. 
4 (4) is example (1) in \[Hir85\]. 
there exists a partial order O such that S and H 
mutually believe that O is salient in context C, 
and utterance U realizes the proposition that S af- 
firms/denies/is gnorant of some value in O, then 
by saying U to H in C, S licenses the scalar im- 
plicature that S has a particular belief regarding 
some other value of O. 
In the next section, I will ap- 
ply Hirschberg's methodology to the problem of 
identifying normal state implicatures. 
3 Normal  S tate  Imp l i ca ture  
In this section, I will argue that (lb) is a 
conversational implicature and propose a conven- 
tion for identifying instances of that class of impli- 
cature, which I will call 'normal state implicature'. 
First, I claim that a speaker S conversa- 
tionally implicates (lb) to a hearer H by saying 
(la) in the context described above; i.e. that (lb) 
is a conversational implicature according to the 
six conditions described in section 2. Condition 1 
is met since S intends to cause H to believe (lb) 
by saying (la); condition 2 since S believes that 
it is a mutual belief of S and H that S is being 
cooperative; condition 3 will be satisfied by pro- 
viding a convention for normal state implicature 
below. The previous discussion about (3a) and 
(3b) provides evidence for cancelability (condition 
4) and reinforceability (condition 6), respectively; 
and, (lb) is nondetachable (condition 5) since al- 
ternate ways of saying (la), in the same context, 
would convey (lb). 
Next, in order "to motivate the general 
convention ((6) below) for identifying normal 
state implicatures, I'll present the instance of 
the convention that accounts for the implicature 
in (1). Let S, H, U, and C be constants de- 
noting speaker, hearer, utterance, and context, 
respectively. Let b0, bl, and g be first or- 
der variables over parrots (PARROT), live par- 
rots (the lambda expression), and plans (PLAN), 
respectively. 5 HAS-PLAN(Agent,Plan,Entity) is 
5The model of plans used here is that of STRIPS \[FN71\] 
with minor extensions. A plan includes preconditions 
which must hold in order for the plan to succeed, and a 
sequence ofactions to be carried out to achieve some goal. 
One extension to this model is to add a llst of entities play- 
ing a role in the plan either as instruments (e.g. a boat 
which is to be used to cross a river) or as the goal itself 
(e.g. a parrot o be acquired for a pet). The second exten- 
true if Agent has a plan in which Entity 
plays a role; PRECOND(Plan,Proposition) is
true if Plan has Proposition as a precondition; 
STEP(Plan,Action) is true if Action is a step 
of Plan. Also, BMB(A,B,Proposition) is true 
if A believes that A and B mutually believe 
that Proposition; REALIZE(Utterance, Propo- 
sition) is true if Utterance expresses Proposi- 
tion; REQUEST(S,H,Action) is true if S re- 
quests H to perform Action; and SAY(S,H,U,C) 
is true if S says U to H in C. 6 SHOW(A,B,C) is 
true if A shows C to B. IN-STATE(Entity,State) 
is true if Entity is in the given State; and 
NORMAL-STATE(State,Plan,Entity) is true if 
State is the normal state of Entity with re- 
spect to Plan. 7 Finally, NORMAL-STATE- 
IMP (Speaker, Hearer ,Utterance ,Prop osition ,Context ) 
is true if by use of Utterance in Context, Speaker 
conveys Proposition to Hearer. 
Now, to paraphrase (5) below, if S and H 
mutually believe that S has a plan in which a par- 
rot plays a role and that a precondition of S's plan 
is that the parrot should be alive, which is its nor- 
mal state with respect to the plan, and that S's 
saying U is a step of that plan; and, if U is a re- 
quest to be shown a parrot, then S normal state 
implicates a request o be shown a l ive parrot. 
5. Vb0:PARROT 
Vbl : \[Ab2: PARROT LIVE(b2)\] 
?g:PLAN 
BMB(S, H, ~HAS-PLAN(S, g, b0) A 
PRECOND(g, IN-STATE(b0, LIVE)) A 
NORMAL-STATE(LIVE, g, b0) A 
STEP(g, SAY(S, H, U, C))) A 
REALIZE(U, REQUEST(S, H, SHOW(H, S, b0))) 
NORMAL-STATE-IMP(S, H, U, REQUEST(S, H, 
SHOW(H, S, bl)),C) 
It is possible to generalize (5) as follows. 
Let K, N, and A be higher order variables over 
classifications (CLASSIF), states (STATE), and 
actions that may be performed as a step in a plan 
sloE, suggested in \[Car88\], is to distinguish preconditions 
which can be achieved as subgoais from those which are 
unreasonable for the agent o try to bring about ("applica- 
bility conditions" ). In (5) and (6), preconditions are meant 
in the sense of applicability conditions. 
eBMB, REALIZE, REQUEST, and SAY are from 
\[Hir85\]. 
7I will discuss what is meant by state and normal state 
in section 4. 
91 
(ACT), respectively. Then, (6) is the general con- 
vention for identifying normal state implicature. 
6. V K:CLASSIF V N:STATE V A:ACT 
Vb0:K 
Vbl: \[~b2:K N(b~)\] 
V g:PLAN 
BMB(S, H, HAS-PLAN(S, g, b0) A 
PRECOND(g, IN-STATE(b0, N)) A 
NORMAL-STATE(N, g, b0) A 
STEP(g, SAY(S, It, U, C))) A 
REALIZE(U, REQUEST(S, H, A(b0))) ?~ 
NORMAL-STATE-IMP(S, H, U, 
REQUEST(S, I-I, A(bl)),C) 
Unfortunately, if (6) is to be of maximum 
use, there are two problems to be solved. First, 
there is the problem of representing all precon- 
ditions of a plan, s and, second, is the problem of 
plan inference, i.e., how does H come to know what 
S's plan is (including the problem of recognizing 
that the saying of U is a step in S's plan)? 9 Both 
problems are outside the scope of this paper. 
4 States and Normal  States 
First, what I mean by a state of an entity 
E is, adopted from \[Lan87\], a history of related 
events involving E. In Lansky's ontology, events 
may be causally or temporally related. Tem- 
poral precedence is transitive. Causality is not 
transitive and does not necessitate occurrence but 
does imply temporal precedence. A strong pre- 
requisite constraint (--,) can be defined such that 
"each event of type E~ can be caused by ex- 
actly one event of type El,  and each event of 
type E1 can cause at most one event of type E2" 
(\[Lan87\],p. 142). 
Many classifications expressed as nouns de- 
note a class of entity whose state varies over the 
period of existence during which it is aptly char- 
acterized by the classification. For example, Fig- 
ure 1 and Figure 2 depict causal event chains l? of 
parrots and vases, respectively. 
(Nodes represent events and directed arcs 
represent causality.) The state of being dead or 
SE.g., see \[McC87\]. 
9E.g., see \[Car88\]. 
1?I don't mean 'causal chain' in the sense that philoso- 
phers have recently used it \[Sch77\], nor in the sense of 
\[SA77\], nor do I mean 'chain' in the mathematical sense 
of a total order. 
broken can be defined in terms of the occurrence 
of an event type of dying or breaking, respectively. 
Live is the state of an entity who has been born 
but has not yet died; ready-to-use is the state of 
an artifact between its creation or repair and its 
destruction. 11 Note that, paradoxically, language 
users would agree that a dead parrot or a vase with 
a crack in it is still aptly characterized as a parrot 
or vase, respectively. 12
Next, what I mean by a normal state of E 
is a state that E is expected to be in. For example, 
in the absence of information to the contrary, live 
or ready-to-use is expected by language users to 
be a state of parrots or vases, respectively. Note, 
however, that NORMAL-STATE in (6) represents 
a normal state of an entity with respect o some 
plan. That is, I am not claiming that, in the ab- 
sence of information about S's plan, S's use of ( la) 
conversationally implicates (lb). 
The reason for stipulating that NORMAL- 
STATE be relative to S's plan is that use of ( la) in 
the context of a different plan could change what 
S and H consider to be normal. For example, in a 
taxidermist's plan, dead could be the normal state 
of a parrot. Also, consider 'coffee': a speaker's use 
of (7) in the context of a coffee farm could be used 
to request coffee beans; in a grocery store, a ja r  of 
instant; and in a restaurant, a hot beverage. 
7. I'd like some coffee. 
92 
Note that more than one precondition of 
S's plan may be relevant o interpreting S's use of 
an expression. For example, a typical restaurant 
customer uttering (7) expects to be understood as 
not only requesting coffee in its hot-beverage state, 
but also in its safe-to-drink state. Also, more than 
one of S's plans may be relevant, Returning to the 
pet shop example, suppose that S and H mutually 
believe that S has plans to acquire a parrot as a pet 
and also to study its vocalizations; then it would 
be inappropriate for H to show S a parrot that H 
believed to be incapable of making vocalizations. 
Normal states differ from stereotypes. A 
stereotype is a generalization about prototypes of 
a category, 13 e.g. (8). 14 
11Examples of how state predicates can be defined in 
Lansky's formal anguage will be given later. 
12The cracked vase example is from \[Her87\]. 
laThe prototype-stereotype distinction is described 
in\[HH83\]. 
14Note that stereotypes may be relative to a state of the 
8. Unripe bananas are green. 
Qualifying an expression in a way which 
contradicts a stereotype may have a different ef- 
fect on H than doing so in a way which specifies a
non-normal state. For instance, if S says (9) after 
saying (la) in the above pet shop scenario, H may 
doubt S's sincerity or S's knowledge about parrots; 
while S's use of (3a) after saying (la) may cause 
tI to have doubts about S's sincerity or It's knowl- 
edge of S's plan, but not S's knowledge about par- 
rots. 
9 . . . .  a 100 pound one 
Another difference between stereotypes and 
normal states is that stereotypes are not affected 
by S's and H's mutual beliefs about S's plan, 
whereas I have just demonstrated that what is 
considered normal may change in the context of 
S's plan. Finally, another eason for making the 
distinction is that I am not claiming that, in the 
above pet shop scenario, S's use of (la) licenses 
(10); i.e., S does not intend to convey (10). 15 
10. I \[the speaker\] would like to see a large, 
green, talking bird. 
5 The Role of Events in cer- 
tain Lexical Representa- 
tions 
Now I will show how the notion of state 
presented in the previous section can be repre- 
sented in the lexicon via state predicates based 
on causal event chains. The purpose of this is to 
clarify what counts as a state and hence, what is 
prototype; e.g. contrast (8) with "Ripe bananas  are yel- 
low". A statement of a stereotype in which the state of the 
prototypes is unspecif ied may describe prototypes in the 
plan- independent ormal  state for the category; e.g. con- 
sider "Bananas  are yellow". Also, note that  stereotypical 
properties may be used to convey the state; e.g. consider 
"I want a green banana" used to convey "I want an unripe 
banana" .  
15I recognize that  it is possible for a speaker to exploit 
mutua l  beliefs about  stereotypes or p lan- independent or- 
real states to convey conversational implicatures. E.g., con- 
sider the conversation: A says, "Is your neighbor ich?" B 
replies, "He's a doctor." However, this k ind of impl icature 
does not occur under  the same condit ions as those given 
for normal  state implicature, and is outside of the scope of 
tiffs paper. 
93 
to be identified by the convention for normal state 
implicature. This way of representing states has 
benefits in other areas. First, entaihnent relation- 
ships between states of an entity are thereby rep- 
resented. Second, certain scalar implicatures may 
be based on the event ordering of a causal event 
chain. 
For example, Figure 3 contains pictorial 
and formal representations of a causal event chain 
for the ripening of fruit. Definitions of states are 
given as state predicates; e.g. the expression 'un- 
ripe' is used to denote a state such that no event 
of ripening (R) has occurred (yet). Note that, as 
(11) shows, 'ripe' may be used to scalar implicate 
but not to entail 'not overripe'; the event order- 
ing of the causal event chain serves as the salient 
order for the scalar implicature. The expected en- 
tailments follow from the constraints represented 
in Figure 3. 
l l .a. It's ripe. In fact, it's just right for eating. 
b. It's ripe. In fact, it's overripe/too ripe. 
6 Comparison of Scalar and 
Normal State Implicature 
These two classes of conversational impli- 
cature have some interesting similarities and dif- 
ferences. 
First, licensing a scalar implicature requires 
the mention of some specific value in an ordering, 
while licensing a normal state implicature requires 
the absence of the mention of any state. For ex- 
ample, consider a situation where S is a restaurant 
customer; H is a waiter; S and H have mutual be- 
lief of the salience of an ordering such that warm 
precedes boiling hot; and, S and H have mutual 
belief of S's plan to make tea by steeping a tea 
bag in boiling hot water. 
14.a. I'd like a pot of water. 
b. I'd like a pot of warm water. 
c. I'd like a pot of boiling hot water. 
d. I'd like a pot of warm but not boiling 
hot water. 
In this situation, use of (14a) would license 
the normal state implicature (14c) but no scalar 
implicature. IIowever, use of (14b) would license 
the scalar implicature (14d) but not the normal 
state implicature (14c). (In fact, use of 'warm' in 
(14b) would cancel (14c), as well as be confusing 
to H due to its inconsistency with H's belief about 
S's intention to make tea.) Thus, at least in this 
example, scalar and normal state implicature are 
mutually exclusive. 
Second, saliency and order relations play a 
role in both. Scalar implicature is based on the 
salience of a partially ordered set (from any do- 
main). Normal state implicature is based on the 
salience of a plan; one of a plan's preconditions 
may involve a normal state, which can be defined 
in terms of a causal event chain. 
normal state implicature, while the presence of a 
qualification (the marked case), blocks it (thereby 
allowing the scalar implicature to be conveyed). 
Finally, Herskovits \[Her87\] addresses the 
problem that the meaning of a locative expression 
varies with the context of its use. Her approach 
is to specify "a set of characteristic constraints - 
constraints that must hold for the expression to be 
used truly and appropriately under normal condi- 
tions. " (p. 20) Her constraints appear to include 
stereotypes and plan-independent ormal states; 
normal is distinguished from prototypical; and the 
constraints may include speaker purpose. 
7 Re la ted  Work 
This work is related to work in several dif- 
ferent areas. 
First, one of the goals of research on non- 
monotonic reasoning 16 has been the use of default 
information. The classic example, that if some- 
thing is a bird then it can fly, appears to in- 
volve all three notions that I have distinguished 
here; namely, stereotype, plan-independent or- 
mal state, and normal state with respect o a plan. 
(It is a stereotype that birds are genetically suited 
for flight; a plan-independent normal state that a 
bird is alive or uninjured; and a normal state with 
respect o a plan to send a message via carrier pi- 
geon that the bird be able to fly.) Also, I have 
shown that the calculation of normal state impli- 
cature is based only on the third notion, i:e., that 
certain "defaults" are context-dependent. 
In another area, work has been done on 
using knowledge of a speaker's plans to fill in 
missing information to interpret incomplete utter- 
ances, e.g. sentence fragments \[AP80\] and ellipsis 
\[car89\]. 
As for related work on conversational im- 
plicature, both \[iior84\] and \[ALS1\] describe prag- 
matic inferences where what is conveyed by an 
utterance is more precise than its literal mean- 
ing. They claim that such inferences are based 
on a principle of speaker economy and exploit the 
speaker's and hearer's hared beliefs about stereo- 
types. Also, Horn points out that an unmarked ex- 
pression tends to be associated with the stereotype 
of an extension and its marked counterpart with 
the non-stereotype. Roughly, this corresponds to 
my observation regarding (14), that the absence 
of a qualification (the unmarked case) licenses a 
lOFor a survey, see \[GinS7\]. 94 
8 Conc lus ions  
This paper has provided a convention for 
identifying normal state implicatures. Normal 
state implicature permits a speaker to omit certain 
information from an indefinite description in cer- 
tain situations without being misunderstood. The 
convention is that if S makes a request hat tt per- 
form an action A on an E, and if S and H mutually 
believe that S has a plan whose success depends 
upon the E being in the normal state N with re- 
spect to that plan, and that S's request is a step 
of that plan, then S is implicating a request for S 
to do A on an E in state N. 
In order to specify the convention for nor- 
mal state implicature, I distinguished the notions 
of stereotype, plan-independent normal state, and 
normal state with respect o a plan. This distinc- 
tion may prove useful in solving other problems in 
the description of how language is used. Also, a 
representation for states, in terms of causal event 
chains, was proposed. 
The convention I have provided is impor- 
tant both in natural language generation and in- 
terpretation. In generation, a system needs to 
consider what normal state implicatures would be 
licensed by its use of an indefinite description. 
These implicatures determine what qualifications 
may be omitted (namely, those which would be im- 
plicated) and what ones are required (those which 
are needed to block implicatures that the system 
does not wish to convey), lr In interpretation, a 
system may need to understand what a user has 
17This latter behavior is an example of Joshi's revised 
Maxim of Quality: "If you, the speaker, plan to say any- 
thing which may imply for the hearer something you believe 
to be false, then provide further information to block it." 
\[JosS2\] 
implicated in order to provide a cooperative re- 
sponse. For instance, if during a dialogue a sys- 
tem has inferred that a user has a plan to make an 
immediate delivery, and then the user says (15a), 
then if the system knows that the only truck in 
terminal A is out of service, it would be uncoop- 
erative for the system to reply with (15b) alone; 
(15c) should be added for a more cooperative r - 
sponse. 
15.a. User: Is there a truck in terminal A? 
b. System: Yes, there is one 
c. but it's out of service. 
This work may be extended in at least two 
ways. First, it would be interesting to investigate 
what plan inference algorithms are necessary in or- 
der to recognize normal state implicatures in ac- 
tual dialogue. Another question is whether the 
notion of normal state implicature can be gener- 
alized to account for other uses of language. 
9 Acknowledgments  
An earlier version of this work was done 
at the University of Pennsylvania, partially sup- 
ported by DARPA grant N00014-85-K0018. My 
thanks to the people there, particularly Bonnie 
Webber and Ellen Prince. Thanks to my col- 
leagues at SAS Institute Inc., Cary, N. C., for their 
moral support while much of this paper was being 
written. The final draft was prepared at the Uni- 
versity of Delaware; thanks to the people there, 
especially Sandra Carberry and K. Vijayashanker. 
References 
\[AL81\] Jay David Atlas and Stephen C. Levin- 
son. It-clefts, informativeness, and log- 
ical form: radical pragmatics (revised 
standard version). In Peter Cole, editor, 
Radical Pragmatics, pages 1-62, Aca- 
demic Press, N. Y., 1981. 
lAP80\] James F. Allen and C. Raymond Per- 
rault. Analyzing intention in utterances. 
Artificial Intelligence, 15:143-178, 1980. 
\[c~881 Sandra Carberry. Modeling the user's 
plans and goals. Computational Linguis- 
tics, 14(3):23-37, 1988. 95 
\[Car80\] 
\[FN71\] 
\[Gin87\] 
\[Gri75\] 
\[Her87\] 
\[HH831 
\[Hir85\] 
\[Hot84\] 
\[JosS2\] 
\[Lan87\] 
\[McC87\] 
Sandra Carberry. A pragmatics-based 
approach to ellipsis resolution. Compu- 
tational Linguistics, 15(2):75-96, 1989. 
R. E. Fikes and N. J. Nilsson. Strips: a 
new approach to the application of the- 
orem proving to problem solving. Artifi- 
cial Intelligence, 2:189-208, 1971. 
Matthew L. Ginsberg. Readings in Non- 
monotonic Reasoning. Morgan Kauf- 
mann, Los Altos, California, 1987. 
H. Paul Grice. Logic and conversation. 
In P. Cole and J. L. Morgan, editors, 
Syntax and Semantics III: Speech Acts, 
pages 41-58, Academic Press, N.Y., 
1975. 
Annette Herskovits. Language and Spa- 
tial Cognition. Cambridge University 
Press, Cambridge, England, 1987. 
J. Hurford and B. Heasley. Semantics: 
A Coursebook. Cambridge University 
Press, Cambridge, England, 1983. 
Julia Bell Hirschberg. A Theory 
of Scalar Implicature. Technical Re- 
port MS-CIS-85-56, Department of 
Computer and Information Science, Uni- 
versity of Pennsylvania, 1985. 
Larry Horn. Toward a new taxonomy 
for pragmatic inference: q-based and r- 
based implicature. In D. Schiffrin, ed- 
itor, GURT '84. Meaning, Form and 
Use in Context: Linguistic Applica- 
tions, pages 11--42, Georgetown Univer- 
sity Press, Washington, D. C., 1984. 
Aravind K. Joshi. Mutual beliefs in 
question-answer systems. In N. Smith, 
editor, Mutual Beliefs, pages 181-197, 
Academic Press, New York, 1982. 
Amy Lansky. A representation of par- 
allel activity based on events, struc- 
ture, and causality. In M. P. Georgeff 
and A. Lansky, editors, Reasoning about 
Actions and Plans: Proceedings of the 
1986 Workshop, pages 123-160, Morgan 
Kaufmann, 1987. 
John McCarthy. Circumscription - a 
form of non-monotonic reasoning. In 
Matthew L. Ginsberg, editor, Readings 
in Nonmonotonic Reasoning, pages 145- 
152, Morgan Kaufmann, 1987. 
\[PASO\] 
\[SA77\] 
\[Sch77\] 
\[Web83\] 
R. Perrault and J. Allen. A plan-based 
analysis of indirect speech acts. Amer- 
ican Journal of Computational Linguis- 
tics, 6(3-4):167-182, 1980. 
Roger C. Schank and Robert P. Abel- 
son. Scripts, Plans, Goals and Under- 
standing. Lawrence Erlbaum Associates, 
Hinsdale, New Jersey, 1977. 
Stephen P. Schwartz. Introduction. In 
Stephen P. Schwartz, editor, Naming, 
Necessity, and Natural Kinds, pages 13- 
41, Cornell University Press, 1977. 
Bonnie L. Webber. So what can we talk 
about now? In Jones K. S. Grosz, B. and 
B. L. Webber, editors, Readings in Nat- 
ural Language Processing, Morgan Kauf- 
mann, Los Altos, California, 1983. 
unborn ,~  live ,~  dead 
Figure 1: Causal event chain for parrot 
unfinished~ready-to-use~ 
Figure 2: Causal event chain for vase 
\ Y 
Y ripe 
Fruit-for-eating = element ype 
events 
R \[Ripen\] 
0 \[Become Overripe\] 
constraints 
1. R--.  O 
end element ype 
unripe(x) = --, (3 r:x.R) occurred(r) 
just-ripe(x) =- (3 r:x.a) occurred(r) A
-~((5o:x.O) occurred(o) A r --* o) 
overripe(x) -- (3 o:x.O) occurred(o) 
ripe(x) _ (3 r:x.R) occurred(r) 
Figure 3: Causal event chain for fruit ripening 
96 
