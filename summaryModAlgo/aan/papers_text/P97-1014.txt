Centering in-the-Large: 
Computing Referential Discourse Segments 
Udo Hahn & Michael Strube 
Computat iona l  Linguist ics Research Group 
Freiburg University, Werthmannplatz  1 
D-79085 Freiburg, Germany 
http://www.coling.uni-freiburg.de/ 
Abstract 
We specify an algorithm that builds up a hi- 
erarchy of referential discourse segments from 
local centering data. The spatial extension and 
nesting of these discourse segments constrain 
the reachability of potential antecedents of an 
anaphoric expression beyond the local level 
of adjacent center pairs. Thus, the centering 
model is scaled up to the level of the global 
referential structure of discourse. An empiri- 
cal evaluation of the algorithm is supplied. 
1 Introduction 
The centering model (Grosz et al, 1995) has evolved as 
a major methodology for computational discourse analy- 
sis. It provides imple, yet powerful data structures, con- 
straints and rules for the local coherence of discourse. As 
far as anaphora resolution is concerned, e.g., the model 
requires to consider those discourse ntities as potential 
antecedents for anaphoric expressions in the current ut- 
terance Ui, which are available in the forward-looking 
centers of the immediately preceding utterance Ui- 1. No 
constraints or rules are formulated, however, that ac- 
count for anaphoric relationships which spread out over 
non-adjacent u terances. Hence, it is unclear how dis- 
course elements which appear in utterances preceding 
utterance Ui-1 are taken into consideration as potential 
antecedents for anaphoric expressions in Ui. 
The extension of the search space for antecedents is by 
no means a trivial enterprise. A simple linear backward 
search of all preceding centering structures, e.g., may 
not only turn out to establish illegal references but also 
contradicts the cognitive principles underlying the lim- 
ited attention constraint (Walker, 1996b). The solution 
we propose starts from the observation that additional 
constraints on valid antecedents are placed by the global 
discourse structure previous utterances are embedded in. 
We want to emphasize from the beginning that our pro- 
posal considers only the referential properties underlying 
the global discourse structure. Accordingly, we define 
the extension of referential discourse segments (over sev- 
eral utterances) and a hierarchy of referential discourse 
segments (structuring the entire discourse). 1 The algo- 
rithmic procedure we propose for creating and manag- 
ing such segments receives local centering data as input 
and generates a sort of superimposed index structure by 
which the reachability of potential antecedents, in par- 
ticular those prior to the immediately preceding utter- 
ance, is made explicit. The adequacy of this definition 
is judged by the effects centered iscourse segmentation 
has on the validity of anaphora resolution (cf. Section 5 
for a discussion of evaluation results). 
2 Global Discourse Structure 
There have been only few attempts at dealing with the 
recognition and incorporation of discourse structure be- 
yond the level of immediately adjacent utterances within 
the centering framework. Two recent studies deal with 
this topic in order to relate attentional and intentional 
structures on a larger scale of global discourse coher- 
ence. Passonneau (1996) proposes an algorithm for the 
generation of referring expressions and Walker (1996a) 
integrates centering into a cache model of attentional 
state. Both studies, among other things, deal with the 
supposition whether a correlation exists between partic- 
ular centering transitions (which were first introduced 
by Brennan et al (1987); cf. Table 1) and intention- 
based discourse segments. In particular, the role of 
SHIFT-type transitions i examined from the perspective 
of whether they not only indicate a shift of the topic be- 
tween two immediately successive utterances but also 
signal (intention-based) segment boundaries. The data 
in both studies reveal that only a weak correlation be- 
tween the SHIFT transitions and segment boundaries can 
be observed. This finding precludes a reliable predic- 
tion of segment boundaries based on the occurrence of 
1 Our notion of referential discourse segment should not be 
confounded with the intentional one originating from Grosz & 
Sidner (1986), for reasons discussed inSection 2. 
104 
SHIFTS and vice versa. In order to accommodate to these 
empirical results divergent solutions are proposed. Pas- 
sonneau suggests that the centering data structures need 
to be modified appropriately, while Walker concludes 
that the local centering data should be left as they are 
and further be complemented by a cache mechanism. 
She thus intends to extend the scope of centering in ac- 
cordance with cognitively plausible limits of the atten- 
tional span. Walker, finally, claims that the content of 
the cache, rather than the intentional discourse segment 
structure, determines the accessibility of discourse nti- 
ties for anaphora resolution. 
c~(v.) = cdu.-~) c~(u.) # 
OR Cb(Vn-1) undef. Cb(Vn-1) 
Cb(Un) = CONTINUE (C) SMOOTH-SHIFT (SS) c~(u.) 
cb(u.) # RETAIN (R) ROUGH-SHIFT (RS) c~(u.) 
Table h Transition Types 
As a working hypothesis, for the purposes of anaphora 
resolution we subscribe to Walker's model, in particular 
to that part which casts doubt on the hypothesized de- 
pendency of the attentional from the intentional structure 
of discourse (Grosz & Sidner, 1986, p. 180). We diverge 
from Walker (1996a), however, in that we propose an al- 
ternative to the caching mechanism, which we consider 
to be methodologically more parsimonious and, at least, 
to be equally effective (for an elaboration of this claim, 
cf. Section 6). 
The proposed extension of the centering model builds 
on the methodological framework of functional center- 
ing (Strube & Hahn, 1996). This is an approach to cen- 
tering in which issues such as thematicity or topicality 
are already inherent. Its linguistic foundations relate the 
ranking of the forward-looking centers and the functional 
information structure of the utterances, a notion origi- 
nally developed by Dane~ (1974). Strube & Hahn (1996) 
use the centering data structures to redefine Dane~'s tri- 
chotomy between given information, theme and rheme 
in terms of the centering model. The Cb(Un), the most 
highly ranked element of C! (Un-1) realized in Un, cor- 
responds to the element which represents the given in- 
formation. The theme of Un is represented by the pre- 
ferred center Cp (Un), the most highly ranked element of 
C! ( Un ). The theme/rheme hierarchy of Un corresponds 
to the ranking in the C! s. As a consequence, utterances 
without any anaphoric expression do not have any given 
elements and, therefore, no Cb. But independent of the 
use of anaphoric expressions, each utterance must have a 
theme and a C! as well. 
The identification of the preferred center with the 
theme implies that it is of major relevance for determin- 
ing the thematic progression of a text. This is reflected in 
our reformulation of the two types of thematic progres- 
sion (TP) which can be directly derived from centering 
data (the third one requires to refer to conceptual gener- 
alization hierarchies and is therefore beyond the scope of 
this paper, cf. Dane~ (1974) for the original statement): 
1. TP with a constant heme: Successive utterances 
continuously share the same Cp. 
2. TP with linear thematization f rhemes: An element 
of the C! (Ui- 1 ) which is not the Cp (Ui- 1 ) appears 
in Ui and becomes the Cp(Ui) after the processing 
of this utterance. 
Cf (V i -1 )  : \[ c 1 . . . . .  e j  . . . . .  cs \] 
C~(V i )  : \[ Cl . . . . .  ck . . . . .  et \] 
Cf (U i -1 ) :  \ [e l  . . . . .  c j  . . . . .  cs \ ]  l< j<s  
Cf (Vd:  \ [e l  ..... ek ..... e~l 
Table 2: Thematic Progression Patterns 
Table 2 visualizes the abstract schemata of TP pat- 
terns. In our example (cf. Table 8 in Section 4), U1 to Ua 
illustrate the constant theme, while U7 to U10 illustrate 
the linear thematization f rhemes. In the latter case, 
the theme changes in each utterance, from "Handbuch" 
(manual) via "Inhaltsverzeichnis" (table of contents) to 
"Kapitel" (chapter) etc. Each of the new themes are in- 
troduced in the immediately preceding utterance so that 
local coherence between these utterances i established. 
Daneg (1974) also allows for the combination and re- 
cursion of these basic patterns; this way the global the- 
matic coherence of a text can be described by recurrence 
to these structural patterns. These principles allow for 
a major extension of the original centering algorithm. 
Given a reformulation of the TP constraints in center- 
ing terms, it is possible to determine referential segment 
boundaries and to arrange these segments in a nested, 
i.e., hierarchical manner on the basis of which reacha- 
bility constraints for antecedents can be formulated. Ac- 
cording to the segmentation strategy of our approach, the 
Cp of the end point (i.e., the last utterance) of a discourse 
segment provides the major theme of the whole segment, 
one which is particularly salient for anaphoric reference 
relations. Whenever a relevant new theme is established, 
however, it should reside in its own discourse segment, 
either embedded or in parallel to another one. Anaphora 
resolution can then be performed (a) with the forward- 
looking centers of the linearly immediately preceding ut- 
terance, (b) with the forward-looking centers of the end 
point of the hierarchically immediately reachable dis- 
course segment, and (c) with the preferred center of the 
end point of any hierarchically reachable discourse seg- 
ment (for a formalization of this constraint, cf. Table 4). 
105 
3 Computing Global Discourse Structure 
Prior to a discussion of the algorithmic procedure for hy- 
pothesizing discourse segments based on evidence from 
local centering data, we will introduce its basic build- 
ing blocks. Let x denote the anaphoric expression under 
consideration, which occurs in utterance Ui associated 
with segment level s. The function Resolved(x, s, Us) 
(cf. Table 3) is evaluated in order to determine the proper 
antecedent ante for x. It consists of the evaluation of 
a teachability predicate for the antecedent on which we 
will concentrate here, and of the evaluation of the predi- 
cate lsAnaphorFor which contains the linguistic and con- 
ceptual constraints imposed on a (pro)nominal anaphor 
(viz. agreement, binding, and sortal constraints) or a tex- 
tual ellipsis (Hahn et al, 1996), not an issue in this paper. 
The predicate lsReachable (cf. Table 4) requires ante to 
be reachable from the utterance Us associated with the 
segment level s. 2 Reachability is thus made dependent 
on the segment structure DS of the discourse as built 
up by the segmentation algorithm which is specified in 
Table 6. In Table 4, the symbol "=str" denotes tring 
equality, N the natural numbers. We also introduce as a 
notational convention that a discourse segment is identi- 
fied by its index s and its opening and closing utterance, 
viz. DS\[s.beg\] and DS\[s.end\], respectively. Hence, we 
may either identify an utterance Ui by its linear text in- 
dex, i, or, if it is accessible, with respect o its hierarchi- 
cal discourse segment index, s (e.g., cf. Table 8 where 
U3 = UDs\[1.end\] or U13 = UDs\[3.end\]). The discourse 
segment index is always identical to the currently valid 
segment level, since the algorithm in Table 6 implements 
a stack behavior. Note also that we attach the discourse 
segment index s to center expressions, e.g., Cb(s, Us). 
Resolved(x, s Ui) := 
l ante if  IsReachable(ante, s, Ui) 
A IsAnaphorFor(x, ante) 
under else 
Table 3: Resolution of Anaphora 
IsReachable(ante, s, Ui ) 
i f  ante 6 C/(s, Ui-1) 
else i f  ante E C/(s - 1, Uosts_,.~,a\]) 
else if  (3v E N : ante =~tr Cp(v, UDsI .... a\]) 
^ v < (s  - 1)) 
A (-~Sv' 6 N :  ante =,t , -  Cp(v',UDst~,.~ndl) 
A v < v') 
Table 4: Reachability of the Anaphoric Antecedent 
Finally, the function Lift(s, i) (cf. Table 5) determines 
the appropriate discourse segment level, s, of an utter- 
2The Cf lists in the functional centering model are totally 
ordered (Strobe & Hahn, 1996, p.272) and we here implicitly 
assume that they are accessed inthe total order given. 
ance Ui (selected by its linear text index, i). Lift only 
applies to structural configurations in the centering lists 
in which themes continuously shift at three different con- 
secutive segment levels and associated preferred centers 
at least (cf. Table 2, lower box, for the basic pattern). 
Lift(s, i) := 
L i f t ( s -  1, i -  1) i f  
s>2Ai>3 
^ c.(s,u,_~) # c~(~ - 1,u,_~) 
^ c~(s - I, u,_~) # c.(s - 2, u,_~) 
^ c~(s,u,_,) ? c j ( s -  1,u,_~) 
8 else 
Table 5: Lifting to the Appropriate Discourse Segment 
Whenever a discourse segment is created, its starting 
and closing utterances are initialized to the current po- 
sition in the discourse. Its end point gets continuously 
incremented as the analysis proceeds until this discourse 
segment DS  is ultimately closed, i.e., whenever another 
segment DS' exists at the same or a hierarchically higher 
level of embedding such that the end point of DS' ex- 
ceeds that of the end point of DS. Closed segments are 
inaccessible for the antecedent search. In Table 8, e.g., 
the first two discourse segments at level 3 (ranging from 
U5 to U5 and Us to Ul l  ) are closed, while those at level 
1 (ranging from U1 to U3), level 2 (ranging from U4 to 
UT) and level 3 (ranging from U12 to U13) are open. 
The main algorithm (see Table 6) consists of three ma- 
jor logical blocks (s and Ui denote the current discourse 
segment level and utterance, respectively). 
1. Continue Current Segment. The Cp(s, Ui-1) is 
taken over for Ui. If Ui-1 and Ui indicate the end 
of a sequence in which a series of thematizations of 
rhemes have occurred, all embedded segments are 
lifted by the function Lift to a higher level s'. As a 
result of lifting, the entire sequence (including the 
final two utterances) forms a single segment. This 
is trivially true for cases of a constant theme. 
2. Close Embedded Segment(s). 
(a) Close the embedded segment(s) and continue 
another, already existing segment: If Ui does 
not include any anaphoric expression which is 
an element of the Cf (s, Ui-O, then match the 
antecedent in the hierarchically reachable seg- 
ments. Only the Cp of the utterance at the end 
point of any of these segments is considered 
a potential antecedent. Note that, as a side 
effect, hierarchically lower segments are ulti- 
mately closed when a match at higher segment 
levels succeeds. 
(b) Close the embedded segment and open a new, 
parallel one: If none of the anaphoric ex- 
pressions under consideration co-specify the 
106 
Cp(8  - 1, U\[8_l.end\]), then the entire C! at 
this segment level is checked for the given ut- 
terance. If an antecedent matches, the segment 
which contains Ui- 1 is ultimately closed, since 
Ui opens a parallel segment at the same level of 
embedding. Subsequent anaphora checks ex- 
clude any of the preceding parallel segments 
from the search for a valid antecedent and just 
visit the currently open one. 
(c) Open new, embedded segment: If there is no 
matching antecedent in hierarchically reach- 
able segments, then for utterance Ui a new, em- 
bedded segment is opened. 
3. Open New, Embedded Segment. If none of the 
above cases applies, then for utterance Ui a new, 
embedded segment is opened. In the course of pro- 
cessing the following utterances, this decision may 
be retracted by the function Lift. It serves as a kind 
of "garbage collector" for globally insignificant dis- 
course segments which, nevertheless, were reason- 
able from a local perspective for reference resolu- 
tion purposes. Hence, the centered iscourse seg- 
mentation procedure works in an incremental way 
and revises only locally relevant, yet globally irrel- 
evant segmentation decisions on the fly. 
s := l  
i :=1  
DS\[s.be9\] :=i 
DS\[s.end\] := i 
while -- end of text 
i := i+1 
n := {Resolved(x,s, Ui) lx E U~} 
i f3 r  ? T~ : r ~---str Cp(s, Ui-1) (1) 
then s' 1= s 
i' := i 
DS\[Lift(s', i').end\] := i 
else i f~3r E Tt : r ? Cl(s, Ui_l ) (2a) 
then found := FALSE 
k :~s  
while-,found A (k > 1) 
k :=k-1  
i_f3r ? 7?.: r =s,r Cp(k, Utk.~,,~) 
then s := k 
DS\[s.end\] := i 
found := TRUE 
else if k = s - 1 (2b) 
then if3r ?~ : r ?  
Cs(k, Utk.o,,,~) 
then DS\[s.beg\] :=i 
DS\[s.end\] := i 
found := TRUE 
if -,found (2e) 
then s := s + 1 
DS\[s.beg\] := i 
DS\[s.end\] := i 
else s := s q- 1 (3) 
DS\[s.beg\] := i 
DS\[s.end\] := i 
Table 6: Algorithm for Centered Segmentation 
4 A Sample Text Segmentation 
The text with respect to which we demonstrate he work- 
ing of the algorithm (see Table 7) is taken from a German 
computer magazine (c't, 1995, No.4, p.209). For ease 
of presentation the text is somewhat shortened. Since 
the method for computing levels of discourse segments 
depends heavily on different kinds of anaphoric expres- 
sions, (pro)nominal anaphors and textual ellipses are 
marked by italics, and the (pro)nominal naphors are un- 
derlined, in addition. In order to convey the influence of 
the German word order we provide a rough phrase-to- 
phrase translation of the entire text. 
The centered segmentation a alysis of the sample text 
is given in Table 8. The first column shows the linear text 
index of each utterance. The second column contains 
the centering data as computed by functional centering 
(Strube & Hahn, 1996). The first element of the C I, the 
preferred center, Cp, is marked by bold font. The third 
column lists the centering transitions which are derived 
from the Cb/C! data of immediately successive utter- 
ances (cf. Table 1 for the definitions). The fourth column 
depicts the levels of discourse segments which are com- 
puted by the algorithm in Table 6. Horizontal ines in- 
dicate the beginning of a segment (in the algorithm, this 
corresponds to a value assignment to DS\[s.beg\]). Verti- 
cal lines show the extension of a segment (its end is fixed 
by an assignment to DS\[s.end\]). The fifth column indi- 
cates which block of the algorithm applies to the current 
utterance (cf. the right margin in Table 6). 
The computation starts at U1, the headline. The 
C1(Ux ) is set to "1260" which is meant as an abbre- 
viation of "Brother HL-1260". Upon initialization, the 
beginning as well as the ending of the initial discourse 
segment are both set to "1". U2 and Ua simply con- 
tinue this segment (block (1) of the algorithm), so Lift 
does not apply. The C v is set to "1260" in all utter- 
ances of this segment. Since U4 does neither contain any 
anaphoric expression which co-specifies the Cv(1 ,Ua) 
(block (1)) nor any other element of the 67/( 1, U3) (block 
(2a)), and as there is no hierarchically preceding seg- 
ment, block (2c) applies. The segment counter s is in- 
cremented and a new segment at level 2 is opened, set- 
ting the beginning and the ending to "4". The phrase 
"das diinne Handbiichlein" (the thin leaflet) in U5 does 
not co-specify the C v (2, U4) but co-specifies an element 
of the C! (2, U4) instead (viz. "Handbuch" (manual)). 
Hence, block (3) of the algorithm applies, leading to 
the creation of a new segment at level 3. The anaphor 
"Handbuch" (manual) in U6 co-specifies the Cv(3 ,Us). 
Hence block (1) applies (the occurrence of "1260" in 
CI(U5 ) is due to the assumptions specified by Strube 
& Hahn (1996)). Given this configuration, the func- 
tion Lift lifts the embedded segment one level, so the 
107 
(1) 
(2) 
(3) 
(4) 
(5) 
(6) 
(7) 
Brother HL- 1260 
Ein Detail fiillt schon beim ersten Umgang mit dem 
grogen Brother auf: 
One particular - is already noticed - in the first approach 
to - the big Brother. 
Im Betrieb macht e._gr durch ein kr~iftiges Arbeitsger~usch 
auf sich aufmerksam, das auch im Stand-by-Modus noch 
gut vemehmbar ist. 
In operation - draws - it - with a heavy noise level - 
attention to itself-  which - also - in the stand-by mode -
is still well audible. 
F~r Standard-InstaUationen kommt man gut ohne Hand- 
buch aus. 
As far as standard installations are concerned- gets - one 
- well - by - without any manual. 
Zwar ed~iutert das dSnne Handbiichlein die Bedienung 
der Hardware anschaulich und gut illustriert. 
Admittedly, gives - the thin leaflet- the operation of the 
hardware- aclear description of - and - well illustrated. 
Die Software-Seite wurde im Handbuch dagegen 
stiefmSttedich behandelt: 
The software part - was - in the manual- however - like 
a stepmother- treated: 
bis auf eine karge Seite mit einem Inhaltsverzeichnis zum 
HP-Modus sucht man vergebens weitere Informationen. 
except for one meagre page- containing the table of con- 
tents for the HP mode - seeks- one-  in vain-  for further 
information. 
(8) Kein Wander: unter dem lnhaltsverzeichnis steht der lap- 
idare Hinweis, man m6ge sich die Seiten dieses Kapitels 
doch bitte yon Diskette ausdrucken- Frechheit. 
No wonder: beneath the table of contents - one finds the 
terse instruction, one should - oneself-  the pages of this 
section - please - from disk - print out - - impertinence. 
(9) Ohne diesen Ausdruck sucht man vergebens nach einem 
Hinweis darauf, warum die Auto-Continue-Funktion n 
der PostScript-Emulation nicht wirkt. 
Without his print-out, looks - one - in vain - for a hint - 
why - the auto-continue-function - in the PostScript em- 
ulation - does not work. 
(10) Nach dem Einschalten zeigt das LC-Display an, dab diese 
praktische Hilfsfunktion icht aktiv ist; 
After switching on - depicts - the LC display - that - this 
practical help function - not active - is; 
(11) si__.ge tiberwacht den Dateientransfer vom Computer. 
it monitors the file transfer from the computer. 
(12) Viele der kleinen Macken verzeiht man dem HL-1260 
wenn man erste Ausdrucke in H~inden h~ilt. 
Many of the minor defects - pardons - one - the 
HL-1260, when - one - the first print outs - holds in 
\[one' s\] hands. 
(13) Gerasterte Grauflftchen erzeugt der Brother sehr homogen 
Raster-mode grey-scale areas - generates - the Brother- 
very homogeneously... 
Table 7: Sample Text 
segment which ended with U4 is now continued up to 
U6 at level 2. As a consequence, the centering data of 
U5 are excluded from further consideration as far as the 
co-specification by any subsequent anaphoric expression 
is concerned. Uz simply continues the same segment, 
since the textual ellipsis "Seite" (page) refers to "Hand- 
buch" (manual). The utterances U8 to U10 exhibit a typ- 
ical thematization-of-the-rhemes pattern which is quite 
common for the detailed description of objects. (Note 
the sequence of SHIFT transitions.) Hence, block (3) 
of the algorithm applies to each of the utterances and, 
correspondingly, new segments at the levels 3 to 5 are 
created. This behavior breaks down at the occurrence 
of the anaphoric expression "sie" (it) in Uxl which co- 
specifies the Cp ( 5, Ul o ), viz. "auto-continue function", 
denoted by another anaphoric expression, namely "Hil- 
fsfunktion" (help function) in U10. Hence, block (1) ap- 
plies. The evaluation of  Lift succeeds with respect to 
two levels of  embedding. As a result, the whole se- 
quence is lifted up to level 3 and continues this segment 
which started at the discourse lement "lnhaltsverzeich- 
his" (list o f  contents). As a result of applying Lift, the 
whole sequence is captured in one segment. U12 does 
not contain any anaphoric expression which co-specifies 
an element of  the C!  (3, U11), hence block (2) of  the al- 
gorithm applies. The anaphor "HL-1260" does not co- 
specify the Cp of the utterance which represents the end 
of the hierarchically preceding discourse segment (UT), 
but it co-specifies an element of the C! (2, UT). The im- 
mediately preceding segment is ultimately closed and a 
parallel segment is opened at UI~ (cf. block (2b)). Note 
also that the algorithm does not check the C! (3, U10) de- 
spite the fact that it contains the antecedent of  "1260". 
However, the occurrences of "1260" in the C fs  of  U9 
and Ux0 are mediated by textual ellipses. I f  these ut- 
terances contained the expression "1260" itself, the al- 
gorithm would have built a different discourse structure 
and, therefore, "1260" in U10 were reachable for the 
anaphor in Ulz. Segment 3, finally, is continued by Ulz. 
5 Empi r i ca l  Eva luat ion  
In this section, we present some empirical data concern- 
ing  the centered segmentation algorithm. Our study was 
based on the analysis of twelve texts from the informa- 
tion technology domain (IT), of one text from a Ger- 
108 
U~ 
(1) Cb: 
Cf." 
(2) Cb: 
Cf: 
(3) Cb: 
Cf: 
(4) Cb: 
Cf." 
(5) Cb: 
Cf: 
(6) Cb: 
Cf: 
(7) Cb: 
Cf: 
(8) Cb: 
Cf: 
(9) Cb: 
Cf: 
(10) Cb: 
Cf: 
(11) Cb: 
Cf: 
(12) Cb: 
Cf: 
(13) Cb: 
Cf: 
Centering Data Trans. 
\[1260\] 
1260 C 
\[1260, Umgang, Detail\] 
1260 C 
\[1260, Betrieb, Arbeitsger~usch, Stand-by-Modus\] 
\[Standard-Installation, Ha dbuch\] 
Handbuch C 
\[Handbueh, 1260, Hardware, Bedienung\] 
Handbuch C 
\[Handbuch, 1260, Software\] 
Handbuch C 
\[Handbueh, Seite, 1260, HP-Modus, 
Inhaltsverzeichnis, Informationen\] 
Inhaltsverzeichnis SS 
\[Inhaltsverzeiehnis, H nweis, Seiten, Kapitel, 
Diskette, Frechheit\] 
Kapitel SS 
\[Kapitel, Ausdmck, Hinweis, 1260, 
Auto-Continue-Funktion, PostScript-Emulation\] 
1260 RS 
\[Auto-Continue-Funktion, 1260, LC-Display\] 
Auto-Continue-Funktion SS 
\[Auto-Continue-Funktion, Dateien-Transfer, 
Computer\] 
\[1260, Macken, Ausdmck\] 
1260 C 
\[1260, Graufl~ichen\] 
man news magazine (Spiegel) 3, and of two literary texts 4
(Lit). Table 9 summarizes the total numbers of anaphors, 
textual ellipses, utterances, and words in the test set. 
Levels of Discourse Segments 
1 2 3 4 5 
E 
496 
240 
547 
8319 
IT Spiegel 
anaphors 197 101 198 
ellipses 195 22 23 
utterances 336 84 127 
words 5241 1468 1610 
Block 
1 
1 
2e 
3 
1, Lift 
1 
I 3 
1, Lift 
2b 
Table 8: Sample of a Centered Text Segmentation Analysis 
neither specified for anaphoric antecedents in Ui, not an 
issue here, nor for anaphoric antecedents beyond Ui-1. 
In the test set, 139 anaphors (28%) and 116 textual el- 
lipses (48,3%) fall out of the (intersentential) scope of 
Lit those common algorithms. So, the problem we consider 
is not a marginal one. 
U~ 
Ui-2 
Ui-a 
Ui-4 
Ui-5 
Table 9: Test Set 
Table 10 and Table 11 consider the number of 
anaphoric and text-elliptical expressions, respectively, 
and the linear distance they have to their correspond- 
ing antecedents. Note that common centering algorithms 
(e.g., the one by Brennan et al (1987)) are specified 
only for the resolution of anaphors in Ui-1. They are 
3japan - Der Neue der alten Garde. In Der Spiegel, Nr. 3, 
1996. 
4The first two chapters of a short story by the German 
writer Heiner MOiler (Liebesgeschichte. In Heiner MOiler. 
Geschichten aus der Produktion 2. Berlin: Rotbuch Verlag, 
1974, pp.57-63) and the first chapter of a novel by Uwe Johnson 
(ZweiAnsichten. Frankfurt/Main: Suhrkamp Verlag, 1965.) 
10 
117 
28 
18 
6 
6 
Lit E 
7 32 49 
70 121 308 
14 24 66 
5 10 33 
1 5 12 
0 1 7 
1 3 12 
1 1 5 
2 1 4 
Ui-~ to Ui-lO 8 
Ui-l, to Ui-15 3 
Ui-l~ to U,-2o 1 
Table 10: Anaphoric Antecedent in Utterance U~ 
Table 12 and Table 13 give the success rate of the 
centered segmentation algorithm for anaphors and tex- 
tual ellipses, respectively. The numbers in these tables 
indicate at which segment level anaphors and textual el- 
lipses were correctly resolved. The category of errors 
109 
U/-1 
Ui-2 
Ui-3 
Ui-4 
Ui-5 
Ui-6 to Ui-lo 
Ui-u to Ui-15 
IT Spiegel Lit E 
94 15 15 124 
42 6 8 56 
16 0 0 16 
14 0 0 14 
8 0 0 8 
14 1 0 15 
7 0 0 7 
Table 11: Elliptical Antecedent in Utterance U
covers erroneous analyses the algorithm produces, while 
the one for false positives concerns those resolution re- 
sults where a referential expression was resolved with 
the hierarchically most recent antecedent but not with the 
linearly most recent (obviously, the targeted) one (both of 
them denote the same discourse ntity). The categories 
Cy(s,  Ui-1) in Tables 12 and 13 contain more elements 
than the categories Ui-1 in Tables 10 and 11, respec- 
tively, due to the mediating property of textual ellipses in 
functional centering (Strube & Hahn, 1996). 
U~ 
cI(~,U~-,) 
Cp(s - 1, UDS\[,--L,,d\]) 
C/(s  - 1, UDsls--l.end\]) 
Cp(s - 2, UDS\[8-2...~) 
Cp(s - 3, UDS\[~-3.,,~) 
Cp(s - 4, UDSl,--4.,,d\]) 
c~( ~ - s, uo  s\[,-~.,,~l) 
errors 
false positives 
~ m  
10 7 32 49 
161 78 125 364 
14 9 24 47 
7 5 9 21 
1 0 1 2 
1 0 1 2 
0 0 1 1 
0 1 0 I 
3 1 5 9 
(I) (3) (7) (11) 
Table 12: Anaphoric Antecedent in Center~ 
c l  (s, U~-i ) 
Cp(s - 1, UDSi,-1.,,~d\]) 
CI(s - 1, Uosls-~.*,a\]) 
Cp(s - 2, Uosts-~.~,,~l) 
Cp(s - 3, UDats-Z.ena\]) 
errors 
IT Spiegel Lit 
156 18 17 
18 0 4 
10 1 2 
7 1 0 
3 0 0 
1 2 0 
(2) (0) (3) 
E 
191 
22 
13 
8 
3 
3 
(5) 
Table 13: Elliptical Antecedent in Centerx 
The centered segmentation algorithm reveals a pretty 
good performance. This is to some extent implied by 
the structural patterns we find in expository texts, viz. 
their single-theme property (e.g., "1260" in the sample 
text). In contrast, the literary texts in the test exhibited 
a much more difficult internal structure which resem- 
bled the multiple thread structure of dialogues discussed 
by Ros6 et al (1995). The good news is that the seg- 
mentation procedure we propose is capable of dealing 
even with these more complicated structures. While only 
one antecedent of a pronoun was not reachable given the 
superimposed text structure, the remaining eight errors 
are characterized by full definite noun phrases or proper 
names. The vast majority of these phenomena can be 
considered informationally redundant utterances in the 
terminology of Walker (1996b) for which we currently 
have no solution at all. It seems to us that these kinds 
of phrases may override text-grammatical structures as 
evidenced by referential discourse segments and, rather, 
trigger other kinds of search strategies. 
Though we fed the centered segmentation algorithm 
with rather long texts (up to 84 utterances), the an- 
tecedents of only two anaphoric expressions had to 
bridge a hierarchical distance of more than 3 levels. This 
coincides with our supposition that the overall structure 
computed by the algorithm should be rather fiat. We 
could not find an embedding of more than seven levels. 
6 Related Work 
There has always been an implicit relationship between 
the local perspective of centering and the global view 
of focusing on discourse structure (cf. the discussion in 
Grosz et al (1995)). However, work establishing an ex- 
plicit account of how both can be joined in a computa- 
tional model has not been done so far. The efforts of 
Sidner (1983), e.g., have provided a variety of different 
focus data structures to be used for reference resolution. 
This multiplicity and the on-going rowth of the number 
of different entities (cf. Suri & McCoy (1994)) mirrors 
an increase in explanatory constructs that we consider a 
methodological drawback to this approach because they 
can hardly be kept control of. Our model, due to its hier- 
archical nature implements a stack behavior that is also 
inherent o the above mentioned proposals. We refrain, 
however, from establishing a new data type (even worse, 
different ypes of stacks) that has to be managed on its 
own. There is no need for extra computations to deter- 
mine the "segment focus", since that is implicitly given 
in the local centering data already available in our model. 
A recent attempt at introducing lobal discourse no- 
tions into the centering framework considers the use of a 
cache model (Walker, 1996b). This introduces an addi- 
tional data type with its own management principles for 
data storage, retrieval and update. While our proposal 
for centered iscourse segmentation also requires a data 
structure of its own, it is better integrated into centering 
than the caching model, since the cells of segment struc- 
tures simply contain "pointers" that implement a direct 
link to the original centering data. Hence, we avoid ex- 
tra operations related to feeding and updating the cache. 
The relation between our centered segmentation algo- 
rithm and Walker's (1996a) integration of centering into 
the cache model can be viewed from two different angles. 
On the one hand, centered segmentation may be a part 
of the cache model, since it provides an elaborate, non- 
linear ordering of the elements within the cache. Note, 
however, that our model does not require any prefixed 
size corresponding to the limited attention constraint. On 
the other hand, centered segmentation may replace the 
110 
cache model entirely, since both are competing models 
of the attentional state. Centered segmentation has also 
the additional advantage of restricting the search space of 
anaphoric antecedents tothose discourse ntities actually 
referred to in the discourse, while the cache model allows 
unrestricted retrieval in the main or long-term memory. 
Text segmentation procedures (more with an informa- 
tion retrieval motivation, rather than being related to ref- 
erence resolution tasks) have also been proposed for a 
coarse-grained partitioning of texts into contiguous, non- 
overlapping blocks and assigning content labels to these 
blocks (Hearst, 1994). The methodological basis of these 
studies are lexical cohesion indicators (Morris & Hirst, 
1991) combined with word-level co-occurrence statis- 
tics. Since the labelling is one-dimensional, this approxi- 
mates our use of preferred centers of discourse segments. 
These studies, however, lack the fine-grained informa- 
tion of the contents of Cf lists also needed for proper 
reference resolution. 
Finally, many studies on discourse segmentation high- 
light the role of cue words for signaling segment bound- 
aries (cf., e.g., the discussion in Passonneau & Litman 
(1993)). However useful this strategy might be, we see 
the danger that such a surface-level description may actu- 
ally hide structural regularities at deeper levels of inves- 
tigation illustrated by access mechanisms for centering 
data at different levels of discourse segmentation. 
7 Conclusions 
We have developed a proposal for extending the cen- 
tering model to incorporate the global referential struc- 
ture of discourse for reference resolution. The hierarchy 
of discourse segments we compute realizes certain con- 
straints on the reachability of antecedents. Moreover, the 
claim is made that the hierarchy of discourse segments 
implements an intuitive notion of the limited attention 
constraint, as we avoid a simplistic, cognitively implausi- 
ble linear backward search for potentional discourse ref- 
erents. Since we operate within a functional framework, 
this study also presents one of the rare formal accounts of 
thematic progression patterns for full-fledged texts which 
were informally introduced by Dane~ (1974). 
The model, nevertheless, still has several restrictions. 
First, it has been developed on the basis of a small corpus 
of written texts. Though these cover diverse text sorts 
(viz. technical product reviews, newspaper articles and 
literary narratives), we currently do not account for spo- 
ken monologues as modelled, e.g., by Passonneau & Lit- 
man (1993) or even the intricacies of dyadic conversa- 
tions Ros6 et al (1995) deal with. Second, a thorough 
integration of the referential and intentional description 
of discourse segments still has to be worked out. 
Acknowledgments. We like to thank our colleagues in the 
CLIF group for fruitful discussions and instant support, Joe 
Bush who polished the text as a native speaker, the three anony- 
mous reviewers for their critical comments, and, in particular, 
Bonnie Webber for supplying invaluable comments to an ear- 
lier draft of this paper. Michael Strube is supported by a post- 
doctoral grant from DFG (Str 545/1-1). 
References 
Brennan, S. E., M. W. Friedman & C. J. Pollard (1987). A 
centering approach to pronouns. In Proc. of the 25 th Annual 
Meeting of the Association for Computational Linguistics; 
Stanford, Cal., 6-g July 1987, pp. 155-162. 
Dane~, E (1974). Functional sentence perspective and the orga- 
nization of the text. In E Dane~ (Ed.), Papers on Functional 
Sentence Perspective, pp. 106-128. Prague: Academia. 
Grosz, B. J., A. K. Joshi & S. Weinstein (1995). Centering: 
A framework for modeling the local coherence ofdiscourse. 
Computational Linguistics, 21 (2):203-225. 
Grosz, B. J. & C. L. Sidner (1986). Attention, intentions, 
and the structure of discourse. Computational Linguistics, 
12(3): 175-204. 
Hahn, U., K. Markert & M. Strube (1996). A conceptual rea- 
soning approach to textual ellipsis. In Proc. of the 12 th Euro- 
pean Conference on Artificial Intelligence (ECAI '96); Bu- 
dapest, Hungary, 12-16 August 1996, pp. 572-576. Chich- 
ester: John Wiley. 
Hearst, M. A. (1994). Multi-paragraph segmentation f expos- 
nd itory text. In Proc. of the 32 Annual Meeting of the As- 
sociation for Computational Linguistics; Las Cruces, N.M., 
27-30June 1994, pp. 9-16. 
Morris, J. & G. Hirst (1991). Lexical cohesion computed by 
thesaural relations as an indicator of the structure of text. 
Computational Linguistics, 17(1):21-48. 
Passonneau, R. J. (1996). Interaction of discourse structure 
with explicitness of discourse anaphoric noun phrases. In 
M. Walker, A. Joshi & E. Prince (Eds.), Centering in Dis- 
course. Preprint. 
Passonneau, R. J. & D. J. Litman (1993). Intention based seg- 
mentation: Human reliability and correlation with linguistic 
cues. In Proc. of the 318t Annual Meeting of the Associa- 
tion for Computational Linguistics; Columbus, Ohio, 22-26 
June 1993, pp. 148-155. 
Ros6, C. E, B. Di Eugenio, L. S. Levin & C. Van Ess-Dykema 
(1995). Discourse processing of dialogues with multiple 
rd  threads. In Proc. of the 33 Annual Meeting of the Asso- 
ciation for Computational Linguistics; Cambridge, Mass., 
26-30June 1995, pp. 31-38. 
Sidner, C. L. (1983). Focusing in the comprehension f definite 
anaphora. InM. Brady & R. Berwick (Eds.), Computational 
Models of Discourse, pp. 267-330. Cambridge, Mass.: MIT 
Press. 
Strobe, M. & U. Hahn (1996). Functional centering. In Proc. 
of the 34 th Annual Meeting of the Association for Computa- 
tional Linguistics; Santa Cruz, Cal., 23-28 June 1996, pp. 
270-277. 
Suri, L. Z. & K. E McCoy (1994). RAFT/RAPR and center- 
ing: A comparison and discussion of problems related to 
processing complex sentences. Computational Linguistics, 
20(2):301-317. 
Walker, M. A. (1996a). Centering, anaphora resolution, and 
discourse structure. In M. Walker, A. Joshi & E. Prince 
(Eds.), Centering in Discourse. Preprint. 
Walker, M. A. (1996b). Limited attention and discourse struc- 
ture. Computational Linguistics, 22(2):255-264. 
111 
