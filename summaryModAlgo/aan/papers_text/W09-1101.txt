Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), page 1,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
Joint Inference for Natural Language Processing
Andrew McCallum
Department of Computer Science
University of Massachusetts Amherst
Amherst, MA 01002
mccallum@cs.umass.edu
Abstract of the Invited Talk
In recent decades, researchers in natural language
processing have made great progress on well-
defined subproblems such as part-of-speech tagging,
phrase chunking, syntactic parsing, named-entity
recognition, coreference and semantic-role label-
ing. Better models, features, and learning algorithms
have allowed systems to perform many of these tasks
with 90% accuracy or better. However, success in in-
tegrated, end-to-end natural language understanding
remains elusive.
I contend that the chief reason for this failure
is that errors cascade and accumulate through a
pipeline of naively chained components. For exam-
ple, if we naively use the single most likely output
of a part-of-speech tagger as the input to a syntactic
parser, and those parse trees as the input to a coref-
erence system, and so on, errors in each step will
propagate to later ones: each components 90% ac-
curacy multiplied through six components becomes
only 53%.
Consider, for instance, the sentence ?I know you
like your mother.? If a part-of-speech tagger de-
terministically labels ?like? as a verb, then certain
later syntactic and semantic analysis will be blocked
from alternative interpretations, such as ?I know you
like your mother (does).? The part-of-speech tag-
ger needs more syntactic and semantic information
to make this choice. Consider also the classic exam-
ple ?The boy saw the man with the telescope.? No
single correct syntactic parse of this sentence is pos-
sible in isolation. Correct interpretation requires the
integration of these syntactic decisions with seman-
tics and context.
Humans manage and resolve ambiguity by uni-
fied, simultaneous consideration of morphology,
syntax, semantics, pragmatics and other contextual
information. In statistical modeling such unified
consideration is known as joint inference. The need
for joint inference appears not only in natural lan-
guage processing, but also in information integra-
tion, computer vision, robotics and elsewhere. All of
these applications require integrating evidence from
multiple sources, at multiple levels of abstraction. I
believe that joint inference is one of the most fun-
damentally central issues in all of artificial intelli-
gence.
In this talk I will describe work in probabilistic
models that perform joint inference across multiple
components of an information processing pipeline
in order to avoid the brittle accumulation of errors.
I will survey work in exact inference, variational
inference and Markov-chain Monte Carlo methods.
We will discuss various approaches that have been
applied to natural language processing, and hypoth-
esize about why joint inference has helped in some
cases, and not in others.
I will then focus on our recent work at Univer-
sity of Massachusetts in large-scale conditional ran-
dom fields with complex relational structure. In a
single factor graph we seamlessly integrate multiple
subproblems, using our new probabilistic program-
ming language to compactly express complex, muta-
ble variable-factor structure both in first-order logic
as well as in more expressive Turing-complete im-
perative procedures. We avoid unrolling this graph-
ical model by using Markov-chain Monte Carlo for
inference, and make inference more efficient with
learned proposal distributions. Parameter estimation
is performed by SampleRank, which avoids com-
plete inference as a subroutine by learning simply
to correctly rank successive states of the Markov-
chain.
Joint work with Aron Culotta, Michael Wick,
Rob Hall, Khashayar Rohanimanesh, Karl Schultz,
Sameer Singh, Charles Sutton and David Smith.
1
