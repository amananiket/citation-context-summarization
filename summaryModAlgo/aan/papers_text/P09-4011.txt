Proceedings of the ACL-IJCNLP 2009 Software Demonstrations, pages 41?44,
Suntec, Singapore, 3 August 2009.
c
?2009 ACL and AFNLP
Combining POMDPs trained with User Simulations and
Rule-based Dialogue Management in a Spoken Dialogue System
Sebastian Varges, Silvia Quarteroni, Giuseppe Riccardi, Alexei V. Ivanov, Pierluigi Roberti
Department of Information Engineering and Computer Science
University of Trento
38050 Povo di Trento, Italy
{varges|silviaq|riccardi|ivanov|roberti}@disi.unitn.it
Abstract
Over several years, we have developed an
approach to spoken dialogue systems that
includes rule-based and trainable dialogue
managers, spoken language understanding
and generation modules, and a compre-
hensive dialogue system architecture. We
present a Reinforcement Learning-based
dialogue system that goes beyond standard
rule-based models and computes on-line
decisions of the best dialogue moves. The
key concept of this work is that we bridge
the gap between manually written dia-
log models (e.g. rule-based) and adaptive
computational models such as Partially
Observable Markov Decision Processes
(POMDP) based dialogue managers.
1 Reinforcement Learning-based
Dialogue Management
In recent years, Machine Learning techniques,
in particular Reinforcement Learning (RL), have
been applied to the task of dialogue management
(DM) (Levin et al, 2000; Williams and Young,
2006). A major motivation is to improve robust-
ness in the face of uncertainty, for example due
to speech recognition errors. A further motivation
is to improve adaptivity w.r.t. different user be-
haviour and application/recognition environments.
The Reinforcement Learning framework is attrac-
tive because it offers a statistical model represent-
ing the dynamics of the interaction between sys-
tem and user. This is in contrast to the super-
vised learning approach of learning system be-
haviour based on a fixed corpus (Higashinaka et
al., 2003). To explore the range of dialogue man-
agement strategies, a simulation environment is
required that includes a simulated user (Schatz-
mann et al, 2006) if one wants to avoid the pro-
hibitive cost of using human subjects.
We demonstrate the various parameters that in-
fluence the learnt dialogue management policy by
using pre-trained policies (section 4). The appli-
cation domain is a tourist information system for
accommodation and events in the local area. The
domain of the trained DMs is identical to that of a
rule-based DM that was used by human users (sec-
tion 2), allowing us to compare the two directly.
The state of the POMDP keeps track of the SLU
hypotheses in the form of domain concepts (10 in
the application domain, e.g. main activity, star rat-
ing of hotels, dates etc.) and their values. These
values may be abstracted into ?known/unknown,?
for example, increasing the likelihood that the sys-
tem re-visits a dialogue state which it can exploit.
Representing the verification status of the con-
cepts in the state, influences ? in combination with
the user model (section 1.2) and N best hypotheses
? if the system learns to use clarification questions.
1.1 The exploration/exploitation trade-off in
reinforcement learning
The RL-DM maintains a policy, an internal data
structure that keeps track of the values (accumu-
lated rewards) of past state-action pairs. The goal
of the learner is to optimize the long-term reward
by maximizing the ?Q-Value?Q
pi
(s
t
, a) of a policy
pi for taking action a at time t. The expected cu-
mulative value V of a state s is defined recursively
as V
pi
(s
t
) =
?
a
pi(s
t
, a)
?
s
t+1
P
a
s
t
,s
t+1
[R
a
s
t
,s
t+1
+ ?V
pi
(s
t+1
)].
Since an analytic solution to finding an optimal
value function is not possible for realistic dialogue
scenarios, V (s) is estimated by dialogue simula-
tions.
To optimize Q and populate the policy with ex-
pected values, the learner needs to explore un-
tried actions (system moves) to gain more expe-
riences, and combine this with exploitation of the
41
??
?
?
?
?
?
?
??
??
??
??????
?
??
??
??
?
?
?
??
?
?
?
??
?
?
???
???
??
?
??
?
?
?
?
??
??
?
???????
?
????
?
??
?
?
?
?
?????
?
?
?
?
??
???
?
?????
?
???
??
?
?
?
?
?
?
??
??
??
??
?
?
??
?
?
?
?
??
??
????
?
??
????
??
????
??
?
??
???
???
??
?
?
???
??
????
????
?
??
?
?
?
?
?
??
?
????
???
?
??
?
???
???
???
??
?
????
?
??
?
??
?
?
?
?
?
?
????
?
??
??
??
?
???
??????
??
??
?
??????
??
?
?
??
?????????
?
?
?????
???
?
?
?
??
???
??
?
??????
??
?
?
?
????
?
???
?
?
???????
?
??
?
??
?
?
??
?
??
???
?
?
?????
??????
?
???
?
?
?
?????
??
????
????
?
?
??
?
????
?
??
?
?
?????
??
?
??????????
??
?
?
???
??
?
??????????
?
?
???
??
????
?????????
?
?
???
????
?
?????
??
??
??
???
?????
?
???
???
??
????
?
??
??
?????
????
?????
?
??????
?
????
?????
?
??
???
???
??????????
???
?
??
?
??????
??
????
?????????
?
?????????
????
????
????????
?????
?
???????
?
???????
???????
?????
?????
??????
???????
???????
?
???
?
??????????
?
???????
???????????
???
???????????????????
????????
?
??????
??????
?
???????????
?????????
???????
?
?????????
????????
?
???????
?????
????????????
????
???????????
??????
????????
?????
????????????
?
?????
?
????????
?
?????????
?
????
?
????
?
?????
?
????????
???????
?????????????
?????????
?
?????
?????
?
????????
??????????
?
?????
????????
????
??????
??????
??????????
????????
????????
?
????????
????
?????
?
????
?
?????
?
????
?
???????????
?????
????????
?
??????
?
??????????
??????
??????
????????
??????
??????
?
????????????????
???????
?
?????
?
????
?
?????
?
?????????
?
?????
?
????
?
????
???????
?
???????????
?
?????????
???????
??????
?
???????
???????????
?
?????
?????
?
???????????
??????
?
?????
????????
?
???????
????????????????????
?
??????????
??????
????????
???????
????????
???????????
??????
?
??????
?????????
?
??????
???????????????????
?????????
?
?????????
?
???????
?
???????
?
????
?
????????
???????
??????????
?
???????
?
???
?
?????
?
???????
??????????
?
????
??????
???????????
?????
??????
??????
??????????
???????
??????
????????
?????
???????????
??????
?????????
?????
?
??????
?
???????
?
?????
?
???????
?????
???????????????
??????????
?
?
0 2000 4000 6000 8000 10000
?8
?6
?4
?2
0
x8
gree
dy0.0
_fixe
d_er
ror_s
essio
ns10
000_
maxs
essio
nleng
th4_r
uns1
0
rewa
rd 
# sessions 
(a) 0% exploration, 100% exploitation: learner does not find
optimal dialogue strategy
????
?
?
?
?
?
?
?
?
?
?
??
?
???
?
??
?
?
?
??
?
?
?
?
??
???
?
?
?
???
??
???
??
?
?
?
??
???
???
?
??
?
?
?
??
?
?
???
?
????????
???
?
?
???
?
??
???
????
?
?
??
?
??
??
?
?
?
??
?
??
??
?
?
?
?
?
??
?
??
??
?
??
?
?
????
??
?
?
??
?
?
??
?
??
?
??
???
??
?
?
??
???
?
?
?
?
?
?
?
??
?
???
?
???
?
?
???
??
??
???
??
???
??
???
??
??
?
?
?
?
?
??
??
???
?
?
?
??
?
???
??
?
??
?
??
?
??????
??
?
?
??
????
?????
??
?
?
???
?
?
?
?
?????
?
???
?
???
??
?
???
??
?
??
??
?
?
??
??
?
?
?
?
??
?
?
?
??
?
???
?
?
?
??
?
?
??
??????
??
?
?
?
?
?
?
?
?
?
??
?
??
?
?
?
?
?
?
?
?????
?
?
?
?
??
?
???
?
?
?
?
?
?
??????
?
?
?
??
?????
?
?
?
?
??
?
??
??
?????
???
??
?
??
??
?
?
??
??
????
?
??
?
?
?
?
?
???
?
??
?
?
??
?
??????
????
?
??
?
?
?
?
??
?
?
?
??
?
??
???
????
?
?
???
?
??
?
?
?
?
?
?
?
??
?
?
????
???
?
?
?
???
?
????
?????
???
?
???
?
???
??
?
?
?
??
???
?
?
???
???
?
?
???
?
?
??
?
?
??
?
??
?
??
?
?
?
??
?
???
??
?
?
?
???
?
?
???
?
?
?
??
?
?
?
?
??
?
??
?
?
?
?
?
?
?
?
?
?
?
?
?
???
??
?
?
???
?
?
?
?
??
?
?
?
?
?
?
?
?
????
?
?
????
????
?
?
?
??
??
???
?
?
?
?
?
?
???
?
?
?
?
?
?
?
?
???
?
?
?
??
??
??
??
??
?????
?
??
?
???
?
?
?
?
??
?
?
?
????
??
?
?
?
????
?
???
????
?
?
??
??
?
?
?
?
??
?
??
????
?
?
??
?
???
??
?
??
???
?
??
?
?
?
?
?
?
??
?
?
????
??
??
??
??
????
?
?
??
?
??
?
?
?
?
?
?
?
??
?
?
???
?
?
?
?
?
?
???
?
?
?
?
?
?
??
?
?
??
?
?
????
?
?
?
??
?
??
?
?
?
??
?
?
???
?
?
?
?
??
?
?
?
?
??
?
??????
?
??
?
?
??
?
?
?
???
??
?
?
?
?
?
?
???
?
?
?
?
?
?
?
??
??
?
?
?
??
???
???
?
?
?
?
??
?
?
?
?
?
??
?
?
?
?
?
?
??
???
?
?
?
?
??
??
?
?
??
?
?
??
??
?
?
??
?
?
?
?
?
?
?
?
?
?
?
?
?
?
??
?
?
?
????
?
?
??
?
?
?
?
????
?????
???
?
??
?
?
??
??
?
?
?
?
???
?
??
?
?
?
??
?
????
?
??
?
?
?
?
??
??
?
??
?
???
?
?
?
?
?
??
?
?
??
?
???
?
?
?
?
?
??
?
?
?
?
?
???
?
?
?
?
?
????
?
?
?
?
??
??
?
???
??
?
???
?
?
?
?
???
?
??
??
?
?
?
??
?
??
?
?
?
?
?
?
???
??
?
?????
?
?
?
?
?
?
?
?
??
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
??
??
?
?
?
?
?
?
??
?
?
?
??
?
?
?
?
?
???
?
?
?
?
?
??
????
??
?
?
??
?
?
?
??
?
?
?
????
??
?
?
?
?
???
?
?
???
?
?
?
?
?
?
?
?
?
?
?
?
?
?
????
?
?????
????
??
?
?
???
?
?
?
?
?
?
?
?
?
??
?
?
??
????
?
????
?
????
?
?
??
?
?
?
??
?
???
?
?
??
?
?
?
?
?
???
??????
?
?
?
?
??
?
?
?
???
?
??
?
?
?
??
?
?
?
?
?
?
?
?
?
?
?
??
?
?
??
??
?
?
?
?
?
?
?
??
?
?
????
?
?
?
?
??
???
??
?????
?
?
?
??
?
?
?
?
?
?
?
??
?????
?
?
?
??
?
?
?
?
?
??
??
?
?
??
?
?
??
??
?
?
?
?
?
?
?
??
?
?
?
??
??
?
?
?
?
?
??
?
???
?
??
??
?
?
???
??
?
?
???
?
?
?
???
?
?
???
??
??
?
?
??
?
??
???
??
?
?
?
?
?
?
?
?????
?
?
??
???
??
?
?
?
?
?
???
??
??
????
???
?
?
?
?
??
?
?
?
?
?
??
?
?
???
?
??
??
?
?
?
??
??
?
??
??
?
??
??
???????
??
?
?
?
?
??
??
??
?
?
??
???
??
?
???
?
??
??
??
?
?
??????
??
?
???
????
?
????
??
?
??
??
?
?
??
?
?
???
?
?
??
??
??
?
?
?
?
?
?
?
?
?
?
?
??
?
?
?
?
?
?
?
?
?
?
?
?
?
?
????
?
?
?
??
??
??
??
?
?
??
???
??
????????
??
??
?
?
?
?
?
?
?
?
??
??
?
?
?
?
?
???????
??
???
?
?
?
?
?
??????
?
?
?
?
?
?
??
??
?
?
??
?
?
??
?
?
?
?
?
?
?
??
??
???
?
?
?
?
??
?
?
??
?
??
?
??
?
?
????
?
??
?
????
?
?
???
?
?
?
?
?
?
?
????
?
?
???
??
?
?
??
?
?
?
?
??
?
?
?
????
?
?
????
?
?
?
?
?
???
??
?
?
????
??
??
???
?
?
?
??
?
????
???
?
?
?
?
?
??
??
?
?
????
?
?
?
??
?
?
??
??
?
?????
???
?
?
?
?
?
????
?
??
?
??
??
?
?????
????
?
?????
?
?
?
???
??
?
????
???
?
??
?
??
?
???
?
?
?
?
?
?????
?
?
??
??
??
?
?
???
?
?
??
??
?
?
?
?????
?
????
?
??
?
?
?
?
??
?
???
??
??
??
?
?
?
?
???
?
?
?????????
?
?
??
?
?
?
?
???
?
?
?
??
?
?
?
??
??
???
???
?
??
?
?
?
???
?
?
?
?
??
?
?
?
?
?
??
?
??
??
?
?
?
?
?
?
??
?
?
???
??
??
??
?
?
?
?
???????
??
?
??
?
?
?
??
??
??
?
?
?
?
??
?
??
?
?
?
?
??
?
?
?
?
?
?
?
?
?
?
?
??
??
?
?
??
?
?
?
?
?
?
??
??
??
?
?
?
?
??
?
?
??
??
??
?
??
??
??
?
?
?
??
????
?
?
?
?
???
?
?
?
?
?
?
?
??
?
?
?
?
??
?
?
??
?
??
??
???
?
??
??
????
?
?
?
?
?
??
???
?
?
?
??
?
???
???
?
?
?
?
?
?
?
??
?
?
?
?
?
????
??
?
??
?
?
?
?
??
??
?
??
??
?
?
?
????
??????
??
???
?
???
?
??
?
?
?
?
?
?
??
??
???
?
?
?
?
??
?
?
?
????
?
??
?
?
?
??
??
???
?
?
?
??
???
?
???
?
???
????
??
??
?
??
?
??
?
?
??
?
??
?
??
?
?
?
?
??
???
?????
???
?
?
?
?
?
???
?
?
?
?
?
?
?
?
?
?
???
?
?
??
????
?
??
?
?
?
?
?
?
?
?
?
?
?
?
?
?
??
?
??
?
?
?
??
????
??
??
?
?
?
???
???
?
?
?
?
?
?
?
?
???
?
??
?
?
?
??
?
?
?
??
?
???
??
?
?
?
????
?
??
??
?????
?
???
?
????
?
???
?
?
?
???
?
?
?
??
?
?
?
?
?
???
??
??
?
????
?
?
?
?
?
???
?
?
?
?
?
??
?
??
?
?
?
?
?
??
??
?
?
?
?
??
?
??
???
?
?
?
??
??
??
?
?
??
?
??
?
??
?
?
?
?
??
?
?
???
????
?
?
?????
??
?
?
?
???
?
????
???
?
??
?
???
?
?
?
?
??
?
??
??
?
?
???
?
??
?
??
???
?
??
?
?
?
?
??
?
?
??
?
?
?
?
????
?
?
?
???
?
?
??
??
?
??
?
?
?
?
?
?
?
?
???
?
?
?
?
?
?
?
??
?
?
???
?
???
?
?
?
?
?
??
?
???
?
?
?
?
??
?
?
?
?
???
?
?
??
?
???
???
??
?
?
?
?
?
?
?
?
??
?
??
?
????
??
?
?
?
?
?
?
???
?
?
?
??
??
??
?
???
?
???
???
??
?
??
??
??????
?
?????
??
?
??????
?
??
?
?
???
???
??
?
??
?
?
?
?
?
??
?
?
?
?
?
???
???
?
??
?
?
?
?
?????
???
???
?
??
?
???
???
?
??
?
?
?
?
??
????
??
?
??
?
??
?
???
???
???
?????
??
??
?
?
??
?
?
???
??
?
??
?
?
???
?
?
?
?
????
?
?
?
?
???
????
?
?
??
??
??
??
?
?
??
?
?
?
?
?
?
?
?
?
?
???
?
?
?
?
?
?
????
?????
??
???
?
??
???
???
??
?
??
?
?
??
?
???????
?
???
?
?
??
?
??
??
??
??
?
???
?
?
?
???
?
?
?
?
?
??
?
?
??
?
?
??
?
?
??
?
?
?
??
??
?
?
?
?
???
?
?
?
??
?
?
????
??
?
?
?
?
?
??
??
??
?
???
??
????
?
???????
?
?
?
?
????
?
?
?
???
?
?
?
?
??
?
??
?
??
?
?
?
???
?
?
?
?
???????
?
?
?
?
?
?
?
??
??
?
?
?
?
???
?
???
?
??
???
?
??
?
?
?
????
?
?
?
?
???
?
?
?
?
?
?
?
??
????
?
????
??
?
?
????
?
?
?
?
?
?
??
?
??
???
?
?
?
?
??
?
?
??
??
??
???
???
????
?
?
?????
??
??
??
?
?
?
?
?
??
?
?????
?
?
?
?
?
?
?
?
???
?
??
?
?
?
?
?
??
?
??
?
?
???
??
??
?????
?
??
?
?
?
?
?
??
?
?
?
??
???
?
??
?
?
?
??
?
??
?
?
?
?
?
??
?
?
?
??
??
?
?
?
?
???
??
?
?
?
?
?
?
??
?
?
?
?
?
???
?
??
?
????
?
?
?
??
?????
?
?
???
??
?
?
??
?
?
?
?
??
?
?
?
?
??
??
?
?
???
?
?
??
?
?
???
???
?
?
??
??
?
?
??
?
?
?
?
???
?
?
?
?
?
?
?
?
??
?
?
?
?
??
?
?
?
???
??
?
?
??
?
?
?
??
?
?
?
?
???
?
?
??
????
?
???
???
???
?
?
?
??
?
?
???
?
?
??
?
?
???
??
?
??
?
?
?
?
?
?
?
?
?
?
?
??
?
?
?
?
?????
?????
?
?
??
?
??
?
??
?????
?
?
?
??
???
?
?
??
??
?
?
??
?
?
??
?
?
?
?
?
?
?
?
?
??
?
??
?
?
??
??
???
?
?
?
?
?
?
????
???
?
?
?
?
???
?
?
?
????
????
?
??
???
?
??
??
?
?
??
?
?
?
?
?
?
?
?
??
??
?
?
?
?
?
???
?
??
?
?
?
?
?
?
?
?
?
?
?
??
?????
?
?
?
?
?
?
?
?
?
?
??
??
?
?
?
?
?
?
???
??
?
?
?
???
?
?
?
??????
?
?
??
?
?
?
?
????
?
?
???
??
??
??
???
?
?
??
?
???
?
?
?
?
??
??
?
??
?
?
?
?
??
?
?
??
?
?
??
???
?
?
??
?
?
???
??
?
??
?
?
?
?
?
??
?
?
????
??
?
?
??
?
0 2000 4000 6000 8000 10000
?8
?6
?4
?2
0
x8
gree
dy0.2
_fixe
d_er
ror_s
essio
ns10
000_
maxs
essio
nleng
th4_r
uns1
0
# sessions 
rewa
rd 
(b) 20% exploration, 80% exploitation: noticeable increase in
reward, hitting upper bound
Figure 1: Exploration/exploitation trade-off
already known successful actions to also ensure
high reward. In principle there is no distinction
between training and testing. Learning in the RL-
based dialogue manager is strongly dependent on
the chosen exploration/exploitation trade-off. This
is determined by the action selection policy, which
for each system turn decides probabilistically (-
greedy, softmax) if to exploit the currently known
best action of the policy for the believed dialogue
state, or to explore an untried action. Figure 1(a)
shows, for a subdomain of the application domain,
how the reward (expressed as minimizing costs)
reaches an upper bound early during 10,000 sim-
ulated dialogue sessions (each dot represents the
average of 10 rewards at a particular session num-
ber). Note that if the policy provides no matching
state, the system can only explore, and thus a cer-
tain amount of exploration always takes place. In
contrast, with exploration the system is able to find
lower cost solutions (figure 1(b)).
1.2 User Simulation
In order to conduct thousands of simulated dia-
logues, the DM needs to deal with heterogeneous
but plausible user input. For this purpose, we have
designed a User Simulator (US) which bootstraps
likely user behaviors starting from a small corpus
of 74 in-domain dialogs, acquired using the rule-
based version of the SDS (section 2). The task of
the US is to simulate the output of the SLU mod-
ule to the DM, hence providing it with a ranked
list of SLU hypotheses.
A list of possible user goals is stored in a
database table (section 3) using a frame/slot rep-
resentation. For each simulated dialogue, one or
more user goals are randomly selected. The User
Simulator?s task is to mimic a user wanting to per-
form such task(s). At each turn, the US mines the
previous system dialog act to obtain the concepts
required by the DM and obtains the corresponding
values (if any) from the current user goal.
The output of the user model proper is passed
to an error model that simulates the ?noisy chan-
nel? recognition errors based on statistics from the
dialogue corpus. These concern concept values as
well as other dialogue phenomena such as noIn-
put, noMatch and hangUp. If the latter phenomena
occur, they are propagated to the DM directly; oth-
erwise, the following US step is to attach plausible
confidences to concept-value pairs, also based on
the dialogue corpus. Finally, concept-value pairs
are combined in an SLU hypothesis and, as in the
regular SLU module, a cumulative utterance-level
confidence is computed, determining the rank of
each of the n hypotheses. The probability of a
given concept-value observation at time t+1 given
the system act at time t, named a
s,t
, and the ses-
sion user goal g
u
, P (o
t+1
|a
s,t
, g
u
), is obtained by
combining the error model and the user model:
P (o
t+1
|a
u,t+1
) ? P (a
u,t+1
|a
s,t
, g
u
)
where a
u,t+1
is the true user action.
2 Rule-based Dialogue Management
A rule-based dialogue manager was developed as a
meaningful comparison to the trained DM, to ob-
tain training data from human-system interaction
for the user simulator, and to understand the prop-
erties of the domain (Varges et al, 2008). Rule-
based dialog management works in two stages:
retrieving and preprocessing facts (tuples) taken
from a dialogue state database (section 3), and
inferencing over those facts to generate a system
response. We distinguish between the ?context
model? of the first phase ? essentially allowing
42
more recent values for a concept to override less
recent ones ? and the ?dialog move engine? (DME)
of the second phase. In the second stage, accep-
tor rules match SLU results to dialogue context,
for example perceived user concepts to open ques-
tions. This may result in the decision to verify the
application parameter in question, and the action
is verbalized by language generation rules. If the
parameter is accepted, application dependent task
rules determine the next parameter to be acquired,
resulting in the generation of an appropriate re-
quest.
3 Data-centric System Architecture
All data is continuously stored in a database which
web-service based processing modules (such as
SLU, DM and language generation) access. This
architecture also allows us to access the database
for immediate visualization. The system presents
an example of a ?thick? inter-module informa-
tion pipeline architecture. Individual components
exchange data by means of sets of hypotheses
complemented by the detailed conversational con-
text. The database concentrates heterogeneous
types of information at various levels of descrip-
tion in a uniform way. This facilitates dialog eval-
uation, data mining and online learning because
data is available for querying as soon as it has
been stored. There is no need for separate logging
mechanisms. Multiple systems/applications are
available on the same infrastructure due to a clean
separation of its processing modules (SLU, DM,
NLG etc.) from data storage (DBMS), and moni-
toring/analysis/visualization and annotation tools.
4 Visualization Tool
We developed a live web-based dialogue visual-
ization tool that displays ongoing and past di-
alogue utterances, semantic interpretation confi-
dences and distributions of confidences for incom-
ing user acts, the dialogue manager state, and
policy-based decisions and updating. An exam-
ple of the visualization tool is given in figures 3
(dialogue logs) and 4 (annotation view). We are
currently extending the visualization tool to dis-
play the POMDP-related information that is al-
ready present in the dialogue database.
The visualization tool shows how our dedicated
SLU module produces a number of candidate se-
mantic parses using the semantics of a domain on-
tology and the output of ASR.
The visualization of the internal representation
of the POMDP-DM includes the N best dialogue
states after each user utterance and the reranking
of the action set. At the end of each dialogue ses-
sion, the reward and the policy updates are shown,
i.e. new or updated state entries and action val-
ues. Another plot relates the current dialogue?s
reward to the reward of previous dialogues (as in
plots 1(b) and 1(a)).
Users are able to talk with several systems
(via SIP phone connection to the dialogue system
server) and see their dialogues in the visualization
tool. They are able to compare the rule-based
system, a randomly exploring learner that has
not been trained yet, and several systems that
use various pre-trained policies. These policies
are obtained by dialogue simulations with user
models based on data obtained from human-
machine dialogues with the original rule-based
dialogue manager. The web tool is available
at http://cicerone.dit.unitn.it/
DialogStatistics/.
Acknowledgments
This work was partially supported by the Euro-
pean Commission Marie Curie Excellence Grant
for the ADAMACH project (contract No. 022593)
and by LUNA STREP project (contract No.
33549).
References
R. Higashinaka, M. Nakano, and K. Aikawa. 2003.
Corpus-based discourse understanding in spoken di-
alogue systems. In ACL-03, Sapporo, Japan.
E. Levin, R. Pieraccini, and W. Eckert. 2000. A
stochastic model of human-machine interaction for
learning dialog strategies. IEEE Transactions on
Speech and Audio Processing, 8(1).
J. Schatzmann, K. Weilhammer, M. Stuttle, and
S. Young. 2006. A Survey of Statistical User Sim-
ulation Techniques for Reinforcement-Learning of
Dialogue Management Strategies. Knowledge En-
gineering Review, 21(2):97?126.
S. Varges, G. Riccardi, and S. Quarteroni. 2008. Per-
sistent Information State in a Data-Centric Architec-
ture. In SIGDIAL-08, Columbus, Ohio.
J. D. Williams and S. Young. 2006. Partially Ob-
servable Markov Decision Processes for Spoken Di-
alog Systems. Computer Speech and Language,
21(2):393?422.
43
ASR
TTS
Turn 
Setup
DB
SLU
DM
NLG
http-req
http-req
http-req
http-req
Ids
VXML
   page
ASR results
        HTTP request 
SLU results
DM context/results
VXMLgen
http-req
NLG context/results
(a) Turn-level information flow in the data-centric SDS ar-
chitecture
DB
Simulation
Environment
DM
NLG
User Model
Error Model
User Goals
Corpus
(b) User simulator interface with the dialogue manager
Figure 2: Architecture for interacting with human user (left) and simulated user (right)
Figure 3: Left pane: overview of all dialogues. Right pane: visualization of a system opening prompt fol-
lowed by the user?s activity request. All distinct SLU hypotheses (concept-value combinations) deriving
from ASR are ranked based on concept-level confidence (2 in this turn).
Figure 4: Turn annotation of task success based on previously filled dialog transcriptions (left box).
44
