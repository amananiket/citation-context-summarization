A STATUS REPORT ON THE LRC MACHINE 
J onathan  Slocum 
Siemens Corporat ion  
Boca Eaton ,  FL 3343 
ABSTRACT 
Th is  paper  d i scusses  the  l ingu is t i c  and 
computat iona l  techn iques  employed in  the  cur rent  
version of Machine Translation sys tem be ing  
developed at the Linguistics Research Center of 
the University of Texas, under contract to Siemens 
AG in Munich, West Germany. We pay particular 
attention to the reasons for our choice of certain 
techn iques  over  o ther  cand idates ,  based on both  
ob jec t ive  and sub jec t ive  c r i te r ia .  We then  repor t  
the  sys tem's  s ta tus  v i s -a -v i s  i t s  read iness  fo r  
app l i ca t ion  in  a p roduct ion  env i ronment ,  as a 
means of jus t i fy ing  our  c la ims  regard ing  the  
pract i ca l  u t i l i t y  of  the  methods we espouse .  
I INTRODUCTION 
The LRC MT sys tem i s  one of very  few 
la rge-sca le  app l i ca t ions  of  modern computat iona l  
l i ngu is t i cs  techn iques  \[Lehmann, 1981\] .  A l though 
the  LRC MT sys tem i s  near ing  the  s ta tus  of a 
p roduct ion  sys tem (a vers ion  shou ld  be de l ivered  
to the  pro jec t  sponsor  about  the  t ime th i s  
conference  takes  p lace) ,  i t  i s  not  a t  a l l  s ta t i c ;  
ra ther ,  i t  i s  an evo lv ing  co l lec t ion  of  techn iques  
which are  cont inua l ly  tes ted  through app l i ca t ion  
to moderate ly  la rge  techn ica l  manua ls  rang ing  from 
50 to 200 pages in  length .  Thus,  our "app l ied"  
sys tem remains  a research  veh ic le  that  serves  as 
an exce l lent  tes tbed  fo r  proposed new procedures .  
In genera l ,  the  c r i te r ia  fo r  our cho ice  of 
l i ngu is t i c  and computat iona l  techn iques  a re  th ree :  
e f fec t iveness ,  conven ience  of use ,  and e f f i c iency .  
These c r i te r ia  a re  app l ied  in  a context  where the  
product ion  of an MT sys tem to be operat iona l  in  
the near-term future is of critical concern. 
Candidate techniques which do not admit near-term, 
large-scale application thus suffer an over- 
whelmins disadvantage. The questions confronting 
us are, then, twofold: (I) which techniques admit 
such application; and (2) which of these best 
satisfy our three general criteria? The first 
question is usually answered through an evaluation 
of the likely difficulties and requirements for 
implementation; the second, through empirical 
results in the course of experiments. 
Our evaluation of the LRC ~E system's current 
status will be based on three points! (a) the 
system's provision of all the tools necessary for 
users to effect the complete translation process 
(including text processing, editing, terminology 
meinten~ok-up ,  etc.); (b) 
quantitae., throughput on a 
particul. (c) qualitative 
PerformS'known about overall 
performliveness (i.e., the  
number c o be\] suppor ted  by a 
s ing le  " ? , m, cheer  \ [expected \ ]  
cnrougnp any o ther  personne l  
necessar-to-day operation of 
the  sySted \] overa l l  cos ts  of  
t rans la t  the norm exper ienced  
in  human-fine I numbers" will 
not be a of the conference. 
but  the ninary experiments by 
our sponthus  some reasonable 
pro jec t i ,  
~UES EMPLOYED 
Our ~een " l ingu is t i c  
ceohniqu%iona l  techn iques"  
(dlscussqection) i s  somewhat 
artificihalidity in a broad 
sense, aSfrom an overview of 
the  po in t  s sec t ion  we present  
the reas of the following 
linguistia phrase-structure 
grammar; ures; (c) semantic 
features ;e rpreta t ions ;  (e) 
transformecific rules; (f) a 
transfer:Cached procedures to 
effect t t  
166 
A. Phras ,  
In ,e employ a phrase- 
structur~Y sufficient lexical 
controls ~ lexical-funccional 
grammar all our linguistic 
decision most controversial, 
and cons the most attention. 
Generall are two competing 
claims: rules per se are 
inadequ~-S., \[Cullingford, 
1978\]);~r forms of gr~ummar 
(ATNs \[~rmational \[Petrick, 
1973\], ;1972\], word-experts 
\[Small,~rior. We will deal 
with th. 
Th~ght that claim that 
syntax ~propriate models of 
languas according to this 
not ion ,  be t reated  \ [a lmost \ ]  ent i re ly  on the  bas i s  
of semant ics ,  gu ided by a s t rong  under ly ing  model 
of the  cur rent  s i tuat iona l  context ,  and the  
expectat ions  that  may be der ived  there f rom.  We 
cannot  a rgue  aga ins t  the  c la im chat  semant ics  i s  
of  c r i t i ca l  concern  in  Natura l  Language 
Process ing .  However, as  yet  no s t rong  case  has  
been advanced fo r  the  abandonment of  syntax .  
Moreover,  no system has been de le loped  by any of  
the  adherents  of the  "semant ics  on ly"  schoo l  of 
thought  that  has more -or - less  success fu l l y  dea l t  
w i th  ALL of  a v ide  range  - -  or  a t  leas t  la rge  
volume - -  of ~ater ia l .  A more damaging argument  
aga ins t  th i s  schoo l  i s  that  every  NLP sys tem to 
date  that  HAS been app l ied  Co la rge  vo lumes  of  
text  ( in  the  a t tempt  to p rocess  ALL of i t  soma 
s ign i f i cant  sense)  has  been based on a s t rong  
syntact i c  model of l anguage  (see, e.g., \ [Boater  et 
e l . ,  1980b\] ,  \[Damerau, 1981\ ] .  \ [Hendr ix  e t  e l . ,  
1978\] ,  \[Lehmann et  e l , ,  1981\] ,  \ [Mar t in  e t  e l . ,  
1981\] ,  \ [Rob inson.  1982\ ] ,  and \ [Sager .  1981\]). 
There are  o ther  schoo ls  of  thought  that  ho ld  
phrase -s t ruc ture  (PS) ru les  in  d i s respect ,  wh i le  
admi t t ing  the  u t i l i ty  (necess i ty )  of  syntax .  I t  
i s  c la imed that  the  phrase-s t ruc ture  fo rmal i sm i s  
inadequate ,  and that  o ther  forms of  g r - - - - r  a re  
necessary .  (Th is  has  been a long-s tand ing  
pos i t ion  in  the  l ingu is t i c  community,  be ing  uphe ld  
there  be fore  most computat iona l  inguists jumped 
on the  bandwagon; i ron ica l l y ,  th i s  pos i t ion  is nov 
be ing  cha l lenged by some wi th in  the  l ingu is t i c  
community itself, who are once again supporting PS 
ru les  as a model of  natura l  l anguage  use  \ [Gazdar ,  
1981\].) The anti-PS positions in the NLP 
c~umiCy are  a l l ,  of  necess i ty ,  based on 
pract i ca l  cons iderat ions ,  s ince  the models  
advanced to rep lace  PS ru les  a re  fo rmal ly  
equ iva lent  in  generat ive  power (assuming  the  PS 
ru les  to be augmented,  which i s  a lways the  case  in  
modern NLP sys tems employ ing them) .  But cascaded 
ATNs \[Woods, 1980\] ,  fo r  example,  a re  on ly  
marg ina l ly  d i f fe rent  from PS ru le  sys tems.  I t  i s  
cur ious  to note  that  on ly  one of the  remain ing  
contenders  (s  t rans format iona l  g r - - , - - r  \[Damerau, 
1981\])  has been demonst ra ted  in  la rge-sca le  
app l i ca t ion  - -  and even th i s  sys tem employs PS 
ru les  in the  initial s tages  of parsing. Other  
formal sys tems (e .g . ,  p rocedura l  gr=mm-rs 
\ [Winograd, 1972\]) have been app l ied  to 
semantically deep (but linguistically 
Lmpover ished) domains - -  or Co excess ive ly  l J Jniced 
domains (e.g., Smell's \[1980\] "word expert" parser 
seems to have encompassed a vocabulary of less 
than 20 items). 
For p rac t i ca l  app l i ca t ion ,  i t  is necessary  
thaca  sys tem be ab le  co accumulate  grammar ru les ,  
and espec ia l l y  lex ica l  i tems,  aca  prod ig ious  ra te  
by current NLP standards. The formalisms 
competing with PS rules and dictionary entries of 
modest size seem to be universally characterizable 
as requiring enormous human resources for their 
implementation in even a moderately large 
environment. This should not be surprising: it is 
precisely the claim of these competing 
methodologies (chose Chac are ocher than slight 
variations on PS rules) that language is an 
exceedingly complex phenomenon, requiring 
167 
cor respond ing ly  complex techn iques  to model .  For 
"deep unders tand ing"  app l i ca t ions ,  we do noc 
contes t  th i s  c la im.  But we do mainta in  chat  there  
a re  some app l i ca t ions  that  do not  seem to requ i re  
th i s  leve l  of  e f fo r t  fo r  adequate  resu l t s  in  a 
p rac t i ca l  se t t ing .  Our par t i cu la r  app l i ca t ion  - -  
automated  t rans la t ion  of techn ica l  tex ts  -- seems 
CO fe l l  i n  ChiJ  ca tegory .  
The LRC )iT sys tem i s  cur rent ly  equ ipped w i th  
someth ing  over  400 PS ru les  descr ib ing  the  Source 
Language (German),  and near ly  10,000 lex ica l  
ent r ies  in  each of  two languages  (German and the  
Target  Language - -  Eng l i sh ) .  The cur rent  s ta te  of  
our  coverage  of  the  SL i s  that  the  sys tem i s  ab le  
to parse  and acceptab ly  t rans la te  the major i ty  of 
sentences  in  p rev ious ly -unseen  texts ,  w i th in  the  
sub jec t  a reas  bounded by our  d ic t ionary  ( spec i f i c  
figures will be related below). By the time this 
conference  convenes ,  we w i l l  have begun the  
process  of  add ing to the  sys tem an ana lys i s  
grammar of  the  cur rent  TL (Eng l i sh ) ,  so that  the  
d i rec t ion  of  t rans la t ion  may be reversed ;  we 
ant i c ipate  br ing ing  the  Eng l i sh  grammar up to the  
leve l  of  the  German gr2m~ar in  about  a year ' s  
t ime.  Our expectat ions  fo r  eventua l  coverage  a~e 
that  around 1,000 PS ru les  w i l l  he adequate  co 
account  fo r  a lmost  a l l  sentence  forms ac tua l ly  
encountered  in  techn ica l  tex ts ,  whatever  the  
language.  We do not  fee l  const ra ined  to account  
fo r  every  poss ib le  sentence  form in such texts  - -  
nor  fo r  sentence  forms not  found in  such texts  (as  
in  the  case  of poet ry )  - -  s ince  the  requ i red  
e f fo r t  would not  be cos t -e f fec t ive  whether  
measured in  f inanc ia l  or  human terms,  even i f  i t  
were poss ib le  us ing  cur rent  techn iques  (which ve 
doubt ) .  
B. Syntact i c  Features  
Our use  of syntact i c  features  i s  re la t ive ly  
noncont rovers ia l ,  g iven  our cho ice  of  the  PS ru le  
formalism. We employ syntactic features for two 
purposes. One is the usual practice of using such 
features to restrict the application of PS rules 
(e .g . ,  by en forc ing  sub jec t -verb  number 
agreement ) .  The o ther  use i s  perhaps  pecu l ia r  to 
our type of app l i ca t ion :  once an ana lys i s  i s  
ach ieved ,  cer ta in  syntact i c  features  a re  employed 
to cont ro l  the  course  (and outcome) of t rans la t ion  
- -  i . e . ,  generat ion  of  the  TL sentence .  The 
"augmentat ions"  to our  PS ru les  inc lude  procedures  
written in a formal language (so that our 
linguists do not have Co learn LISP) that 
manipulate features by restricting their presence. 
their values if present, etc., and by moving them 
from node to node in the "parse tree" during the 
course of the analysis. As is the case with other 
researchers employing such techniques, we have 
found this to be an extremely powerful (and of 
course necessary) means of restricting the 
activities of the parser. 
C. Semantic Features 
We employ simple semantic features, as 
opposed to complex models of the domain. Our 
reasons  are  pr imar i l y  p rac t i ca l .  F i r s t ,  they  seem 
su f f i c ient  fo r  a t  leas t  the  in i t ia l  s tage  of our  
app l i ca t ion .  Second, the  thought  of wr i t ing  
complex models  of  even one complete  techn ica l  
domain i s  s tagger ing :  the  operat ion  and 
maintenance  manua ls  we ar  e cur rent ly  work ing w i th  
(descr ib ing  a d ig i ta l  te lephone  sw i tch ing  sys tem)  
are  par t  of  a document co l lec t ion  that  i s  expected  
to compr i se  some 100,000 pages  of  text  when 
complete .  A research  group the  s i ze  of  ours  would 
not  even be ab le  to read  that  vo lume of mater ia l ,  
much less write the "necessary" semantic models 
subsumed by i t ,  in any reasonable amount of time. 
(The group would also have to become electronics 
engineers, in all likelihood.) If such models are 
indeed required for our application, we will never 
succeed .  
As i t  tu rns  out ,  we are  do ing  surpr i s ing ly  
we l l  w i thout  such mode ls .  In  fac t ,  our  semant ic  
feature  sys tem i s  not  yet  be ing  employed to 
res t r i c t  the  ana lys i s  e f fo r t  a t  a l l ;  i ns tead ,  i t  
i s  used a t  " t rans fer  t ime"  (descr ibed  la ter )  to  
improve the  qua l i ty  of  the  t rans la t ions ,  p r imar i l y  
of  p repos i t ions .  We look forward  to extend ing  the  
use of  semant ic  features  to o ther  par ts  of  speech ,  
and to substant ive  ac t iv i ty  dur ing  ana lys i s ;  but  
even we were p leased  a t  the  resu l t s  we ach ieved  
using only syntactic features. 
D. Scored In terpreta t ions  
I t  i s  a we l l -known fac t  that  NLP sys tems tend 
to produce many read ings  of  the i r  input  sentences  
(un less ,  of course ,  const ra ined  to produce the  
first reading only -- which can result in the 
"right" interpretation being overlooked). The LRC 
MT system produces all interpretations of the 
input "sentence" and assigns each of them a score, 
or plausibility factor \[Robinson, 1982\]. This 
technique can be used, in theory, to select a 
"best" interpretation from the possible readings 
of an ambiguous sentence. We base our scores on 
both lexical and grammatical phenomena -- plus the 
types of any spelling/typographical errors, which 
can sometimes be "corrected" in more than one way. 
Our exper iences  re la t ing  to the  re l iab i l i ty  
and s tab i l i ty  of heur i s t i cs  based on th i s  
techn ique  are  dec ided ly  pos i t i ve :  we employ on ly  
the  (or  a) h ighest -scor ing  read ing  fo r  t rans la t ion  
( the  o thers  be ing  d i scarded) ,  and our  in fo rmal  
exper iments  ind icate  that  i t  i s  very  ra re ly  t rue  
that  a bet te r  t rans la t ion  resu l t s  f rom a 
lower -scor ing  ana lys i s .  (Surpr i s ing ly  o f ten ,  a 
number of the  h igher -scor ing  in terpreta t ions  w i l l  
be t rans la ted  ident i ca l l y .  But poorer  
t rans la t ions  a re  f requent ly  seen  from the  
lower -scor ing  in terpreta t ions ,  demonst ra t ing  that  
the  techn ique  i s  indeed e f fec t ive . )  
to syntact i c  const ruc ts .  (Ac tua l ly ,  both  s ty les  
a re  ava i lab le ,  but  our  l ingu is ts  have never  seen  
the need or practicality of employing the open- 
ended variety). It is clearly more efficient to 
index tranoformations to specif ic rules when 
possible; the import of our findings is that it 
seems to be unnecessary to have open-ended 
transformations -- even during analysis, when one 
might intuitively expect them to be useful. 
F. T rans fer  Component 
I t  i s  f requent ly  a rgued that  t rans la t ion  
shou ld  be a process  of  ana lyz ing  the  Source  
Language (SL) in to  a "deep representat ion"  of  some 
sort, then directly synthesizing the Target 
Language (TL) (e.g., \[Carbonnel, 1978\]). We and 
others \[King, 1981\] contest this claim -- 
especially with regard to "similar languages" 
(e.g., those in the Indo-European family). One 
objection is based on large-scale, long-term 
trials of the "deep representation" (in MT. called 
the "pivot language") technique by the MT group at 
Grenoble \[Boitet, 1980a\]. After an enormous 
investment in time and energy, includin E 
experiments with massive amounts of text, it was 
decided that the development of a suitable pivot 
language (for use in Russian-French translation) 
was probably impossible. Another objection is 
based on practical considerations: since it is not 
likely that any NLP system will in the foreseeable 
future become capable of handling unrestricted 
input -- even in the technical area(s) for which 
it might be designed -- it is clear that a 
"fail-soft" technique is necessary. It is not 
obvious that such is possible in a system based 
solely on a pivot language; a hybrid system 
capable of dealing with shallower levels of 
understanding is necessary in a practical setting. 
This being the case, it seems better in near-term 
applications to start off with a system employing 
a "shallow" but usable level of analysis, and 
deepen the level of analysis as experience 
dictates, and resources permit. 
Our alternative is to have a "transfer" 
component which maps "shallow analyses of 
sentences" in the SL into "shallow analyses of 
equivalent sentences" in the TL, from which 
synthesis then takes place. While we and the rest 
of the NLP community continue to debate the nature 
of an adequate pivot language (i.e., the nature of 
deep semantic models and the processing they 
entail), we can hopefully proceed to construct a 
usable system capable of progressive enhancement 
as linguistic theory becomes able to support 
deeper  mode ls .  
G. A t tached  Trans la t ion  P rocedures  
E. Indexed Transformations 
We employ a t rans format iona l  component ,  
dur ing  both the ana lys i s  phase and the  t rans la t ion  
phase. The transformations, however, are indexed 
to specific syntax rules rather than loosely keyed 
Our Transfer procedures (which effect the 
actual translation of SL into TL) are tightly 
hound to nodes in the analysis (parse tree) 
structure \[Paxton, 1977\]. They are, in effect, 
suspended procedures -- the same procedures that 
constructed the corresponding parse tree nodes to 
begin with. This is to be preferred over a more 
168 
genera l ,  loose assoc ia t ion  based on syntact i c  
const ruc ts  because,  as ide from i t s  advantage in 
sheer computat ional  e f f i c iency ,  i t  e l im inates  the 
poss ib i l i ty  that  the '~rong"  procedure can be 
appl ied to a const ruc t .  The only real  argument 
aga ins t  th i s  techn ique,  as we see i t ,  i s  based on 
space cons iderat ions :  to the extent  that  d i f fe rent  
const ruc ts  share the same t rans fer  operat ions ,  
rep l i ca t ion  of the procedures chat /~plemenc sa id 
operat ions  (and ed i t ing  e f fo r t  to modify them) i s  
poss ib le .  We have not not iced th i s  to be a 
problem. For a whi le ,  our system load-up 
procedure searched fo r  dup l i ca tes  of th i s  nature  
and e l iminated  them; however, the ga ins  turned out 
to be minimal N d i f fe rent  const ruc ts  typ ica l ly  do 
requ i re  d i f fe rent  operet ions .  
llI COMPUTATIONAL TECHNIQUES ~qFLOYED 
Again, our separat ion  of " l ingu is t i c "  from 
"computat ional"  techniques i s  somewhat a r t i f i c ia l .  
but never the less  use fu l .  In th i s  sec t ion  we 
present  the reasons for  our use of the fo l lowing 
cmaputat ion~l techn iques :  (a) an a l l -paths ,  
bottom-up parser ;  (b) assoc ia ted  ru le-body 
procedures;  (c) spe l l ing  cor rec t ion ;  (d) another  
fa i l - so f t  ana lys i s  technique;  and (e) recurs lve  
pars ing  of parenthet i ca l  express ions .  
A. A l l -paths ,  Bottom-up Perser  
Among a l l  our choices of computat ional  
techn iques ,  the use of an a l l -paths ,  bottom-up 
parser  i s  probably the most cont rovers ia l .  I t  
a lso  rece ived our g reates t  exper imental  sc ru t iny .  
We have co l lec ted  ? substant ia l  body of empir ica l  
evidence re la t ing  Co pars ing  techn iques .  Since 
the evidence and conc lus ions  requ i re  lengthy 
d i scuss ion ,  and are presented elsewhere \[Slocum, 
1981\], we w i l l  only b r ie f ly  s~r i ze  the resu l t s .  
The evidence ind icates  that  our use of an 
a l l -paths  bottom-up parser  i s  jus t i f i ed ,  g iven the 
current state of the art in Computational 
Linguistics. Our reasons are the following: 
first, the dreaded "exponential explosion" of 
processing time has not appeared (and our sr---~=r 
and tes t  texts  are among the la rgest  in the 
wor ld) ,  but ins tead ,  process ing time appears Co be 
l inear  with sentence length  - -  even though our 
system produces a l l  poss ib le  in terpreta t ions ;  
second, top-down pars ing methods su f fe r  inherent  
d isadvantages  in e f f i c iency ,  and bottom-up parsers  
can be and have been augmented with "top-down 
filtering" to restrict the syntax rules applied to 
those that an all-paths top-down parser would 
apply; th i rd ,  i t  is  d i f f i cu l t  to persuade a 
top-down parser  to cont inue the ana lys i s  e f fo r t  to 
the end of the sentence,  when i t  blocks somewhere 
in the middle - -  which makes the implementat ion of
"fail-soft" techniques that  much more difficult; 
and lastly, the lack of any strong notion of how 
to construct a "best-path" parser, coupled with 
the raw speed of well-unplemented parsers, implies 
that an all-paths parser which scores 
interpretations and can continue the analysis to 
the end of the sentence is best in a practical 
application such as ours. 
169 
B. Assoc ia ted  Rule-body Procedures 
We assoc ia te  a procedure d i rec t ly  with each 
ind iv idua l  syntax  ru le ,  and eva luate  i t  as soon as 
the parser  determines the ru le  to be (seemingly)  
app l i cab le  \ [P ra t t ,  1973; Hendrix,  1978\] - -  hence 
the term "ru le-body procedure" .  This p rac t i ce  i s  
equ iva lent  to what i s  done in ATN systems.  From 
the linguist's point of view, the contents of our 
ru le-body procedures appear to  const i tu te  a fo rmal  
language dealing with syntecCic and semantic 
features /va lues  of nodes in the t ree  - -  i . e . ,  no 
knovledse of LISP i s  necessary  to code e f fec t ive  
procedures .  Since these procedures are compiled 
in to  LISP, a l l  the power of LISP is  ava i lab le  as 
necessary .  The ch ie f  l i ngu is t  on our p ro jec t ,  who 
has ? vague knowledge of LISP, has employed OR and 
AND operators  to a s ign i f i cant  extent  (we d idn ' t  
bother  to inc lude them in the spec i f i ca t ions  o f  
the formal language,  though we obv ious ly  could 
have) ,  and on rare  occas ions  has resor ted  to us ing 
COND. No other  ca l l s  to t rue LISP funct ions  (as 
opposed to our formal operators ,  which are few and 
typ ica l ly  qu i te  p r imi t ive )  have seemed necessary .  
nor has th i s  capab i l i ty  been requested ,  to date .  
The power of our ru le -body procedures eems to l i e  
in  the choice of features /va lues  that  decorate the 
nodes, ra ther  than the process in  E capab i l i t i es  of 
the procedures themse lves .  
C. Spe l l ing  Correct ion  
There are l im i ta t ions  and dansers  to spe l l ing  
cor rec t ion  in  genera l ,  but we have found i t  to be 
an indispensable component of an applied system. 
People do make spe l l ing  and typograph ica l  e r ro rs ,  
as i s  wel l  known; even in  "po l i shed"  documents 
they appear with surpr i s ing  f requency (about every 
other  PaSe, in  our exper ience) .  Arguments by LISP 
programmers ( re :  INTERLISP's DWIM) as ide ,  users  of 
appl ied NLP systems d is t inc t ly  d i s l i ke  being 
confronted with requests for clarification -- or, 
worse, unnecessary ~ailure -- in lieu of automated 
spelling correction. Spelling correction. 
therefore, is necessary. 
Luck i ly ,  almost a l l  such er rors  are t reatab le  
with simple techn iques :  s ing le - le t te r  add i t ions ,  
omiss ions ,  and mis takes ,  plus two- or th ree- le t te r  
t ranspos i t ions  account for  almost a l l  m is takes .  
Unfor tunate ly ,  i t  i s  not in f requent ly  the case 
that there i s  more than one way to "correct" a 
mistake (i.e., resulting in different corrected 
versions). Even a human cannot always determine 
the correct form in isolation, and for NLP systems 
it is even more difficult. There is yet another 
problem with automatic spelling correction: how 
much to correct. Given unlimited rein, any word 
can be "corrected" Co any other. Clearly there 
must be limits, but what are they? 
Our informal findings concerning how much one 
may safely "correct" in an application such as 
ours are these: the few errors chat simple 
techniques ha~e not handled are almost always 
bizarre (e.g., repeated syllables or larger 
portions of words) or highly unusual (e.g., blanks 
inserted within words); correction of more than a 
one er ror  in  a word i s  dangerous  ( i t  i s  bet te r  to 
t reat  the  word as unknown, hence a noun) ;  and 
"cor rec t ion"  of  e r ro rs  wh ich  have conver ted  one 
word in to  another  (va l id  in  i so la t ion)  shou ld  not  
be t r ied .  
D. Fail-soft Gr~-m-tical Analysis 
In  the  event  of  fa i lu re  to ach ieve  a 
comprehens ive  ana lys i s  of  the  sentence ,  a sys tem 
such  as ours  -- which i s  to  be app l ied  to  hundreds  
of thousands  of  pages  of  text  - -  cannot  indu lge  in  
the  luxury  of s imp ly  rep ly ing  w i th  an er ror  
message  s ta t ing  Chat the  sentence  cannot  be 
in terpreted .  Such behav io r  i s  a s ign i f i cant  
prob lem,  one which  the  NLP commuuity has  fa i led  to  
come to gr ips  w i th  in  any coherent  fash ion .  There 
have ,  a t  leas t ,  been some fo rays .  We ishede l  and 
Black \[1980\] discusa techniques for interacting 
with the  linguist/developer to identify 
insufficiencies in the grammar. This is fine for 
deve lopment  purposes .  But ,  of  course ,  in  an 
app l ied  sys tem the  user  w i l l  be ne i ther  the  
deve loper  nor  a l ingu is t ,  so th i s  approach  has  no 
va lue  in  the  f ie ld .  Rayes and Mourad lan \[1981\] 
d i scuss  ways of  a l low ing  the  parser  to  cope w i th  
ungr - - - - - t i ca l  u t te rances ;  th i s  work is i n  i t s  
in fancy ,  but  i t  i s  s t imu la t ing  nonethe less .  We 
look forward to  experimenting with similar 
techniques in our system. 
What we requ i re  now, however ,  i s  a means of  
dea l ing  w i th  "ungrammat ica l "  input  (whether  
th rough the  human's  e r ro r  or the  shor tcomings  of  
our own ru les )  that  i s  h igh ly  e f f i c ient ,  
su f f i c ient ly  genera l  to account  fo r  a la rge ,  
unknown range  of  such er rors  on i t s  f i r s t  out ing ,  
and which  can be implemented in  a shor t  per iod  of  
t ime.  We found jus t  such a techn ique  three  years  
ago:  a spec ia l  p rocedure  ( invoked when the  
ana lys i s  e f fo r t  has  been car r ied  th rough to the  
end of the  sentence)  searches  th rough the  parser ' s  
char t  to f ind  the  shor tes t  path  from one end to 
the  o ther ;  th i s  path  represents  the  fewest ,  
l ongest -spann ing  phrases  which were const ruc ted  
dur inE  the  ana lys i s .  T ies  a re  broken  by use  of 
the  s tandard  scor ing  mechanism that  p rw ides  each 
phrase in the analysis with a score, or 
plausibility measure (discussed earlier). We call 
this procedure "phrasal analysis'. 
Our phrasa l  ana lys i s  techn ique  has  proven to 
be use fu l  fo r  both  the  deve lopers  and the  
end-user ,  in  our  app l i ca t ion :  the  sys tem 
t rans la tes  each phrase  ind iv idua l ly ,  when a 
comprehens ive  sentence  ana lys i s  i s  not  ava i lab le .  
The linguists use the results to pin-point missing 
(or faulty) rules. The users (who are 
professional translators, editing the MT system's 
output) have available the best  translation 
poss ib le  under  the  c i rcumstances ,  ra ther  than  no 
usab le  output  of  any k ind .  To our  knowledge,  no 
o ther  NLP sys tem re l ies  on a such  a genera l  
techn ique  fo r  search ing  the  parser ' s  char t  when an 
ana lys i s  e f fo r t  has  fa i led .  We th ink  that  phrasa l  
analysis -- which is simple and independent of 
both language and grammar -- could be useful in 
ocher  app l i ca t ions  of NLP techno logy ,  such  as 
natura l  l anguage  in ter faces  to databases .  
E. Recurs ive  Pars ing  of Parenthet i ca l  Express ions  
Few ~LP sys tems have dea l t  w i th  parenthet i ca l  
express ions ;  but  MT researchers  know well that  
these  const ruc ts  appear  in  abundance  in  techn ica l  
tex ts .  We dea l  w i th  th i s  phenomenon in  the  
fo l low ing  way: ra ther  than  t reat ing  parentheses  as 
lexical items, we make use of LISP's natural 
treatment of them as list delimiters, and treat 
the  resu l t ing  sub l ia ts  as  ind iv idua l  "words" in  
the  sentence ;  these  '~ords" are  "lexically 
ana lyzed"  v ia  recurs ive  ca l l s  to  the  parser .  
As ide  from the  e legance  of the  t reatment ,  th i s  has  
the  advantage  that  "ungra - - -a t i ca l "  parenthet i ca l  
expressions may undergo phrasal analysis and thus 
become single-phrase entities as far as the 
analysis of the encompassing sentence is 
concerned;  thus ,  ungr - - - -a t i ca l  parenthet i ca l  
express ions  need not  resu l t  in  ungrammat ica l  
(hence  poor ly  hand led)  sentences .  
IV CURRENT STATUS 
A. Adequate  Suppor t  Too ls  
No NLP sys tem i s  l i ke ly  to to be success fu l  
in  i so la t ion :  an env i ro , - -ent  of suppor t  too ls  i s  
necessary  fo r  u l t imate  acceptance  on the  par t  of  
p rospect ive  users .  The fo l low ing  suppor t  too ls ,  
we think, constitute a minimum workable 
enviro,--ent for both development and use: a DBMS 
for handling lexical entries; validation programs 
that verify the admissability of all linguistic 
ru les  (g r - - - .a r ,  l ex icons ,  t rans format ions ,  e tc . )  
accord in  E to  a se t  of fo rmal  spec i f i ca t ions ;  
d ic t ionary  programs that  search  through la rge  
numbers of  p roposed new lex ica l  ent r ies  (words ,  in  
a l l  re levant  languages)  to  determine  which ent r ies  
a re  ac tua l ly  new, and which appear  to rep l i ca te  
ex is t ing  ent r ies ;  de fau l t ing  programs that  "code"  
new lex ica l  ent r ies  in  the  NLP sys tem's  chosen  
fo rmal i sm automat ica l l y ,  g iven  on ly  the  root  forms 
of the  words and the i r  ca tegor ies ,  us ing  
empi r i ca l l y  determined  best  guesses  based  on the  
ava i lab le  d ic t ionary  database  ent r ies  p lus  
whatever  o r thograph ic  in fo rmat ion  i s  ava i lab le  in  
the  root  fo rms;  and benchmark programs to tes t  the  
in tegr i ty  of the  NLP sys tem a f te r  s ign i f i cant  
modifications \[Slocum, 1982\]. A DB}~ for handling 
grammar ru les  i s  a l so  a good idea .  
For Machine Trans la t ion  app l i ca t ions ,  one 
must  add:  a co l lec t ion  of  text -p rocess ing  programs 
that \[semi-\]automatically mark and extract 
translatable segments of text from large 
documents, and which automatically insert 
t rans la t ions  produced by the  MT sys tem back in to  
the  or ig ina l  document ,  p reserv ing  a l l  fo rmat t ing  
convent ions  such  as tab les  of contents ,  sec t ion  
headings, paragraphs, multi-column tables, 
flowcharts, figure labels, and the like; a 
powerful on-line editing program with special 
capabilities (such as single-keystroke commands to 
look up words in on-line dictionaries) in addition 
to the normal editing commands (almost all of 
170 
which shou ld  be invokab le  w i th  a s ing le  
keyst roke) ;  and a l so ,  perhaps ,  (assess  to)  a " term 
databank , "  i .e . ,  an on- l ine  database  of  techn ica l  
terms used in the  sub jec t  a rea(s )  to be covered by 
the  ~ sys tem.  
The LRC MT sys tem a l ready  prov ides  a l l  o f  the  
too ls  ment ioned  above,  w i th  the  except ion  of  the  
text  ed i to r  and te rmino logy  database  (both  of  
which our  sponsor  v i i i  p rov ide) .  A l l  of th i s  
comes in  a s ing le  in tngraCed work ing env i ro -~ent ,  
so that our l ingu is ts  and lex icographers  can 
implement changes  and tes t  them i~ned ia ta ly  fo r  
the i r  e f fec ts  on t rans la t ion  qua l i ty ,  and modi fy  
or  de le te  the i r  add i t ions  w i th  ease ,  i f  des i red .  
S. Quant i ta t ive  Per formance 
The average  per fo rmance  of  the  LRC MT sys tem 
when t rans la t ing  techn ica l  manua ls  from German 
in to  Eng l i sh ,  runn in  S in  compi led INTERLISP on a 
DEC 2060 w i th  over  a mi l l i on  words of  phys ica l  
m~ory ,  has been measured a t  s l ight ly  under  2 
seconds of  CPU t ime per  input  word; th i s  inc ludes  
s to rage  management ( the  garbage  co l lec tor  a lone  
cousmes  45Z of a l l  CPU t ime on th i s  
l im i ted-address -space  mach ine) ,  pag ing ,  swapping,  
and I /0  ~ that  i s ,  a l l  forum of  overhead .  Our 
exper ience  on the  2060 invo lved  the  t rans la t ion  of  
some 330 pages of text ,  in  th ree  segments ,  over  a 
two year  period. 
On our  Symbol ica LM-2 L i sp  Machine.  w i th  256K 
vords  of  phys ica l  memory, p re l im inary  measurements  
ind icate  an average  pre fornance  of 6-10 seconds  
( rea l  time) per input  word, l i kewise  inc lud ing  a l l  
forms of  overhead .  Our LM-2 exper ience  to date  
has  invo lved  the  t rans la t ion  of  about  200 pages of  
text i n  a s ing le  run .  The pag ing  ra te  ind icates  
that ,  w i th  added memory (512K words i s  "s tandard"  
on these  mach ines) ,  we could  expect  a s ign i f i cant  
reduct ion  in  th i s  per formance f igure .  With a 
faster, second-generation Lisp Machine, we would 
expect  a more substant ia l  reduct ion  of  rea l - t ime 
process ing  requ i rements .  We hope to have had the  
oppor tun i ty  to conduct  an exper iment  on a t  leas t  
one such mach ine ,  by the  t ime th i s  conference  
convenes .  
C. Qualitative Per formance 
Measur ing MT sys tem throughput  i s  one th in  S. 
Measur ing "machine t rans la t ion  qua l i ty"  i s  qu i te  
another ,  s ince  the s tandards  fo r  measurement  (and 
for i n te rpret in  S the  measurements )  a re  little 
unders tood ,  and vary  w ide ly .  Thus,  "qua l i ty"  
measurements  are  of l i t t le  va l id i ty ,  However, 
because  there  i s  usua l ly  a cons iderab le  amount of  
lay  in teres t  in  such n~--bers,  we sha l l  endeavor  to 
ind icate  why they are  bas ica l l y  mean ing less ,  and 
then  repor t  our f ind ings  fo r  the  benef i t  of those  
who fee l  a need to know. 
Cer ta in ly  i t  i s  the  case that  "cor rec tness"  
numbers can theoret i ca l l y  g ive  some ind icat ion  of 
the quality of t rans la t ion .  If an ~ sys tem were 
sa id  to t rans la te ,  say ,  IOZ of its input 
cor rec t ly ,  no one would be l i ke ly  to cons ider  i t  
unab le .  The t roub le  i s ,  quoted f igures  a lmost  
un iversa l ly  hover  a t  the  oppos i te  ext reme of the  
speetr tun - -  around 90X -- fo r  }iT sys tems that  vary  
r~arkab ly  v . r . t ,  the  sub jec t ive  qua l i ty  of the i r  
output .  (S ince ,  to the  lay  person ,  "90Z cor rec t "  
seom8 to const i tu te  min ima l  acceptable qua l i ty .  
the  cons is tent  use  of  the  90Z f igure  should not  be 
surpr i s ing . )  
The t roub le  a r i ses  from at  leas t  the  
fo l low ing  human var iab les :  who per fo rms the  
meaaur~ent?  what ,  exact ly ,  is measured?  and by 
whet s tandards?  S ince  a lmost  a l l  measurements  a re  
per formed by the  vendor  of  the  sys tem in  quest ion .  
there  i s  obv ious  room for  b ias .  Second, i f  one 
measures '~orda  t rans la ted  cor rec t ly , "  whatever  
that means, that is a very different thin S from 
measuring, e .g . ,  "sentences t rans la ted  correctly." 
whatever  that  means .  F ina l ly ,  there  i s  the  mat ter  
of  de f in ing  the  operat ive  word, "cor rec t ' .  S ince 
no two t rans la tors  a re  l i ke ly  to agree  on what 
const i tu tes  a "cor rec t "  t rans la t ion  - -  tO say 
noth ing  of  es tab l i sh ing  a r igorous ,  ob jec t ive  
s tandard  - -  the  not ion  of  "cor rec tness"  w i l l  
na tura l l y  vary  depend ing  on who determines  i t .  I t  
w i l l  a l so  vary  depend ing  on the  amount of  t ime 
ava i lab le  to per fo rm the  measurement :  it i s  widely 
recogn ized  that  an ed i to r  v i i i  change more in  a 
g iven  t rans la t ion ,  the  more t ime he has  to work on 
i t .  F ina l ly ,  "cor rec tness"  w i l l  vary  depend ing  on 
the  use  to which the  t rans la t ion  i s  in tended to be 
put ,  the  c lass ica l  first d iv i s ion  be ing  
information acquisition vs. dissemination. 
There are  a few subs id ia ry  qua l i f i ca t ions  
that  must  be app l ied  to s ta tements  of  measured 
qua l i ty :  what k inds  of  text  were invo lved?  who 
chose them? d id  the  vendor  have access  to them 
before  the  cas t?  i f  so,  in  what form? and fo r  
bow l one?  These are  c r i t i ca l l y  impor tant  
quest ions  re la t ing  to the  in terpreta t ion  of the  
resu l t s .  It s tands  to reason  that ,  to get  the  
most t rus twor thy  f igures :  the  sys tem shou ld  be 
app l ied  Co such var ie t ies  of  text  as ic i s  
in tended to hand le  ( in  the  near  term, at  leas t ) ;  
the  texts  shou ld  be chosen by the  user ,  and not 
d ivu lged  to the  vendor  be forehand except  perhaps  
in  the  form of a l i s t  of words or  techn ica l  terms 
(in root form) which appear therein -- and that. 
for not too ion S a period of time before the test. 
With the  reader  bear ing  a l l  of the  above in  
mind,  we repor t  the  fo l low ing  qua l i ty  
measurements: during the last two years. LRC 
personnel have measured the quality of 
translations produced by the L~C MT system in 
terms of the percentage of sentences (actually. 
"translation units', since isolated words and 
phrases appear frequently) which were translated 
from German into acceptable English; if any change 
to the translated unit was necessary, however 
slight, the translation was considered incorrect; 
the  test runs were made once or twice for each 
text -- once, before the text was ever seen by the 
LRC staff (a "blind" run), and once more, after a 
few months of system enhancement based in part on 
the previous results (a "follow-up" run); the 
project sponsor always provided the LRC with a 
171 
l i s t  of the words and techn ica l  terms sa id  to be 
employed in  the text  ( the  l i s t  was sometimes 
incomplete ,  as one would expect  of human 
compi la t ions  of the vocabu lary  in a la rge  
document) .  The f i r s t  run,  on a 50-page text ,  was 
performed only a f te r  the text  had been s tud ied  fo r  
some t ime;  the second and th i rd  runs ,  on an 
80-page text ,  were performed both ways ( 'b l ind"  
and " fo l low-up ' ) ;  the four th  tes t  was a b l ind  run 
on a 200-page text .  The f igures  so measured 
var ied  from 55% to 85% depending on the text ,  and 
on whet~er the tes t  was a b l ind  or  fo l low-up  run .  
A f i f th  tes t  - -  a fo l low-up  run on the text  used 
in  the four th  tes t  - -  has a l ready  been per formed,  
but the qua l i ta t ive  resu l t s  a re  not ava i lab le  at  
th i s  wr i t ing .  The resu l t s  of th i s  run and two 
more b l ind  runs  on ~wo very  d i f fe rent  texts  
to ta l l ing  160 pages should be ava i lab le  when the 
conference  convenes;  these  qua l i ta t ive  resu l t s  a re  
a l l  to be measured by pro fess iona l  techn ica l  
t rans la tors  employed by the pro jec t  sponsor .  
D. Interpretation of the Results 
Any pos i t ive  conc lus ions  we might  draw based 
on such data  w i l l  be sub jec t  to cer ta in  
ob jec t ions .  I t  has been argued that ,  un less  an MT 
system const i tu tes  an a lmost  per fec t  t rans la tor ,  
i t  w i l l  be use less  in  any pract i ca l  se t t ing  \[Kay, 
1980\].  As we in terpret  i t ,  the argument proceeds 
something like this: 
(I) there are classical problems in Cemputational 
Linguistics that remain unsolved to this day 
(e.g., anaphora, quantifiers, conjunctions); 
(2) these problems will, in any practical setting, 
compound on one another so as to result in a 
very low probability that any given sentence 
will be correctly translated; 
(3) it is not in principle possible for a system 
suffering from malady (1) above to reliably 
identify and mark its probable errors; 
(4) if the human post-editor has to check every 
sentence to determine if it has been correctly 
translated, then the translation is useless. 
We accept claims (i) and (3) without question. We 
consider claim (2) to be a matter for empirical 
validation -- surely not a very controversial 
contention. As it happens, the substantial body 
of empirical evidence gathered by the LRC to date 
argues against this claim. By the time the 
conference convenes, we will have more definitive 
data to present ,  der ived  by the pro jec t  sponsor .  
Regarding (4 ) ,  we embrace the asaumpt ion that  
a human post -ed i to r  w i l l  have to check the ent i re  
t rans la t ion ,  sentence-by-sentence ;  but  we argue 
that  Kay"s conc lus ion  ( " then  the t rans la t ion  i s  
use less" )  i s  again  proper ly  a mat ter  fo r  empi r i ca l  
va l idat ion .  Meanwhile, we are operat ing  under the 
assumpt ion  that  th i s  conc lus ion  i s  patent ly  fa l se  
-- after all, where translation is taken 
seriously, human translations are routinely edited 
via exhaustive review, but no one claims that they 
are use less l  
E. Overa l l  Performance 
In th i s  sect ion  we advance a mean ingfu l .  
more -or - less  ob jec t ive  metr i c  by which any MT 
system can and should  be judged:  overa l l  
(man/machine) t rans la t ion  per fo rmance .  The idea 
i s  s imp le .  The MT system must ach ieve  two 
s imul taneous  goa ls :  first, the sys tem's  output  
must be acceptab le  to the t rans la tor /ed i to r  fo r  
the purpose of rev is ion ;  second,  the cost  of the 
to ta l  e f fo r t  ( inc lud ing  amort i za t ion  and 
maintenance of the hardware and so f tware)  must be 
less  than the cur rent  a l te rnat ive  fo r  l i ke  
material -- human translation followed by 
post-editing. 
There may be a s ign i f i cant  problem wi th  the 
re l iab i l i ty  of human rev isors"  judgements (which 
are  never the less  the best  ava i lab le ) :  the wr i te r  
has been to ld  by pro fess iona l  techn ica l  ed i to rs /  
t rans la tors  (potent ia l  users  of the LRC HT system) 
that  they look forward to ed i t ing  our machine 
t rans la t ions  "because the machine doesn ' t  care"  
\ [p r ivate  communicat ion\ ] .  (That i s ,  they would 
change more in  a machine t rans la t ion  than in a 
supposed ly  equ iva lent  human t rans la t ion  because 
they would not  have to worry about insu l t ing  the 
or ig ina l  t rans la tor  w i th  what s /he  might  cons ider  
"petty" changes.) Thus, the "correctness" 
s tandards  to be app l ied  to MT will very likely 
differ from those applied to human translation, 
simply due to the translation source. Since the 
er rors  committed by an MT system seldom resemble  
er rors  made by human t rans la tors ,  the poss ib i l i ty  
of a "Tur ing  tes t "  fo r  an MT system does not  ex is t  
a t  the cur rent  t ime.  
When the conference convenes, we will present 
such data as we have, bearing on the issue of 
overall performance using our system. Preliminary 
data from at least one outside assessment should 
be available. This information will tend co 
indicate the readiness of our system for use in a 
production translation enviroement. 
V DISCUSSION 
We have commented on the relative merits in 
large-scale application of several linguistic 
techn iques :  (a) a phrase-s t ructure  grammar; (b) 
syntact i c  features ;  (c) semant ic  features ;  (d) 
scored in terpretat ions ;  (e) t rans format ions  
indexed to specific ~ules; (f) a transfer 
component; and (g) attached procedures to effect 
translation. We also have presented our findings 
concerning the practical merits of several 
computational techniques: (a) a bottom-up, all- 
paths parser; (b) associated rule-body procedures; 
(c) spelling correction; (d) chart searching in 
case of analysis failures; and (e) recursive 
parsing of parenthetical expressions. We believe 
these findings constitute useful information about 
the state of the art in Computational Linguistics. 
172 
We wi l l  not have any f im empir ica l  evidence 
concerning overa l l  performance unt i l  l a te r  in 
1983, when the LEt )iT system wi l l  have been used 
in-house by our sponsor,  for  very - la rge-sca le  
translation experiments. However, we will have 
some pre l iminary  data from our sponsor source that  
can be adduced as a bas is  fo r  ext rapo la t ion .  (Our 
sponsor w i l l  indeed be using the data fo r  jus t  
such a purpose.)  This should const i tu te  usefu l  
in format ion about the s ta te  of the arc in Machine 
Trans la t ion  at  the Un ivers i ty  of Texas. To the 
extent  that  such f ind ings  are pos i t ive ,  they w i l l  
lend credence Co our c laims regard ing the 
pract i ca l  utility of the methods we employed. 
VI REY~CES 
go i te r ,  Ca., P. Chate l in ,  and P. Daun FraMe, 
"Present  and Future Paradigms in  the Automatized 
Translation of Languages," Proc. COLING 80, Tokyo, 
1980\[a\]. 
go i te r .  Ch., end M. Nedobejkine, "Russ ian-French 
at  GETA: Out l ine of the Method and Deta i led  
Y~umple," Proceedings of the Eighth In ternat iona l  
Conference on Computational L ingu is t i cs ,  Tokyo, 
Sept.  30 - Oct. 4, 1980\[b\] .  
Bresnan, J .  W., "A Rea l i s t i c  Transformat iona l  
Gr - - - - r , "  in  Hal le ,  8resuan, and Mi l le r  (eds . ) ,  
Linguistic Theory and Psychologica l  Rea l i ty .  MIT 
Press, 1977. 
Carbonnel,  J . ,  R. E. Cu l l ing ford ,  and A. V. 
Gershman, '~nowledge-Based Machine Trans la t ion , "  
Research Report #I~5. C$ Dept.)  Yale Un ivers i ty ,  
Dec. 1978. 
Cu l l ing ford ,  R. E., "Scr ip t  App l i ca t ion :  Computer 
Understanding of Newspaper S tor ies , "  Research 
Report #115, CS Dept. ,  Yale Un ivers i ty ,  1978. 
Damerau, F. J . ,  "Operat ing Sta t i s t i cs  fo r  the 
Transformat ional  Quest ion Answering System," AJCL 
7 ( I ) ,  January-March 1981. pp. 30-42. 
Goader, G., '~nbounded Dependencies and Coordinate 
S t ructure , "  in L ingu is t i c  Inqu i ry ,  12 (2 ) ,  Spring 
1981, pp. 155-184. 
Hayes, P. J . ,  and G. V. Mouradian, "F lex ib le  
Pars ing , "  AJCL, 7 (4) ,  October-December 1981, pp. 
232-242. 
Hendrix, G. G., etal., '~eveloping a Natural 
Language Interface to Complex Data," ACM 
Transact ions on Database Systems 3 (2 ) ,  June 1978, 
pp. 105-147. 
Kay, M., "The Proper Place of Men and Machines in 
Language and Translation," Technical Report, Xerox 
PARC, Palo Alto, California, 1980. 
King, M., '~es ign  Character i s t i cs  of a Machine 
Trans la t ion  System," Proc. 7oh LICAI, Vancouver, 
B.C., Canada, Aug. 1981, v. 1, pp. 43-46. 
Lehmaun, W. P. ,  W. S. Bennett ,  J .  Slocum. et  e l . ,  
"The METAL System," F inal  Technical  Report 
RADC-TR-80-374, Rome Air  Development Center,  
January 1981. 
Mart in,  W. A., K. W. Church, and R. S. Per i l ,  
"Pre l iminary  Analys is  of s Breadth -F i r s t  Pars ing 
Algor i thm: Theoret i ca l  and exper imenta l  resu l t s , "  
paper presented at  the Un ivers i ty  of Texas 
Symposium on Modell ing Human Pars ing St ra teg ies ,  
24-26 March 1981. 
Paxton, W. H., "A Framework fo r  Speech 
Understanding," Tech. Note 142, AI Center,  SRI 
International, Menlo Park, California? June 1977. 
Pet r i ck ,  S. R., "Transformat iona l  Ana lys i s , "  in R. 
Ruet in (ed . ) ,  Natural  Language Process ing.  
A lgor i thmics  Press ,  New York, 1973, pp. 27-41. 
P ra t t ,  V. R., "AL ingu isc ics  Or iented Progr- - - - ing 
Language," Proc. 3rd IJCAI, Stanford Un ivers i ty ,  
Ca l i fo rn ia ,  August 1973, pp. 372-381. 
Robinson, J. J., '~IAGRAM: A Gr----ar for 
Dialogues," CACM 25 (I), Jan. 1982. 
Sager, N. Natural  Language In format ion 
Process ing.  Addison-Wesley. Reading, 
Massachusetts ,  1981. 
Sloctm. J . ,  "A P ract i ca l  Comparison of Pars ing 
St ra teg ies  fo r  Machine Trans la t ion  and Other 
Natural  Language Process ing Purposes ,"  Tech. 
Report NL-41, Department of Computer Sc iences.  
Un ivers i ty  of Texas, August 1981. 
Slocum. J . ,  'hfhe LRC Machine Trans la t ion  System: 
An App l i ca t ion  of S ta te -o f - the -Ar t  Text and 
Natura l  Language Process ing Techniques,"  COL ING 
82, Prague, C=echoslovakia, Ju ly  5-10, 1982. 
Small,  S. ,  '~ord Expert Pars ing:  A Theory of 
D is t r ibuted  Word-Based Natural  Language 
Unders tand ing , "  Tech. Rep. 954, CS Dept. ,  Univ. of 
Maryland, 1980. 
Weischedel,  R. M., and J .  E. Black, " I f  the Parser  
Fa i l s , "  Proceedings of the 18th Annual Meeting of 
the ACL, Univ. of Pennsylvania,  June 19-22, 1980. 
Winograd, T. Understanding Natural  Language. 
Academic Press ,  New York, 1972. 
Woods, W. A., "Transition Network Grammars for 
Natural Language Analysis," CACM, 13 (I0), October 
1970, pp. 591-608. 
Woods, W. A.) "Syntax, Semantics, and Speech." BEN 
Report 3067, Bolt, geranek, and Newman, Inc., 
Cambridge, Massachusetts ,  Apr i l  1975. 
Woods, W. A.) "Cascaded ATN Grammars," AJCL, 6 
(i), January-March 1980, pp. 1-12. 
173 
