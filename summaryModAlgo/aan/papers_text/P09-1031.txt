Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 271?279,
Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLP
A Metric-based Framework for Automatic Taxonomy Induction 
 
 
Hui Yang 
Language Technologies Institute 
School of Computer Science  
Carnegie Mellon University 
huiyang@cs.cmu.edu 
Jamie Callan 
Language Technologies Institute 
School of Computer Science 
Carnegie Mellon University 
callan@cs.cmu.edu 
  
 
Abstract 
This paper presents a novel metric-based 
framework for the task of automatic taxonomy 
induction. The framework incrementally clus-
ters terms based on ontology metric, a score 
indicating semantic distance; and transforms 
the task into a multi-criteria optimization 
based on minimization of taxonomy structures 
and modeling of term abstractness. It com-
bines the strengths of both lexico-syntactic 
patterns and clustering through incorporating 
heterogeneous features. The flexible design of 
the framework allows a further study on which 
features are the best for the task under various 
conditions. The experiments not only show 
that our system achieves higher F1-measure 
than other state-of-the-art systems, but also re-
veal the interaction between features and vari-
ous types of relations, as well as the interac-
tion between features and term abstractness.  
1 Introduction 
Automatic taxonomy induction is an important 
task in the fields of Natural Language 
Processing, Knowledge Management, and Se-
mantic Web. It has been receiving increasing 
attention because semantic taxonomies, such as 
WordNet (Fellbaum, 1998), play an important 
role in solving knowledge-rich problems, includ-
ing question answering (Harabagiu et al, 2003) 
and textual entailment (Geffet and Dagan, 2005). 
Nevertheless, most existing taxonomies are ma-
nually created at great cost. These taxonomies 
are rarely complete; it is difficult to include new 
terms in them from emerging or rapidly changing 
domains. Moreover, manual taxonomy construc-
tion is time-consuming, which may make it un-
feasible for specialized domains and personalized 
tasks. Automatic taxonomy induction is a solu-
tion to augment existing resources and to pro-
duce new taxonomies for such domains and 
tasks. 
Automatic taxonomy induction can be decom-
posed into two subtasks: term extraction and re-
lation formation. Since term extraction is rela-
tively easy, relation formation becomes the focus 
of most research on automatic taxonomy induc-
tion. In this paper, we also assume that terms in a 
taxonomy are given and concentrate on the sub-
task of relation formation. 
Existing work on automatic taxonomy induc-
tion has been conducted under a variety of 
names, such as ontology learning, semantic class 
learning, semantic relation classification, and 
relation extraction. The approaches fall into two 
main categories: pattern-based and clustering-
based. Pattern-based approaches define lexical-
syntactic patterns for relations, and use these pat-
terns to discover instances of relations. Cluster-
ing-based approaches hierarchically cluster terms 
based on similarities of their meanings usually 
represented by a vector of quantifiable features. 
Pattern-based approaches are known for their 
high accuracy in recognizing instances of rela-
tions if the patterns are carefully chosen, either 
manually (Berland and Charniak, 1999; Kozare-
va et al, 2008) or via automatic bootstrapping 
(Hearst, 1992; Widdows and Dorow, 2002; Girju 
et al, 2003). The approaches, however, suffer 
from sparse coverage of patterns in a given cor-
pus. Recent studies (Etzioni et al, 2005; Kozare-
va et al, 2008) show that if the size of a corpus, 
such as the Web, is nearly unlimited, a pattern 
has a higher chance to explicitly appear in the 
corpus. However, corpus size is often not that 
large; hence the problem still exists. Moreover, 
since patterns usually extract instances in pairs, 
the approaches suffer from the problem of incon-
sistent concept chains after connecting pairs of 
instances to form taxonomy hierarchies.  
Clustering-based approaches have a main ad-
vantage that they are able to discover relations 
271
which do not explicitly appear in text. They also 
avoid the problem of inconsistent chains by ad-
dressing the structure of a taxonomy globally 
from the outset. Nevertheless, it is generally be-
lieved that clustering-based approaches cannot 
generate relations as accurate as pattern-based 
approaches. Moreover, their performance is 
largely influenced by the types of features used. 
The common types of features include contextual 
(Lin, 1998), co-occurrence (Yang and Callan, 
2008), and syntactic dependency (Pantel and Lin, 
2002; Pantel and Ravichandran, 2004). So far 
there is no systematic study on which features 
are the best for automatic taxonomy induction 
under various conditions. 
This paper presents a metric-based taxonomy 
induction framework. It combines the strengths 
of both pattern-based and clustering-based ap-
proaches by incorporating lexico-syntactic pat-
terns as one type of features in a clustering 
framework. The framework integrates contex-
tual, co-occurrence, syntactic dependency, lexi-
cal-syntactic patterns, and other features to learn 
an ontology metric, a score indicating semantic 
distance, for each pair of terms in a taxonomy; it 
then incrementally clusters terms based on their 
ontology metric scores. The incremental cluster-
ing is transformed into an optimization problem 
based on two assumptions: minimum evolution 
and abstractness. The flexible design of the 
framework allows a further study of the interac-
tion between features and relations, as well as 
that between features and term abstractness. 
2 Related Work 
There has been a substantial amount of research 
on automatic taxonomy induction. As we men-
tioned earlier, two main approaches are pattern-
based and clustering-based.  
Pattern-based approaches are the main trend 
for automatic taxonomy induction. Though suf-
fering from the problems of sparse coverage and 
inconsistent chains, they are still popular due to 
their simplicity and high accuracy. They have 
been applied to extract various types of lexical 
and semantic relations, including is-a, part-of, 
sibling, synonym, causal, and many others.  
Pattern-based approaches started from and still 
pay a great deal of attention to the most common  
is-a relations. Hearst (1992) pioneered using a 
hand crafted list of hyponym patterns as seeds 
and employing bootstrapping to discover is-a 
relations. Since then, many approaches (Mann, 
2002; Etzioni et al, 2005; Snow et al, 2005) 
have used Hearst-style patterns in their work on 
is-a relations. For instance, Mann (2002) ex-
tracted is-a relations for proper nouns by Hearst-
style patterns. Pantel et al (2004) extended is-a 
relation acquisition towards terascale, and auto-
matically identified hypernym patterns by mi-
nimal edit distance. 
Another common relation is sibling, which de-
scribes the relation of sharing similar meanings 
and being members of the same class. Terms in 
sibling relations are also known as class mem-
bers or similar terms. Inspired by the conjunction 
and appositive structures, Riloff and Shepherd 
(1997), Roark and Charniak (1998) used co-
occurrence statistics in local context to discover 
sibling relations. The KnowItAll system (Etzioni 
et al, 2005) extended the work in (Hearst, 1992) 
and bootstrapped patterns on the Web to discover 
siblings; it also ranked and selected the patterns 
by statistical measures. Widdows and Dorow 
(2002) combined symmetric patterns and graph 
link analysis to discover sibling relations. Davi-
dov and Rappoport (2006) also used symmetric 
patterns for this task. Recently, Kozareva et al 
(2008) combined a double-anchored hyponym 
pattern with graph structure to extract siblings. 
The third common relation is part-of. Berland 
and Charniak (1999) used two meronym patterns 
to discover part-of relations, and also used statis-
tical measures to rank and select the matching 
instances. Girju et al (2003) took a similar ap-
proach to Hearst (1992) for part-of relations. 
Other types of relations that have been studied 
by pattern-based approaches include question-
answer relations (such as birthdates and inven-
tor) (Ravichandran and Hovy, 2002), synonyms 
and antonyms (Lin et al, 2003), general purpose 
analogy (Turney et al, 2003), verb relations (in-
cluding similarity, strength, antonym, enable-
ment and temporal) (Chklovski and Pantel, 
2004), entailment (Szpektor et al, 2004), and 
more specific relations, such as purpose, creation 
(Cimiano and Wenderoth, 2007), LivesIn, and 
EmployedBy (Bunescu and Mooney , 2007).  
 The most commonly used technique in pat-
tern-based approaches is bootstrapping (Hearst, 
1992; Etzioni et al, 2005; Girju et al, 2003; Ra-
vichandran and Hovy, 2002; Pantel and Pennac-
chiotti, 2006). It utilizes a few man-crafted seed 
patterns to extract instances from corpora, then 
extracts new patterns using these instances, and 
continues the cycle to find new instances and 
new patterns. It is effective and scalable to large 
datasets; however, uncontrolled bootstrapping 
272
soon generates undesired instances once a noisy 
pattern brought into the cycle. 
 To aid bootstrapping, methods of pattern 
quality control are widely applied. Statistical 
measures, such as point-wise mutual information 
(Etzioni et al, 2005; Pantel and Pennacchiotti, 
2006) and conditional probability (Cimiano and 
Wenderoth, 2007),   have been shown to be ef-
fective to rank and select patterns and instances. 
Pattern quality control is also investigated by 
using WordNet (Girju et al, 2006), graph struc-
tures built among terms (Widdows and Dorow, 
2002; Kozareva et al, 2008), and pattern clusters 
(Davidov and Rappoport, 2008). 
Clustering-based approaches usually represent 
word contexts as vectors and cluster words based 
on similarities of the vectors (Brown et al, 1992; 
Lin, 1998). Besides contextual features, the vec-
tors can also be represented by verb-noun rela-
tions (Pereira et al, 1993), syntactic dependency 
(Pantel and Ravichandran, 2004; Snow et al, 
2005), co-occurrence (Yang and Callan, 2008), 
conjunction and appositive features (Caraballo, 
1999). More work is described in (Buitelaar et 
al., 2005; Cimiano and Volker, 2005). Cluster-
ing-based approaches allow discovery of rela-
tions which do not explicitly appear in text. Pan-
tel and Pennacchiotti (2006), however, pointed 
out that clustering-based approaches generally 
fail to produce coherent cluster for small corpora. 
In addition, clustering-based approaches had on-
ly applied to solve is-a and sibling relations. 
Many clustering-based approaches face the 
challenge of appropriately labeling non-leaf clus-
ters. The labeling amplifies the difficulty in crea-
tion and evaluation of taxonomies. Agglomera-
tive clustering (Brown et al, 1992; Caraballo, 
1999; Rosenfeld and Feldman, 2007; Yang and 
Callan, 2008) iteratively merges the most similar 
clusters into bigger clusters, which need to be 
labeled. Divisive clustering, such as CBC (Clus-
tering By Committee) which constructs cluster 
centroids by averaging the feature vectors of a 
subset of carefully chosen cluster members (Pan-
tel and Lin, 2002; Pantel and Ravichandran, 
2004), also need to label the parents of split clus-
ters. In this paper, we take an incremental clus-
tering approach, in which terms and relations are 
added into a taxonomy one at a time, and their 
parents are from the existing taxonomy. The ad-
vantage of the incremental approach is that it 
eliminates the trouble of inventing cluster labels 
and concentrates on placing terms in the correct 
positions in a taxonomy hierarchy.  
The work by Snow et al (2006) is the most 
similar to ours because they also took an incre-
mental approach to construct taxonomies. In their 
work, a taxonomy grows based on maximization 
of conditional probability of relations given evi-
dence; while in our work based on optimization 
of taxonomy structures and modeling of term 
abstractness. Moreover, our approach employs 
heterogeneous features from a wide range; while 
their approach only used syntactic dependency. 
We compare system performance between (Snow 
et al, 2006) and our framework in Section 5.  
3 The Features 
The features used in this work are indicators of 
semantic relations between terms. Given two in-
put terms yx cc , , a feature is defined as a func-
tion generating a single numeric score 
?),( yx cch ? or a vector of numeric scores 
?),( yx cch ?n. The features include contextual, 
co-occurrence, syntactic dependency, lexical-
syntactic patterns, and miscellaneous.  
The first set of features captures contextual in-
formation of terms. According to Distributional 
Hypothesis (Harris, 1954), words appearing in 
similar contexts tend to be similar. Therefore, 
word meanings can be inferred from and 
represented by contexts. Based on the hypothe-
sis, we develop the following features: (1) Glob-
al Context KL-Divergence: The global context of 
each input term is the search results collected 
through querying search engines against several 
corpora (Details in Section 5.1). It is built into a 
unigram language model without smoothing for 
each term. This feature function measures the 
Kullback-Leibler divergence (KL divergence) 
between the language models associated with the 
two inputs. (2) Local Context KL-Divergence: 
The local context is the collection of all the left 
two and the right two words surrounding an input 
term. Similarly, the local context is built into a 
unigram language model without smoothing for 
each term; the feature function outputs KL diver-
gence between the models. 
The second set of features is co-occurrence. In 
our work, co-occurrence is measured by point-
wise mutual information between two terms:  
)()(
),(
log),(
yx
yx
yx
cCountcCount
ccCount
ccpmi =  
where Count(.) is defined as the number of doc-
uments or sentences containing the term(s); or n 
as in ?Results 1-10 of about n for term? appear-
ing on the first page of Google search results for 
a term or the concatenation of a term pair. Based 
273
on different definitions of Count(.), we have (3) 
Document PMI, (4) Sentence PMI, and (5) 
Google PMI as the co-occurrence features. 
The third set of features employs syntactic de-
pendency analysis. We have (6) Minipar Syntac-
tic Distance to measure the average length of the 
shortest syntactic paths (in the first syntactic 
parse tree returned by Minipar1) between two 
terms in sentences containing them, (7) Modifier 
Overlap, (8) Object Overlap, (9) Subject Over-
lap, and (10) Verb Overlap to measure the num-
ber of overlaps between modifiers, objects, sub-
jects, and verbs, respectively, for the two terms 
in sentences containing them. We use Assert2 to 
label the semantic roles. 
The fourth set of features is lexical-syntactic 
patterns. We have (11) Hypernym Patterns based 
on patterns proposed by (Hearst, 1992) and 
(Snow et al, 2005), (12) Sibling Patterns which 
are basically conjunctions, and (13) Part-of Pat-
terns based on patterns proposed by (Girju et al, 
2003) and (Cimiano and Wenderoth, 2007). Ta-
ble 1 lists all patterns. Each feature function re-
turns a vector of scores for two input terms, one 
score per pattern. A score is 1 if two terms match 
a pattern in text, 0 otherwise. 
The last set of features is miscellaneous. We 
have (14) Word Length Difference to measure the 
length difference between two terms, and (15) 
Definition Overlap to measure the number of 
word overlaps between the term definitions ob-
tained by querying Google with ?define:term?. 
These heterogeneous features vary from sim-
ple statistics to complicated syntactic dependen-
cy features, basic word length to comprehensive 
Web-based contextual features. The flexible de-
sign of our learning framework allows us to use 
all of them, and even allows us to use different 
sets of them under different conditions, for in-
stance, different types of relations and different 
abstraction levels. We study the interaction be-
                                                 
1
 http://www.cs.ualberta.ca/lindek/minipar.htm. 
2
 http://cemantix.org/assert. 
tween features and relations and that between 
features and abstractness in Section 5. 
4 The Metric-based Framework 
This section presents the metric-based frame-
work which incrementally clusters terms to form 
taxonomies. By minimizing the changes of tax-
onomy structures and modeling term abstractness 
at each step, it finds the optimal position for each 
term in a taxonomy. We first introduce defini-
tions, terminologies and assumptions about tax-
onomies; then, we formulate automatic taxono-
my induction as a multi-criterion optimization 
and solve it by a greedy algorithm; lastly, we 
show how to estimate ontology metrics.      
4.1 Taxonomies, Ontology Metric, Assump-
tions, and Information Functions 
We define a taxonomy T as a data model that 
represents a set of terms C and a set of relations 
R between these terms. T can be written as 
T(C,R). Note that for the subtask of relation for-
mation, we assume that the term set C is given. A 
full taxonomy is a tree containing all the terms in 
C. A partial taxonomy is a tree containing only a 
subset of terms in C.  
In our framework, automatic taxonomy induc-
tion is the process to construct a full taxonomy T?
given a set of terms C and an initial partial tax-
onomy ),( 000 RST , where CS ?0 . Note that T0 is 
possibly empty. The process starts from the ini-
tial partial taxonomy T0 and randomly adds terms 
from C to T0 one by one, until a full taxonomy is 
formed, i.e., all terms in C are added. 
Ontology Metric 
We define an ontology metric as a distance 
measure between two terms (cx,cy) in a taxonomy 
T(C,R). Formally, it is a function ?? CCd : ?+, 
where C is the set of terms in T.  An ontology 
metric d on a taxonomy T with edge weights w 
for any term pair (cx,cy)?C is the sum of all edge 
weights along the shortest path between the pair: 
?
?
=
),(
,),(
,
)(),(
yxPe
yxyxwT
yx
ewccd
 
Hypernym Patterns Sibling Patterns 
NPx (,)?and/or other NPy NPx and/or NPy 
such NPy as NPx Part-of Patterns 
NPy (,)? such as NPx NPx of NPy 
NPy (,)? including NPx NPy?s NPx 
NPy (,)? especially NPx NPy has/had/have NPx 
NPy like NPx NPy is made (up)? of NPx 
NPy called NPx NPy comprises NPx 
NPx is a/an NPy NPy consists of NPx 
NPx , a/an NPy  
Table 1. Lexico-Syntactic Patterns. 
 
Figure 1. Illustration of Ontology Metric. 
274
where ),( yxP  is the set of edges defining the 
shortest path from term cx to cy . Figure 1 illu-
strates ontology metrics for a 5-node taxonomy. 
Section 4.3 presents the details of learning ontol-
ogy metrics. 
Information Functions 
The amount of information in a taxonomy T is 
measured and represented by an information 
function Info(T). An information function is de-
fined as the sum of the ontology metrics among a 
set of term pairs. The function can be defined 
over a taxonomy, or on a single level of a tax-
onomy. For a taxonomy T(C,R), we define its 
information function as: 
?
?<
=
Cycxcyx
yx ccdTInfo
,,
),()(   (1) 
Similarly, we define the information function 
for an abstraction level Li as:  
?
?<
=
iLycxcyx
yxii ccdLInfo
,,
),()(   (2) 
where Li is the subset of terms lying at the ith lev-
el of a taxonomy T. For example, in Figure 1, 
node 1 is at level L1, node 2 and node 5 level L2. 
Assumptions 
Given the above definitions about taxonomies, 
we make the following assumptions: 
Minimum Evolution Assumption. Inspired by 
the minimum evolution tree selection criterion 
widely used in phylogeny (Hendy and Penny, 
1985), we assume that a good taxonomy not only 
minimizes the overall semantic distance among 
the terms but also avoid dramatic changes. Con-
struction of a full taxonomy is proceeded by add-
ing terms one at a time, which yields a series of 
partial taxonomies. After adding each term, the 
current taxonomy Tn+1 from the previous tax-
onomy Tn is one that introduces the least changes 
between the information in the two taxonomies: 
),(minarg '
'
1 TTInfoT n
T
n ?=+  
where the information change function is 
|)()(| ),( baba TInfoTInfoTTInfo ?=? .  
Abstractness Assumption. In a taxonomy, con-
crete concepts usually lay at the bottom of the 
hierarchy while abstract concepts often occupy 
the intermediate and top levels. Concrete con-
cepts often represent physical entities, such as 
?basketball? and ?mercury pollution?. While ab-
stract concepts, such as ?science? and ?econo-
my?, do not have a physical form thus we must 
imagine their existence. This obvious difference 
suggests that there is a need to treat them diffe-
rently in taxonomy induction. Hence we assume 
that terms at the same abstraction level have 
common characteristics and share the same Info(.) 
function. We also assume that terms at different 
abstraction levels have different characteristics; 
hence they do not necessarily share the same  
Info(.) function. That is to say, ,concept  Tc ??
, leveln abstractio TLi ?  (.). uses ii InfocLc ??  
4.2 Problem Formulation 
The Minimum Evolution Objective 
Based on the minimum evolution assumption, we 
define the goal of taxonomy induction is to find 
the optimal full taxonomy T?  such that the infor-
mation changes are the least since the initial par-
tial taxonomy T0, i.e., to find:  
),(minarg? '0
'
TTInfoT
T
?=   (3) 
where 'T  is a full taxonomy, i.e., the set of terms 
in 'T  equals C. 
To find the optimal solution for Equation (3),  
T? , we need to find the optimal term set C? and 
the optimal relation set R? . Since the optimal term 
set for a full taxonomy is always C, the only un-
known part left is R? . Thus, Equation (3) can be 
transformed equivalently into:
 
)),(),,((minarg? 000''
'
RSTRCTInfoR
R
?=  
Note that in the framework, terms are added 
incrementally into a taxonomy. Each term inser-
tion yields a new partial taxonomy T. By the 
minimum evolution assumption, the optimal next 
partial taxonomy is one gives the least informa-
tion change. Therefore, the updating function for 
the set of relations 1+nR after a new term z is in-
serted can be calculated as: 
)),(),},{((minarg? '
'
nnn
R
RSTRzSTInfoR ??=
 
By plugging in the definition of the information 
change function (.,.)Info? in Section 4.1 and Equ-
ation (1), the updating function becomes: 
|),(),(|minarg?
,}{,'
??
???
?=
nSycxc
yx
znSycxc
yx
R
ccdccdR
 
The above updating function can be transformed 
into a minimization problem: 
yx
ccdccdu
ccdccdu
u
znSycxc
yx
nSycxc
yx
nSycxc
yx
znSycxc
yx
<
??
??
??
??
???
???
}{,,
,}{,
),(),(                 
),(),(    subject to
 
min
 
The minimization follows the minimum evolu-
tion assumption; hence we call it the minimum 
evolution objective. 
 
275
The Abstractness Objective 
The abstractness assumption suggests that term 
abstractness should be modeled explicitly by 
learning separate information functions for terms 
at different abstraction levels. We approximate 
an information function by a linear interpolation 
of some underlying feature functions. Each ab-
straction level Li is characterized by its own in-
formation function Infoi(.). The least square fit of 
Infoi(.) is: .|)(|min 2iTiii HWLInfo ?  
By plugging Equation (2) and minimizing over 
every abstraction level, we have: 
2
,,
,
)),(),((min yxji
j
ji
i iLycxc
yx cchwccd ?? ? ?
?
where jih , (.,.) is the jth underlying feature func-
tion for term pairs at level Li, jiw , is the weight 
for jih , (.,.). This minimization follows the ab-
stractness assumption; hence we call it the ab-
stractness objective. 
The Multi-Criterion Optimization Algorithm 
We propose that both minimum evolution and 
abstractness objectives need to be satisfied. To 
optimize multiple criteria, the Pareto optimality 
needs to be satisfied (Boyd and Vandenberghe, 
2004). We handle this by introducing   0,1 to 
control the contribution of each objective. The 
multi-criterion optimization function is: 
yx
cchwccdv
ccdccdu
ccdccdu
vu
yxji
j
ji
i Lcc
yx
zScc
yx
Scc
yx
Scc
yx
zScc
yx
iyx
n
yx
n
yx
n
yx
n
yx
<
?=
??
??
?+
?? ?
??
??
?
???
???
2)),(),((                              
),(),(                   
),(),(      subject to
)1(min
,,
,
}{,,
,}{,
??
The above optimization can be solved by a gree-
dy optimization algorithm. At each term insertion 
step, it produces a new partial taxonomy by add-
ing to the existing partial taxonomy a new term z, 
and a new set of relations R(z,.). z is attached to 
every nodes in the existing partial taxonomy; and 
the algorithm selects the optimal position indi-
cated by R(z,.), which minimizes the multi-
criterion objective function. The algorithm is: 
);,(
)};)1((min{arg
;
\
RST
vuRR
{z}SS
SCz
(z,.)R
Output 
            
            
 foreach
?? ?+??
??
?
   
The above algorithm presents a general incre-
mental clustering procedure to construct taxono-
mies. By minimizing the taxonomy structure 
changes and modeling term abstractness at each 
step, it finds the optimal position of each term in 
the taxonomy hierarchy. 
4.3 Estimating Ontology Metric 
Learning a good ontology metric is important for 
the multi-criterion optimization algorithm. In this 
work, the estimation and prediction of ontology 
metric are achieved by ridge regression (Hastie et 
al., 2001). In the training data, an ontology me-
tric d(cx,cy) for a term pair (cx,cy) is generated by 
assuming every edge weight as 1 and summing 
up all the edge weights along the shortest path 
from cx to cy. We assume that there are some un-
derlying feature functions which measure the 
semantic distance from term cx to cy. A weighted 
combination of these functions approximates the 
ontology metric for (cx,cy): 
?= ),(),( yxjjj cchwyxd  
where jw  is the jth weight for ),( yxj cch , the jth 
feature function. The feature functions are gener-
ated as mentioned in Section 3.  
5 Experiments  
5.1 Data 
The gold standards used in the evaluation are 
hypernym taxonomies extracted from WordNet 
and ODP (Open Directory Project), and me-
ronym taxonomies extracted from WordNet. In 
WordNet taxonomy extraction, we only use the 
word senses within a particular taxonomy to en-
sure no ambiguity. In ODP taxonomy extraction, 
we parse the topic lines, such as ?Topic 
r:id=`Top/Arts/Movies??, in the XML databases 
to obtain relations, such as is_a(movies, arts). In 
total, there are 100 hypernym taxonomies, 50 
each extracted from WordNet3 and ODP4, and 50 
meronym taxonomies from WordNet5. Table 2  
                                                 
3
 WordNet hypernym taxonomies are from 12 topics: ga-
thering, professional, people, building, place, milk, meal, 
water, beverage, alcohol, dish, and herb. 
4
 ODP hypernym taxonomies are from 16 topics: computers, 
robotics, intranet, mobile computing, database, operating 
system, linux, tex, software, computer science, data commu-
nication, algorithms, data formats, security multimedia, and 
artificial intelligence. 
5
 WordNet meronym taxonomies are from 15 topics: bed, 
car, building, lamp, earth, television, body, drama, theatre, 
water, airplane, piano, book, computer, and watch. 
Statistics WN/is-a ODP/is-a WN/part-of 
#taxonomies 50 50 50 
#terms 1,964 2,210 1,812 
Avg #terms 39 44 37 
Avg depth 6 6 5 
Table 2. Data Statistics. 
 
276
summarizes the data statistics. 
We also use two Web-based auxiliary datasets 
to generate features mentioned in Section 3: 
? Wikipedia corpus. The entire Wikipedia corpus 
is downloaded and indexed by Indri6. The top 
100 documents returned by Indri are the global 
context of a term when querying with the term.  
? Google corpus. A collection of the top 1000 
documents by querying Google using each 
term, and each term pair. Each top 1000 docu-
ments are the global context of a query term. 
Both corpora are split into sentences and are used 
to generate contextual, co-occurrence, syntactic 
dependency and lexico-syntactic pattern features.  
5.2 Methodology 
We evaluate the quality of automatic generated 
taxonomies by comparing them with the gold 
standards in terms of precision, recall and F1-
measure. F1-measure is calculated as 2*P*R/ 
(P+R), where P is precision, the percentage of 
correctly returned relations out of the total re-
turned relations, R is recall, the percentage of 
correctly returned relations out of the total rela-
tions in the gold standard. 
Leave-one-out cross validation is used to aver-
age the system performance across different 
training and test datasets. For each 50 datasets 
from WordNet hypernyms, WordNet meronyms 
or ODP hypernyms, we randomly pick 49 of 
them to generate training data, and test on the 
remaining dataset. We repeat the process for 50 
times, with different training and test sets at each 
                                                 
6
 http://www.lemurproject.org/indri/. 
time, and report the averaged precision, recall 
and F1-measure across all 50 runs. 
We also group the fifteen features in Section 3 
into six sets: contextual, co-concurrence, pat-
terns, syntactic dependency, word length differ-
ence and definition. Each set is turned on one by 
one for experiments in Section 5.4 and 5.5. 
5.3 Performance of Taxonomy Induction 
In this section, we compare the following auto-
matic taxonomy induction systems: HE, the sys-
tem by Hearst (1992) with 6 hypernym patterns; 
GI, the system by Girju et al (2003) with 3 me-
ronym patterns; PR, the probabilistic framework 
by Snow et al (2006); and ME, the metric-based 
framework proposed in this paper. To have a fair 
comparison, for PR, we estimate the conditional 
probability of a relation given the evidence 
P(Rij|Eij), as in (Snow et al 2006), by using the 
same set of features as in ME. 
Table 3 shows precision, recall, and F1-
measure of each system for WordNet hypernyms 
(is-a), WordNet meronyms (part-of) and ODP 
hypernyms (is-a). Bold font indicates the best 
performance in a column. Note that HE is not 
applicable to part-of, so is GI to is-a. 
Table 3 shows that systems using heterogene-
ous features (PR and ME) achieve higher F1-
measure than systems only using patterns (HE 
and GI) with a significant absolute gain of >30%. 
Generally speaking, pattern-based systems show 
higher precision and lower recall, while systems 
using heterogeneous features show lower preci-
sion and higher recall. However, when consider-
ing both precision and recall, using heterogene-
ous features is more effective than just using pat-
terns. The proposed system ME consistently pro-
duces the best F1-measure for all three tasks.  
The performance of the systems for ODP/is-a 
is worse than that for WordNet/is-a. This may be 
because there is more noise in ODP than in 
WordNet/is-a 
System Precision Recall F1-measure 
HE 0.85 0.32 0.46 
GI n/a n/a n/a 
PR 0.75 0.73 0.74 
ME 0.82 0.79 0.82 
ODP/is-a 
System Precision Recall F1-measure 
HE 0.31 0.29 0.30 
GI n/a n/a n/a 
PR 0.60 0.72 0.65 
ME 0.64 0.70 0.67 
WordNet/part-of 
System Precision Recall F1-measure 
HE n/a n/a n/a 
GI 0.75 0.25 0.38 
PR 0.68 0.52 0.59 
ME 0.69 0.55 0.61 
Table 3. System Performance. 
Feature  is-a sibling part-
of 
Benefited 
Relations  
Contextual 0.21 0.42 0.12 sibling 
Co-occur. 0.48 0.41 0.28 All 
Patterns 0.46 0.41 0.30 All 
Syntactic 0.22 0.36 0.12 sibling 
Word Leng. 0.16 0.16 0.15 All but 
limited 
Definition 0.12 0.18 0.10 Sibling but 
limited 
Best Features Co-
occur., 
patterns  
Contextual, 
co-occur., 
patterns 
Co-
occur., 
patterns 
 
Table 4. F1-measure for Features vs. Relations: WordNet. 
277
WordNet. For example, under artificial intelli-
gence, ODP has neural networks, natural lan-
guage and academic departments. Clearly, aca-
demic departments is not a hyponym of artificial 
intelligence. The noise in ODP interferes with 
the learning process, thus hurts the performance. 
5.4 Features vs. Relations 
This section studies the impact of different sets 
of features on different types of relations. Table 4 
shows F1-measure of using each set of features 
alone on taxonomy induction for WordNet is-a, 
sibling, and part-of relations. Bold font means a 
feature set gives a major contribution to the task 
of automatic taxonomy induction for a particular 
type of relation. 
Table 4 shows that different relations favor 
different sets of features.  Both co-occurrence 
and lexico-syntactic patterns work well for all 
three types of relations. It is interesting to see 
that simple co-occurrence statistics work as good 
as lexico-syntactic patterns. Contextual features 
work well for sibling relations, but not for is-a 
and part-of. Syntactic features also work well for 
sibling, but not for is-a and part-of. The similar 
behavior of contextual and syntactic features 
may be because that four out of five syntactic 
features (Modifier, Subject, Object, and Verb 
overlaps) are just surrounding context for a term. 
Comparing the is-a and part-of columns in 
Table 4 and the ME rows in Table 3, we notice a 
significant difference in F1-measure. It indicates 
that combination of heterogeneous features gives 
more rise to the system performance than a sin-
gle set of features does. 
5.5 Features vs. Abstractness 
This section studies the impact of different sets 
of features on terms at different abstraction le-
vels. In the experiments, F1-measure is evaluated 
for terms at each level of a taxonomy, not the 
whole taxonomy. Table 5 and 6 demonstrate F1-
measure of using each set of features alone on 
each abstraction levels. Columns 2-6 are indices 
of the levels in a taxonomy. The larger the indic-
es are, the lower the levels. Higher levels contain 
abstract terms, while lower levels contain con-
crete terms. L1 is ignored here since it only con-
tains a single term, the root. Bold font indicates 
good performance in a column. 
Both tables show that abstract terms and con-
crete terms favor different sets of features. In 
particular, contextual, co-occurrence, pattern, 
and syntactic features work well for terms at L4-
L6, i.e., concrete terms; co-occurrence works well 
for terms at L2-L3, i.e., abstract terms. This differ-
ence indicates that terms at different abstraction 
levels have different characteristics; it confirms 
our abstractness assumption in Section 4.1.  
We also observe that for abstract terms in 
WordNet, patterns work better than contextual 
features; while for abstract terms in ODP, the 
conclusion is the opposite. This may be because 
that WordNet has a richer vocabulary and a more 
rigid definition of hypernyms, and hence is-a 
relations in WordNet are recognized more effec-
tively by using lexico-syntactic patterns; while 
ODP contains more noise, and hence it favors 
features requiring less rigidity, such as the con-
textual features generated from the Web. 
6 Conclusions  
This paper presents a novel metric-based tax-
onomy induction framework combining the 
strengths of lexico-syntactic patterns and cluster-
ing. The framework incrementally clusters terms 
and transforms automatic taxonomy induction 
into a multi-criteria optimization based on mini-
mization of taxonomy structures and modeling of 
term abstractness. The experiments show that our 
framework is effective; it achieves higher F1-
measure than three state-of-the-art systems. The 
paper also studies which features are the best for 
different types of relations and for terms at dif-
ferent abstraction levels.  
Most prior work uses a single rule or feature 
function for automatic taxonomy induction at all 
levels of abstraction. Our work is a more general 
framework which allows a wider range of fea-
tures and different metric functions at different 
abstraction levels.  This more general framework 
has the potential to learn more complex taxono-
mies than previous approaches. 
Acknowledgements 
This research was supported by NSF grant IIS-
0704210. Any opinions, findings, conclusions, or 
recommendations expressed in this paper are of 
the authors, and do not necessarily reflect those 
of the sponsor. 
Feature  L2 L3 L4 L5 L6 
Contextual 0.29 0.31 0.35 0.36 0.36 
Co-occurrence 0.47 0.56 0.45 0.41 0.41 
Patterns 0.47 0.44 0.42 0.39 0.40 
Syntactic 0.31 0.28 0.36 0.38 0.39 
Word Length 0.16 0.16 0.16 0.16 0.16 
Definition 0.12 0.12 0.12 0.12 0.12 
Table 5. F1-measure for Features vs. Abstractness: 
WordNet/is-a. 
Feature  L2 L3 L4 L5 L6 
Contextual 0.30 0.30 0.33 0.29 0.29 
Co-occurrence 0.34 0.36 0.34 0.31 0.31 
Patterns 0.23 0.25 0.30 0.28 0.28 
Syntactic 0.18 0.18 0.23 0.27 0.27 
Word Length 0.15 0.15 0.15 0.14 0.14 
Definition 0.13 0.13 0.13 0.12 0.12 
Table 6. F1-measure for Features vs. Abstractness: 
ODP/is-a. 
278
References 
M. Berland and E. Charniak. 1999. Finding parts in very 
large corpora. ACL?99. 
S. Boyd and L. Vandenberghe. 2004. Convex optimization. 
In Cambridge University Press, 2004.  
P. Brown, V. D. Pietra, P. deSouza, J. Lai, and R. Mercer. 
1992. Class-based ngram models for natural language. 
Computational Linguistics, 18(4):468?479. 
P. Buitelaar, P. Cimiano, and B. Magnini. 2005. Ontology 
Learning from Text: Methods, Evaluation and Applica-
tions. Volume 123 Frontiers in Artificial Intelligence and 
Applications. 
R. Bunescu and R. Mooney. 2007.  Learning to Extract 
Relations from the Web using Minimal Supervision. 
ACL?07. 
S. Caraballo. 1999.  Automatic construction of a hypernym-
labeled noun hierarchy from text. ACL?99. 
T. Chklovski and P. Pantel. 2004. VerbOcean: mining the 
web for fine-grained semantic verb relations. EMNLP 
?04. 
P. Cimiano and J. Volker. 2005. Towards large-scale, open-
domain and ontology-based named entity classification. 
RANLP?07. 
P. Cimiano and J. Wenderoth. 2007. Automatic Acquisition 
of Ranked Qualia Structures from the Web. ACL?07. 
D. Davidov and A. Rappoport. 2006. Efficient Unsuper-
vised Discovery of Word Categories Using Symmetric 
Patterns and High Frequency Words. ACL?06. 
D. Davidov and A. Rappoport. 2008. Classification of Se-
mantic Relationships between Nominals Using Pattern  
Clusters. ACL?08. 
D. Downey, O. Etzioni, and S. Soderland. 2005. A Probabil-
istic model of redundancy in information extraction. IJ-
CAI?05.  
O. Etzioni, M. Cafarella, D. Downey, A. Popescu, T. 
Shaked, S. Soderland, D. Weld, and A. Yates. 2005. Un-
supervised named-entity extraction from the web: an ex-
perimental study. Artificial Intelligence, 165(1):91?134. 
C. Fellbuam. 1998. WordNet: An Electronic Lexical Data-
base. MIT Press. 1998. 
M. Geffet and I. Dagan. 2005. The Distributional Inclusion 
Hypotheses and Lexical Entailment. ACL?05. 
R. Girju, A. Badulescu, and D. Moldovan. 2003. Learning 
Semantic Constraints for the Automatic Discovery of 
Part-Whole Relations. HLT?03. 
R. Girju, A. Badulescu, and D. Moldovan. 2006. Automatic 
Discovery of Part-Whole Relations. Computational Lin-
guistics, 32(1): 83-135. 
Z. Harris. 1985. Distributional structure. In Word, 10(23): 
146-162s, 1954.  
T. Hastie, R. Tibshirani and J. Friedman. 2001. The Ele-
ments of Statistical Learning: Data Mining, Inference, 
and Prediction. Springer-Verlag, 2001. 
M. Hearst. 1992. Automatic acquisition of hyponyms from 
large text corpora. COLING?92. 
M. D. Hendy and D. Penny. 1982. Branch and bound algo-
rithms to determine minimal evolutionary trees. Mathe-
matical Biosciences 59: 277-290. 
Z. Kozareva, E. Riloff, and E. Hovy. 2008. Semantic Class 
Learning from the Web with Hyponym Pattern Linkage 
Graphs. ACL?08. 
D. Lin, 1998. Automatic retrieval and clustering of similar 
words. COLING?98. 
D. Lin, S. Zhao, L. Qin, and M. Zhou. 2003. Identifying 
Synonyms among Distributionally Similar Words. IJ-
CAI?03. 
G. S. Mann. 2002. Fine-Grained Proper Noun Ontologies 
for Question Answering. In Proceedings of SemaNet? 02: 
Building and Using Semantic Networks, Taipei. 
P. Pantel and D Lin. 2002. Discovering word senses from 
text. SIGKDD?02. 
P. Pantel and D. Ravichandran. 2004. Automatically labe-
ling semantic classes. HLT/NAACL?04.  
P. Pantel, D. Ravichandran, and E. Hovy. 2004. Towards 
terascale knowledge acquisition. COLING?04. 
P. Pantel and M. Pennacchiotti. 2006. Espresso: Leveraging 
Generic Patterns for Automatically Harvesting Semantic 
Relations. ACL?06. 
F. Pereira, N. Tishby, and L. Lee. 1993. Distributional clus-
tering of English words. ACL?93. 
D. Ravichandran and E. Hovy. 2002. Learning surface text 
patterns for a question answering system. ACL?02. 
E. Riloff and J. Shepherd. 1997. A corpus-based approach 
for building semantic lexicons. EMNLP?97. 
B. Roark and E. Charniak. 1998. Noun-phrase co-
occurrence statistics for semi-automatic semantic lexicon 
construction. ACL/COLING?98. 
R. Snow, D. Jurafsky, and A. Y. Ng. 2005. Learning syntac-
tic patterns for automatic hypernym discovery. NIPS?05. 
R. Snow, D. Jurafsky, and A. Y. Ng. 2006. Semantic Tax-
onomy Induction from Heterogeneous Evidence. 
ACL?06. 
B. Rosenfeld and R. Feldman. 2007. Clustering for unsu-
pervised relation identification. CIKM?07. 
P. Turney, M. Littman, J. Bigham, and V. Shnayder. 2003. 
Combining independent modules to solve multiple-
choice synonym and analogy problems. RANLP?03.  
S. M. Harabagiu, S. J. Maiorano and M. A. Pasca. 2003. 
Open-Domain Textual Question Answering Techniques. 
Natural Language Engineering 9 (3): 1-38, 2003. 
I. Szpektor, H. Tanev, I. Dagan, and B. Coppola. 2004. 
Scaling web-based acquisition of entailment relations. 
EMNLP?04.  
D. Widdows and B. Dorow. 2002. A graph model for unsu-
pervised Lexical acquisition. COLING ?02. 
H. Yang and J. Callan. 2008. Learning the Distance Metric 
in a Personal Ontology. Workshop on Ontologies and In-
formation Systems for the Semantic Web of CIKM?08. 
279
