Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 41?48,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Learning Expressive Models for Word Sense Disambiguation 
Lucia Specia 
NILC/ICMC 
University of S?o Paulo 
Caixa Postal 668, 13560-970 
S?o Carlos, SP, Brazil 
lspecia@icmc.usp.br 
Mark Stevenson 
Department of Computer Science 
University of Sheffield 
Regent Court, 211 Portobello St. 
Sheffield, S1 4DP, UK  
marks@dcs.shef.ac.uk 
Maria das Gra?as V. Nunes 
NILC/ICMC 
University of S?o Paulo 
Caixa Postal 668, 13560-970  
S?o Carlos, SP, Brazil 
gracan@icmc.usp.br 
 
 
Abstract 
We present a novel approach to the word 
sense disambiguation problem which 
makes use of corpus-based evidence com-
bined with background knowledge. Em-
ploying an inductive logic programming 
algorithm, the approach generates expres-
sive disambiguation rules which exploit 
several knowledge sources and can also 
model relations between them. The ap-
proach is evaluated in two tasks: identifica-
tion of the correct translation for a set of 
highly ambiguous verbs in English-
Portuguese translation and disambiguation 
of verbs from the Senseval-3 lexical sam-
ple task. The average accuracy obtained for 
the multilingual task outperforms the other 
machine learning techniques investigated. 
In the monolingual task, the approach per-
forms as well as the state-of-the-art sys-
tems which reported results for the same 
set of verbs. 
1 Introduction 
Word Sense Disambiguation (WSD) is concerned 
with the identification of the meaning of ambi-
guous words in context. For example, among the 
possible senses of the verb ?run? are ?to move fast 
by using one's feet? and ?to direct or control?. 
WSD can be useful for many applications, includ-
ing information retrieval, information extraction 
and machine translation. Sense ambiguity has been 
recognized as one of the most important obstacles 
to successful language understanding since the ear-
ly 1960?s and many techniques have been pro-
posed to solve the problem. Recent approaches 
focus on the use of various lexical resources and 
corpus-based techniques in order to avoid the sub-
stantial effort required to codify linguistic know-
ledge. These approaches have shown good results; 
particularly those using supervised learning (see 
Mihalcea et al, 2004 for an overview of state-of-
the-art systems). However, current approaches rely 
on limited knowledge representation and modeling 
techniques: traditional machine learning algorithms 
and attribute-value vectors to represent disambigu-
ation instances. This has made it difficult to exploit 
deep knowledge sources in the generation of the 
disambiguation models, that is, knowledge that 
goes beyond simple features extracted directly 
from the corpus, like bags-of-words and colloca-
tions, or provided by shallow natural language 
tools like part-of-speech taggers.  
In this paper we present a novel approach for 
WSD that follows a hybrid strategy, i.e. combines 
knowledge and corpus-based evidence, and em-
ploys a first-order formalism to allow the represen-
tation of deep knowledge about disambiguation 
examples together with a powerful modeling tech-
nique to induce theories based on the examples and 
background knowledge. This is achieved using 
Inductive Logic Programming (ILP) (Muggleton, 
1991), which has not yet been applied to WSD.  
Our hypothesis is that by using a very expres-
sive representation formalism, a range of (shallow 
and deep) knowledge sources and ILP as learning 
technique, it is possible to generate models that, 
when compared to models produced by machine 
learning algorithms conventionally applied to 
41
WSD, are both more accurate for fine-grained dis-
tinctions, and ?interesting?, from a knowledge ac-
quisition point of view (i.e., convey potentially 
new knowledge that can be easily interpreted by 
humans).  
WSD systems have generally been more suc-
cessful in the disambiguation of nouns than other 
grammatical categories (Mihalcea et al, 2004). A 
common approach to the disambiguation of nouns 
has been to consider a wide context around the 
ambiguous word and treat it as a bag of words or 
limited set of collocates. However, disambiguation 
of verbs generally benefits from more specific 
knowledge sources, such as the verb?s relation to 
other items in the sentence (for example, by ana-
lysing the semantic type of its subject and object). 
Consequently, we believe that the disambiguation 
of verbs is task to which ILP is particularly well-
suited. Therefore, this paper focuses on the disam-
biguation of verbs, which is an interesting task 
since much of the previous work on WSD has con-
centrated on the disambiguation of nouns.  
WSD is usually approached as an independent 
task, however, it has been argued that different 
applications may have specific requirements (Res-
nik and Yarowsky, 1997). For example, in machine 
translation, WSD, or translation disambiguation, is 
responsible for identifying the correct translation 
for an ambiguous source word. There is not always 
a direct relation between the possible senses for a 
word in a (monolingual) lexicon and its transla-
tions to a particular language, so this represents a 
different task to WSD against a (monolingual) 
lexicon (Hutchins and Somers, 1992). Although it 
has been argued that WSD does not yield better 
translation quality than a machine translation 
system alone, it has been recently shown that a 
WSD module that is developed following specific 
multilingual requirements can significantly im-
prove the performance of a machine translation 
system (Carpuat et al, 2006). 
This paper focuses on the application of our ap-
proach to the translation of verbs in English to Por-
tuguese translation, specifically for a set of 10 
mainly light and highly ambiguous verbs. We also 
experiment with a monolingual task by using the 
verbs from Senseval-3 lexical sample task. We 
explore knowledge from 12 syntactic, semantic 
and pragmatic sources. In principle, the proposed 
approach could also be applied to any lexical dis-
ambiguation task by customizing the sense reposi-
tory and knowledge sources. 
In the remainder of this paper we first present 
related approaches to WSD and discuss their limi-
tations (Section 2). We then describe some basic 
concepts on ILP and our application of this tech-
nique to WSD (Section 3). Finally, we described 
our experiments and their results (Section 4).  
2 Related Work 
WSD approaches can be classified as (a) know-
ledge-based approaches, which make use of lin-
guistic knowledge, manually coded or extracted 
from lexical resources (Agirre and Rigau, 1996; 
Lesk 1986); (b) corpus-based approaches, which 
make use of shallow knowledge automatically ac-
quired from corpus and statistical or machine 
learning algorithms to induce disambiguation 
models (Yarowsky, 1995; Sch?tze 1998); and (c) 
hybrid approaches, which mix characteristics from 
the two other approaches to automatically acquire 
disambiguation models from corpus supported by 
linguistic knowledge (Ng and Lee 1996; Stevenson 
and Wilks, 2001). 
Hybrid approaches can combine advantages 
from both strategies, potentially yielding accurate 
and comprehensive systems, particularly when 
deep knowledge is explored. Linguistic knowledge 
is available in electronic resources suitable for 
practical use, such as WordNet (Fellbaum, 1998), 
dictionaries and parsers. However, the use of this 
information has been hampered by the limitations 
of the modeling techniques that have been ex-
plored so far: using deep sources of domain know-
ledge is beyond the capabilities of such techniques, 
which are in general based on attribute-value vec-
tor representations. 
Attribute-value vectors consist of a set of 
attributes intended to represent properties of the 
examples. Each attribute has a type (its name) and 
a single value for a given example. Therefore, 
attribute-value vectors have the same expressive-
ness as propositional formalisms, that is, they only 
allow the representation of atomic propositions and 
constants. These are the representations used by 
most of the machine learning algorithms conven-
tionally employed to WSD, for example Na?ve 
Bayes and decision-trees. First-order logic, a more 
expressive formalism which is employed by ILP, 
allows the representation of variables and n-ary 
predicates, i.e., relational knowledge.  
42
In the hybrid approaches that have been ex-
plored so far, deep knowledge, like selectional pre-
ferences, is either pre-processed into a vector 
representation to accommodate machine learning 
algorithms, or used in previous steps to filter out 
possible senses e.g. (Stevenson and Wilks, 2001). 
This may cause information to be lost and, in addi-
tion, deep knowledge sources cannot interact in the 
learning process. As a consequence, the models 
produced reflect only the shallow knowledge that 
is provided to the learning algorithm.  
Another limitation of attribute-value vectors is 
the need for a unique representation for all the ex-
amples: one attribute is created for every knowl-
edge feature and the same structure is used to 
characterize all the examples. This usually results 
in a very sparse representation of the data, given 
that values for certain features will not be available 
for many examples. The problem of data sparse-
ness increases as more knowledge is exploited and 
this can cause problems for the machine learning 
algorithms. 
A final disadvantage of attribute-value vectors 
is that equivalent features may have to be bounded 
to distinct identifiers. An example of this occurs 
when the syntactic relations between words in a 
sentence are represented by attributes for each pos-
sible relation, sentences in which there is more 
than one instantiation for a particular grammatical 
role cannot be easily represented.  For example, the 
sentence ?John and Anna gave Mary a present.? 
contains a coordinate subject and, since each fea-
ture requires a unique identifier, two are required 
(subj1-verb1, subj2-verb1). These will be treated as 
two independent pieces of knowledge by the learn-
ing algorithm.  
First-order formalisms allow a generic predicate 
to be created for every possible syntactic role, re-
lating two or more elements. For example 
has_subject(verb, subject), which could then have 
two instantiations: has_subject(give, john) and 
has_subject(give, anna). Since each example is 
represented independently from the others, the data 
sparseness problem is minimized. Therefore, ILP 
seems to provide the most general-purpose frame-
work for dealing with such data: it does not suffer 
from the limitations mentioned above since there 
are explicit provisions made for the inclusion of 
background knowledge of any form, and the repre-
sentation language is powerful enough to capture 
contextual relationships. 
3 A hybrid relational approach to WSD 
In what follows we provide an introduction to ILP 
and then outline how it is applied to WSD by pre-
senting the sample corpus and knowledge sources 
used in our experiments. 
3.1 Inductive Logic Programming 
Inductive Logic Programming (Muggleton, 1991) 
employs techniques from Machine Learning and 
Logic Programming to build first-order theories 
from examples and background knowledge, which 
are also represented by first-order clauses. It allows 
the efficient representation of substantial know-
ledge about the problem, which is used during the 
learning process, and produces disambiguation 
models that can make use of this knowledge. The 
general approach underlying ILP can be outlined 
as follows:  
Given: 
-  a set of positive and negative examples E = 
E+ ? E- 
- a predicate p specifying the target relation to 
be learned 
- knowledge ? of the domain, described ac-
cording to a language Lk, which specifies which 
predicates qi can be part of the definition of p. 
The goal is: to induce a hypothesis (or theory) 
h for p, with relation to E and ?, which covers 
most of the E+, without covering the E-, i.e., K ? h 
 E+ and K ? h  E-.  
 
We use the Aleph ILP system (Srinivasan, 2000), 
which provides a complete inference engine and 
can be customized in various ways. The default 
inference engine induces a theory iteratively using 
the following steps: 
1. One instance is randomly selected to be gen-
eralized.  
2. A more specific clause (the bottom clause) is 
built using inverse entailment (Muggleton, 1995), 
generally consisting of the representation of all the 
knowledge about that example. 
3. A clause that is more generic than the bottom 
clause is searched for using a given search (e.g., 
best-first) and evaluation strategy (e.g., number of 
positive examples covered). 
4. The best clause is added to the theory and the 
examples covered by that clause are removed from 
the sample set. Stop if there are more no examples 
in the training set, otherwise return to step 1. 
43
3.2 Sample data 
This approach was evaluated using two scenarios: 
(1) an English-Portuguese multilingual setting ad-
dressing 10 very frequent and problematic verbs 
selected in a previous study (Specia et. al., 2005); 
and (2) an English setting consisting of 32 verbs 
from Senseval-3 lexical sample task (Mihalcea et. 
al. 2004). 
For the first scenario a corpus containing 500 
sentences for each of the 10 verbs was constructed. 
The text was randomly selected from corpora of 
different domains and genres, including literary 
fiction, Bible, computer science dissertation ab-
stracts, operational system user manuals, newspa-
pers and European Parliament proceedings. This 
corpus was automatically annotated with the trans-
lation of the verb using a tagging system based on 
parallel corpus, statistical information and transla-
tion dictionaries (Specia et al, 2005), followed by 
a manual revision. For each verb, the sense reposi-
tory was defined as the set of all the possible trans-
lations of that verb in the corpus. 80% of the 
corpus was randomly selected and used for train-
ing, with the remainder retained for testing. The 10 
verbs, number of possible translations and the per-
centage of sentences for each verb which use the 
most frequent translation are shown in Table 1. 
For the monolingual scenario, we use the sense 
tagged corpus and sense repositories provided for 
verbs in Senseval-3. There are 32 verbs with be-
tween 40 and 398 examples each. The number of 
senses varies between 3 and 10 and the average 
percentage of examples with the majority (most 
frequent) sense is 55%.  
 
 Verb # Translations Most frequent 
translation - % 
ask 7 53 
come 29 36 
get 41 13 
give 22 72 
go 30 53 
live 8 66 
look 12 41 
make 21 70 
take 32 25 
tell 8 66 
Table 1. Verbs and possible senses in our corpus 
 
Both corpora were lemmatized and part-of-speech 
(POS) tagged using Minipar (Lin, 1993) and 
Mxpost (Ratnaparkhi, 1996), respectivelly. Addi-
tionally, proper nouns identified by the tagger were 
replaced by a single identifier (proper_noun) and 
pronouns replaced by identifiers representing 
classes of pronouns (relative_pronoun, etc.).  
3.3 Knowledge sources 
We now describe the background knowledge 
sources used by the learning algorithm, having as 
an example sentence (1), in which the word ?com-
ing? is the target verb being disambiguated. 
 
(1) "If there is such a thing as reincarnation, I 
would not mind coming back as a squirrel". 
 
KS1. Bag-of-words consisting of 5 words to the 
right and left of the verb (excluding stop words), 
represented using definitions of the form 
has_bag(snt, word): 
has_bag(snt1, mind). 
has_bag(snt1, not). ? 
 
KS2. Frequent bigrams consisting of pairs of adja-
cent words in a sentence (other than the target 
verb) which occur more than 10 times in the cor-
pus, represented by has_bigram(snt, word1, 
word2): 
has_bigram(snt1, back, as). 
has_bigram(snt1, such, a). ? 
 
KS3. Narrow context containing 5 content words to 
the right and left of the verb, identified using POS 
tags, represented by has_narrow(snt, 
word_position, word): 
has_narrow(snt1, 1st_word_left, mind). 
has_narrow(snt1, 1st_word_right, back). ? 
 
KS4. POS tags of 5 words to the right and left of 
the verb, represented by has_pos(snt, 
word_position, pos): 
has pos(snt1, 1st_word_left, nn). 
has pos(snt1, 1st_word_right, rb). ? 
 
KS5. 11 collocations of the verb: 1st preposition to 
the right, 1st and 2nd words to the left and right, 
1st noun, 1st adjective, and 1st verb to the left and 
right. These are represented using definitions of the 
form has_collocation(snt, type, collocation): 
has_collocation(snt1, 1st_prep_right, back). 
has_collocation(snt1, 1st_noun_left, mind).? 
44
KS6. Subject and object of the verb obtained using 
Minipar and represented by has_rel(snt, type, 
word): 
has_rel(snt1, subject, i). 
has_rel(snt1, object, nil). ? 
 
KS7. Grammatical relations not including the tar-
get verb also identified using Minipar. The rela-
tions (verb-subject, verb-object, verb-modifier, 
subject-modifier, and object-modifier) occurring 
more than 10 times in the corpus are represented 
by has_related_pair(snt, word1, word2): 
has_related_pair(snt1, there, be). ? 
 
KS8. The sense with the highest count of overlap-
ping words in its dictionary definition and in the 
sentence containing the target verb (excluding stop 
words) (Lesk, 1986), represented by 
has_overlapping(sentence, translation): 
has_overlapping(snt1, voltar). 
 
KS9. Selectional restrictions of the verbs defined 
using LDOCE (Procter, 1978). WordNet is used 
when the restrictions imposed by the verb are not 
part of the description of its arguments, but can be 
satisfied by synonyms or hyperonyms of those ar-
guments. A hierarchy of feature types is used to 
account for restrictions established by the verb that 
are more generic than the features describing its 
arguments in the sentence. This information is 
represented by definitions of the form satis-
fy_restriction(snt, rest_subject, rest_object): 
satisfy_restriction(snt1, [human], nil). 
satisfy_restriction(snt1, [animal, human], nil). 
 
KS1-KS9 can be applied to both multilingual and 
monolingual disambiguation tasks. The following 
knowledge sources were specifically designed for 
multilingual applications: 
 
KS10. Phrasal verbs in the sentence identified using 
a list extracted from various dictionaries. (This 
information was not used in the monolingual task 
because phrasal constructions are not considered 
verb senses in Senseval data.) These are 
represented by definitions of the form 
has_expression(snt, verbal_expression):  
has_expression(snt1, ?come back?). 
 
KS11. Five words to the right and left of the target 
verb in the Portuguese translation. This could be 
obtained using a machine translation system that 
would first translate the non-ambiguous words in 
the sentence. In our experiments it was extracted 
using a parallel corpus and represented using defi-
nitions of the form has_bag_trns(snt, portu-
guese_word): 
has_bag_trns(snt1, coelho). 
has_bag_trns(snt1, reincarna??o). ? 
 
KS12. Narrow context consisting of 5 collocations 
of the verb in the Portuguese translation, which 
take into account the positions of the words, 
represented by has_narrow_trns(snt, 
word_position, portuguese_word): 
has_narrow_trns(snt1, 1st_word_right, como). 
has_narrow_trns(snt1, 2nd_word_right, um). ? 
 
In addition to background knowledge, the system 
learns from a set of examples. Since all knowledge 
about them is expressed as background knowledge, 
their representation is very simple, containing only 
the sentence identifier and the sense of the verb in 
that sentence, i.e. sense(snt, sense): 
sense(snt1,voltar).  
sense(snt2,ir). ? 
 
Based on the examples, background knowledge 
and a series of settings specifying the predicate to 
be learned (i.e., the heads of the rules), the predi-
cates that can be in the conditional part of the 
rules, how the arguments can be shared among dif-
ferent  predicates and several other parameters, the 
inference engine produces a set of symbolic rules. 
Figure 1 shows examples of the rules induced for 
the verb ?to come? in the multilingual task.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Examples of rules produced for the verb 
?come? in the multilingual task 
 
Rule_1. sense(A, voltar) :- 
    has_collocation(A, 1st_prep_right, back). 
Rule_2. sense(A, chegar) :- 
   has_rel(A, subj, B), has_bigram(A, today, B), 
   has_bag_trans(A, hoje). 
Rule_3. sense(A, chegar) :- 
    satisfy_restriction(A, [animal, human], [concrete]); 
    has_expression(A, 'come at'). 
Rule_4. sense(A, vir) :- 
    satisfy_restriction(A, [animate], nil);  
    (has_rel(A, subj, B), 
    (has_pos(A, B, nnp); has_pos(A, B, prp))). 
 
45
Models learned with ILP are symbolic and can be 
easily interpreted. Additionally, innovative knowl-
edge about the problem can emerge from the rules 
learned by the system. Although some rules simply 
test shallow features such as collocates, others pose 
conditions on sets of knowledge sources, including 
relational sources, and allow non-instantiated ar-
guments to be shared amongst them by means of 
variables. For example, in Figure 1, Rule_1 states 
that the translation of the verb in a sentence A will 
be ?voltar? (return) if the first preposition to the 
right of the verb in that sentence is ?back?. Rule_2 
states that the translation of the verb will be 
?chegar? (arrive) if it has a certain subject B, 
which occurs frequently with the word ?today? as a 
bigram, and if the partially translated sentence con-
tains the word ?hoje? (the translation of ?today?). 
Rule_3 says that the translation of the verb will be 
?chegar? (reach) if the subject of the verb has the 
features ?animal? or ?human? and the object has 
the feature ?concrete?, or if the verb occurs in the 
expression ?come at?. Rule_4 states that the trans-
lation of the verb will be ?vir? (move toward) if the 
subject of the verb has the feature ?animate? and 
there is no object, or if the verb has a subject B that 
is a proper noun (nnp) or a personal pronoun (prp). 
4 Experiments and results 
To assess the performance of the approach the 
model produced for each verb was tested on the 
corresponding set of test cases by applying the 
rules in a decision-list like approach, i.e., retaining 
the order in which they were produced and backing 
off to the most frequent sense in the training set to 
classify cases that were not covered by any of the 
rules. All the knowledge sources were made avail-
able to be used by the inference engine, since pre-
vious experiments showed that they are all relevant 
(Specia, 2006). In what follows we present the re-
sults and discuss each task.  
4.1 Multilingual task 
Table 2 shows the accuracies (in terms of percen-
tage of corpus instances which were correctly dis-
ambiguated) obtained by the Aleph models. 
Results are compared against the accuracy that 
would be obtained by using the most frequent 
translation in the training set to classify all the ex-
amples of the test set (in the column labeled ?Ma-
jority sense?). For comparison, we ran experiments 
with three learning algorithms frequently used for 
WSD, which rely on knowledge represented as 
attribute-value vectors: C4.5 (decision-trees), 
Naive Bayes and Support Vector Machine (SVM)1. 
In order to represent all knowledge sources in 
attribute-value vectors, KS2, KS7, KS9 and KS10 
had to be pre-processed to be transformed into bi-
nary attributes. For example, in the case of selec-
tional restrictions (KS9), one attribute was created 
for each possible sense of the verb and a true/false 
value was assigned to it depending on whether the 
arguments of the verb satisfied any restrictions re-
ferring to that sense. Results for each of these algo-
rithms are also shown in Table 2. 
As we can see in Table 2, the accuracy of the 
ILP approach is considerably better than the most 
frequent sense baseline and also outperforms the 
other learning algorithms. This improvement is 
statistically significant (paired t-test; p < 0.05). As 
expected, accuracy is generally higher for verbs 
with fewer possible translations.  
The models produced by Aleph for all the verbs 
are reasonably compact, containing 50 to 96 rules. 
In those models the various knowledge sources 
appear in different rules and all are used. This 
demonstrates that they are all useful for the disam-
biguation of verbs. 
 
Verb Majori- 
ty sense 
C4.5 Na?ve  
Bayes 
SVM Aleph 
ask 0.68 0.68 0.82 0.88 0.92 
come 0.46 0.57 0.61 0.68 0.73 
get 0.03 0.25 0.46 0.47 0.49 
give 0.72 0.71 0.74 0.74 0.74 
go 0.49 0.61 0.66 0.66 0.66 
live 0.71 0.72 0.64 0.73 0.87 
look 0.48 0.69 0.81 0.83 0.93 
make 0.64 0.62 0.60 0.64 0.68 
take 0.14 0.41 0.50 0.51 0.59 
tell 0.65 0.67 0.66 0.68 0.82 
Average 0.50 0.59 0.65 0.68 0.74 
Table 2. Accuracies obtained by Aleph and other 
learning algorithms in the multilingual task 
 
These results are very positive, particularly if we 
consider the characteristics of the multilingual sce-
nario: (1) the verbs addressed are highly ambi-
guous; (2) the corpus was automatically tagged and 
thus distinct synonym translations were sometimes 
                                                          
1
 The implementations provided by Weka were used. Weka is 
available from http://www.cs.waikato.ac.nz/ml/weka/ 
46
used to annotate different examples (these count as 
different senses for the inference engine); and (3) 
certain translations occur very infrequently (just 1 
or 2 examples in the whole corpus). It is likely that 
a less strict evaluation regime, such as one which 
takes account of synonym translations, would re-
sult in higher accuracies. 
It is worth noticing that we experimented with a 
few relevant parameters for both Aleph and the 
other learning algorithms. Values that yielded the 
best average predictive accuracy in the training 
sets were assumed to be optimal and used to eva-
luate the test sets.  
4.2 Monolingual task 
Table 3 shows the average accuracy obtained by 
Aleph in the monolingual task (Senseval-3 verbs 
with fine-grained sense distinctions and using the 
evaluation system provided by Senseval). It also 
shows the average accuracy of the most frequent 
sense and accuracies reported on the same set of 
verbs by the best systems submitted by the sites 
which participated in this task. Syntalex-3 (Mo-
hammad and Pedersen, 2004) is based on an en-
semble of bagged decision trees with narrow 
context part-of-speech features and bigrams. 
CLaC1 (Lamjiri et al, 2004) uses a Naive Bayes 
algorithm with a dynamically adjusted context 
window around the target word. Finally, MC-WSD 
(Ciaramita and Johnson, 2004) is a multi-class av-
eraged perceptron classifier using syntactic and 
narrow context features, with one component 
trained on the data provided by Senseval and other 
trained on WordNet glosses.  
 
System % Average accuracy 
Majority sense 0.56 
Syntalex-3 0.67 
CLaC1 0.67 
MC-WSD 0.72 
Aleph 0.72 
Table 3. Accuracies obtained by Aleph and other 
approaches in the monolingual task 
 
As we can see in Table 3, results are very encour-
aging: even without being particularly customized 
for this monolingual task, the ILP approach signif-
icantly outperforms the majority sense baseline and 
performs as well as the state-of-the-art system re-
porting results for the same set of verbs. As with 
the multilingual task, the models produced contain 
a small number of rules (from 6, for verbs with a 
few examples, to 88) and all knowledge sources 
are used across different rules and verbs. 
In general, results from both multilingual and 
monolingual tasks demonstrate that the hypothesis 
put forward in Section 1, that ILP?s ability to gen-
erate expressive rules which combine and integrate 
a wide range of knowledge sources is beneficial for 
WSD systems, is correct.  
5 Conclusion 
We have introduced a new hybrid approach to 
WSD which uses ILP to combine deep and shallow 
knowledge sources. ILP induces expressive disam-
biguation models which include relations between 
knowledge sources. It is an interesting approach to 
learning which has been considered promising for 
several applications in natural language processing 
and has been explored for a few of them, namely 
POS-tagging, grammar acquisition and semantic 
parsing (Cussens et al, 1997; Mooney, 1997). This 
paper has demonstrated that ILP also yields good 
results for WSD, in particular for the disambigua-
tion of verbs.  
We plan to further evaluate our approach for 
other sets of words, including other parts-of-speech 
to allow further comparisons with other approach-
es. For example, Dang and Palmer (2005) also use 
a rich set of features with a traditional learning al-
gorithm (maximum entropy). Currently, we are 
evaluating the role of the WSD models for the 10 
verbs of the multilingual task in an English-
Portuguese statistical machine translation system. 
References 
Eneko Agirre and German Rigau. 1996. Word Sense 
Disambiguation using Conceptual Density. Proceed-
ings of the 15th Conference on Computational Lin-
guistics (COLING-96). Copenhagen, pages 16-22. 
Marine Carpuat, Yihai Shen, Xiaofeng Yu, and Dekai 
WU. 2006. Toward Integrating Word Sense and Enti-
ty Disambiguation into Statistical Machine Transla-
tion. Proceedings of the Third International 
Workshop on Spoken Language Translation,. Kyoto, 
pages 37-44. 
Massimiliano Ciaramita and Mark Johnson. 2004. Mul-
ti-component Word Sense Disambiguation. Proceed-
ings of Senseval-3: 3rd International Workshop on 
the Evaluation of Systems for the Semantic Analysis 
of Text, Barcelona, pages 97-100. 
47
James Cussens, David Page, Stephen Muggleton, and 
Ashwin Srinivasan. 1997. Using Inductive Logic 
Programming for Natural Language Processing. 
Workshop Notes on Empirical Learning of Natural 
Language Tasks, Prague, pages 25-34. 
Hoa T. Dang and Martha Palmer. 2005. The Role of 
Semantic Roles in Disambiguating Verb Senses. 
Proceedings of the 43rd Meeting of the Association 
for Computational Linguistics (ACL-05), Ann Arbor, 
pages 42?49. 
Christiane Fellbaum. 1998. WordNet: An Electronic 
Lexical Database. MIT Press, Massachusetts.  
W. John Hutchins and Harold L. Somers. 1992. An In-
troduction to Machine Translation. Academic Press, 
Great Britain. 
Abolfazl K. Lamjiri, Osama El Demerdash, Leila Kos-
seim. 2004. Simple features for statistical Word 
Sense Disambiguation. Proceedings of Senseval-3: 
3rd International Workshop on the Evaluation of Sys-
tems for the Semantic Analysis of Text, Barcelona, 
pages 133-136. 
Michael Lesk. 1986. Automatic sense disambiguation 
using machine readable dictionaries: how to tell a 
pine cone from an ice cream cone. ACM SIGDOC 
Conference, Toronto, pages 24-26. 
Dekang Lin. 1993. Principle based parsing without 
overgeneration. Proceedings of the 31st Meeting of 
the Association for Computational Linguistics (ACL-
93), Columbus, pages 112-120. 
Rada Mihalcea, Timothy Chklovski and Adam Kilga-
riff. 2004. The Senseval-3 English Lexical Sample 
Task. Proceedings of Senseval-3: 3rd International 
Workshop on the Evaluation of Systems for Semantic 
Analysis of Text, Barcelona, pages 25-28. 
Saif Mohammad and Ted Pedersen. 2004. Complemen-
tarity of Lexical and Simple Syntactic Features: The 
SyntaLex Approach to Senseval-3. Proceedings of 
Senseval-3: 3rd International Workshop on the Eval-
uation of Systems for the Semantic Analysis of Text, 
Barcelona, pages 159-162. 
Raymond J. Mooney. 1997. Inductive Logic Program-
ming for Natural Language Processing. Proceedings 
of the 6th International Workshop on ILP, LNAI 
1314, Stockolm, pages 3-24. 
Stephen Muggleton. 1991. Inductive Logic Program-
ming. New Generation Computing, 8(4):295-318. 
Stephen Muggleton. 1995. Inverse Entailment and Pro-
gol. New Generation Computing, 13:245-286. 
 
Hwee T. Ng and Hian B. Lee. 1996. Integrating mul-
tiple knowledge sources to disambiguate word sense: 
an exemplar-based approach. Proceedings of the 34th 
Meeting of the Association for Computational 
Linguistics (ACL-96), Santa Cruz, CA, pages 40-47. 
Paul Procter (editor). 1978. Longman Dictionary of 
Contemporary English. Longman Group, Essex. 
Adwait Ratnaparkhi. 1996. A Maximum Entropy Part-
Of-Speech Tagger. Proceedings of the Conference on 
Empirical Methods in Natural Language Processing, 
New Jersey, pages 133-142. 
Phillip Resnik and David Yarowsky. 1997. A Perspec-
tive on Word Sense Disambiguation Methods and 
their Evaluating. Proceedings of the ACL-SIGLEX 
Workshop Tagging Texts with Lexical Semantics: 
Why, What and How?, Washington. 
Hinrich Sch?tze. 1998. Automatic Word Sense Discrim-
ination. Computational Linguistics, 24(1): 97-123. 
Lucia Specia, Maria G.V. Nunes, and Mark Stevenson. 
2005. Exploiting Parallel Texts to Produce a 
Multilingual Sense Tagged Corpus for Word Sense 
Disambiguation. Proceedings of the Conference on 
Recent Advances on Natural Language Processing 
(RANLP-2005), Borovets, pages 525-531. 
Lucia Specia. 2006. A Hybrid Relational Approach for 
WSD - First Results. Proceedings of the 
COLING/ACL 06 Student Research Workshop, Syd-
ney, pages 55-60.  
Ashwin Srinivasan. 2000. The Aleph Manual. Technical 
Report. Computing Laboratory, Oxford University. 
Mark Stevenson and Yorick Wilks. 2001. The Interaction 
of Knowledge Sources for Word Sense Disambiguation. 
Computational Linguistics, 27(3):321-349. 
Yorick Wilks and Mark Stevenson. 1998. The Grammar 
of Sense: Using Part-of-speech Tags as a First Step in 
Semantic Disambiguation. Journal of Natural Lan-
guage Engineering, 4(1):1-9 
David Yarowsky. 1995. Unsupervised Word-Sense Dis-
ambiguation Rivaling Supervised Methods. 
Proceedings of the 33rd Meeting of the Association 
for Computational Linguistics (ACL-05), Cambridge, 
MA, pages 189-196.  
 
48
